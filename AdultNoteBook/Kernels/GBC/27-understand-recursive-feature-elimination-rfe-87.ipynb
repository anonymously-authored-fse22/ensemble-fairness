{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing libraries ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import *\n#from IPython.core.display import display, HTML\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom collections import Counter\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split, KFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nsns.set(style='white', context='notebook', palette='deep')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting the Dataset using Kaggle API","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle = pd.read_csv(\"../input/adult-census-income/adult.csv\")\ndata_kaggle.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total rows, column\ndata_kaggle.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Total rows are 32561, while columns or variables or fields are 14, plus categorical 1 target class field ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis and Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Displaying datatypes and number of non-mising rows in every variable. Results show that there are no missing values in the dataset. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying datatypes and number of non-missing value for each column \ndata_kaggle.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the duplicate Rows\n\nprint(\"shape with duplicate rows: \",data_kaggle.shape)\ndata_kaggle = data_kaggle.drop_duplicates(keep = 'first')\nprint(\"shape without duplicate rows: \",data_kaggle.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This is a summary statisics for numerical columns. Now lets identify various levels in the remaining categorical columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This block shows that Native.country, workclass, and occupation have literal value '?' inside them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying names of all columns\nprint(data_kaggle.columns)\n#Displaying levels in all categorical columns\nprint(\"workclass :\",data_kaggle.workclass.unique())\nprint(\"education :\",data_kaggle.education.unique())\nprint(\"marital status :\",data_kaggle['marital.status'].unique())\nprint(\"occupation :\",data_kaggle.occupation.unique())\nprint(\"relationship :\",data_kaggle.relationship.unique())\nprint(\"race :\",data_kaggle.race.unique())\nprint(\"sex :\",data_kaggle.sex.unique())\nprint(\"native country :\",data_kaggle['native.country'].unique())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exploring target variable ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying target field and distribution for two classes\nprint(data_kaggle.income.unique())\nprint(data_kaggle.income.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count of >50K & <=50K\nsns.countplot(data_kaggle['income'],label=\"Count\")\n#sns.plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram Distribution of all numeric fields of the Dataset\ndistribution = data_kaggle.hist(edgecolor = 'black', linewidth = 1.2, color = 'b')\nfig = plt.gcf()\nfig.set_size_inches(12,12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Few insights from above graphs -\n* Capital gain and Capital Loss have maximum entries as 0. I will be combining the two fields later on as part of my feature engineering work.\n* Hours per week has maximum entries (almost half) as 40 hours. This will help in analysisng later on whwther this field can be converted into a categorical field and how it can be done.\n* Education number has most entries for 9, 10 and 13 levels. This column can be explored for conversion to lesser categories during the analysis.\n* Also note that, fnlwgt is weight of an observation.\n\nPlease note that this above piece of EDA code of plotting histograms, is from kernel - https://www.kaggle.com/sumitm004/eda-and-income-predictions-86-75-accuracy. The analysis is all mine and I have included this kernel in my research too, pleease refer my report for details. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting levels in all categorical columns\ndata_kaggle.sex.value_counts().head(10).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.workclass.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.education.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle['education.num'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Some insights:\n* Educatin and education.num stands for same dimension.\n* education.num is not the years spent in education but is an ordinal ranking to corresponding education level","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle['marital.status'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.occupation.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.relationship.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.race.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.sex.value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle['native.country'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Sex along with the target field income. This has shown that most of the females are earning lesser than 50000 dollars\n#Thus Sex can be a good predictor of target class.\npd.crosstab(data_kaggle['sex'],data_kaggle['income']).plot(kind=\"bar\",figsize=(15,6) )\nplt.title('Income  for Sex')\nplt.xlabel('Sex (0 = Female, 1 = Male)')\nplt.xticks(rotation=0)\nplt.ylabel('Frequency')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This EDA code for exploring sex and income together, is taken from a kernel which can be found here - https://www.kaggle.com/lodetomasi1995/income-classification-eda-azure-dataset. \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Few insights from plotting categorical variables\n* Very high majority has their 'Native Country' as USA. I can recode this variable as 0 and 1, keeping 1 for USa and 0 for rest of the countries or vice-versa\n* Similarly, Race can be recoded with 'white' as 1 and others as 0.\n* In workclass variable, '?' is 4th most occurring value, and in occupation its 8th most occuring. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting count of '?' in occupation\ncount_occu = data_kaggle[data_kaggle.occupation == '?'].occupation.count()\nprint(count_occu)\n#Getting count of '?' in workclass\ncount_work = data_kaggle[data_kaggle.workclass == '?'].workclass.count()\nprint(count_work)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting count of '?' in occupation\ndata_kaggle[data_kaggle.occupation == '?'].workclass.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting count of '?' in occupation\ndata_kaggle[data_kaggle.workclass == '?'].occupation.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Some insights :\n* When value for occupation is '?' , workclass is either '?' or 'Never worked'. And when value for workclass is '?' , occuptaion is  '?' too. \n* 1800 rows is a huge numuber, hence discarding the rows will not be a right decision. Instead, i will recode '?' with Not working' or 'Unemployed' in both the variables. It can be any other literal value too, but since both variables have '?' for same rows and general intuition says that status can be as unemploed too so going forward with this substitution.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will replace \"?\" with \"unemployed\" \ndata_kaggle.replace(to_replace =\"?\", \n                 value =\"unemployed\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Native country had '?' values too and now it is replaced with 'unempployed', which doesnt make sense. So changing the values, assigining a new category as 'unknown' for all '?' values. I am not dropping these values unlike how the kernels i have reviewed have done, as 583 rows is a significant number of rows.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle[data_kaggle['native.country'] == 'unemployed'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will replace \"?\" with \"unemployed\" \ndata_kaggle['native.country'].replace(to_replace =\"unemployed\", \n                 value =\"unknown\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now coming over to Capital gain and Capital loss variables -\n* Capital gain has more than 29k rows as 0\n* capital loss has 31k rows as 0\n* These two variables are in fact linked, as general intuition also indicates.\n* When Capital gain is 0 capital loss is either 0 or has a value, and when capital gain has a value, capital loss is always 0\n* When capital loss is 0, capital gain is either 0 or has a value, and when capital loss has a value, capital gain always has a value\n* This indicates and also as general intuition suggests - There can either be Nocapital gain and no capital loss (both are 0) , or there can be only a capital gain (when loss is 0 and gain has some value), or there can be only a capital loss at a time (when loss has a value, while gain is 0)\n\n* Thus, reengineering both columns as a single column or merging them together here. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_kaggle[data_kaggle['capital.gain']==0].shape)\nprint(data_kaggle[data_kaggle['capital.loss']==0].shape)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data_kaggle[data_kaggle['capital.gain']==0].filter(['capital.gain','capital.loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle[data_kaggle['capital.gain']==0]['capital.loss'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle[data_kaggle['capital.loss']==0]['capital.gain'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Majority values are 0 for both gain and loss\ndata_kaggle[(data_kaggle['capital.gain']==0) & (data_kaggle['capital.loss'] == 0)].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merging two columns - such that a negative value means capital loss and positive value means capital gain\ndata_kaggle['capital.flow'] =  data_kaggle['capital.gain'] - data_kaggle['capital.loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle['capital.flow'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Histogram Distribution of newly created capital.flow of the Dataset\ndistribution = data_kaggle['capital.flow'].hist(edgecolor = 'black', linewidth = 1.2, color = 'b')\nfig = plt.gcf()\nfig.set_size_inches(12,12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking for Correlation and multicollinearity - \n* When variables are highly correlated, performance of classifiers can decrease. This problem is known as multicollinearity and solution is removing one of the correlated variables between the two.\n* Using Pearson's correlation we can test for correlation between numeric fields","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" #This heatmap shows the Correlation between the different variables\nplt.rcParams['figure.figsize'] = [10,7]\nsns.heatmap(data_kaggle.filter(['age','fnlwgt','capital.flow','hours.per.week']).corr(), annot = True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n* The numberic variables are not highly or even moderateely correlated \n* It is safe to include the variables in building a model without worrying about multicollinearity\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Selecting Features:\n1. Using SelectKBest method from scikit\n    + ANOVA for numerical input variables\n    + Chi-square for categorical inputs\n2. Using Recursive Feature Elimiation or RFE ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.columns\ndata_kaggle.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection with Univariate Statistical Tests - for Numeric inputs\nfrom pandas import read_csv\nfrom numpy import set_printoptions\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n# load data\nnames = ['age','fnlwgt','capital.flow','hours.per.week']\nX= data_kaggle[names]\nY= data_kaggle['income']\n# Performing feature extraction using ANOVA method\ntest = SelectKBest(score_func=f_classif, k=2)\nfit = test.fit(X, Y)\n# summarize scores\nfeature_list_num = fit.scores_\nprint(fit.scores_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations :\n* This shows that most relevant features are those with highest scores.\n* fnlwgt is has very low relevance score, and it is understood too. The data description on Kaggle also suggests that this field is just the weight of an observation calculated on the bigger dataset collected from all USA states. I will thus be discarding the field in all my model building atttempts. I have seen this happening in some of the kernels I researched too, however the author did not statistically determined the significance or the reason of discarding the field fnlwgt.  \n* I will be using age, capital.flow and hours.per.week in my models.\n* K value is meant for telling the algortithm how many variables i want to select finally while tranforming the data. In our case since I am only using it to understand the relative importance of features and not transforming the data, it doesn't matter what value i piut in for k (k=2,k=3,k=1 will all give same outputs here)\n* Also, I will be doing this analysis as a sub-loop while performing k-fold cross validation. The reason for doing this is that , firstly, it is a stochastic approach and hence for more robust conclusion we need multiple runs to understand the actual behaviour. Secondly, while i will be doing k-fold validation, the folds or train datasets will be different every time and hence the features might behave differently for different vallues. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Encoder - Encoding or feature engineering for categorical (non-ordinal) variables\nfrom sklearn.preprocessing import LabelEncoder\n#Creating a copy of my dataframe\ndata_kaggle_cat = data_kaggle\ncategorical_features = ['workclass','marital.status','occupation','relationship','race','sex','native.country']\n\nlabel_encoder_feat = {}\nfor i, feature in enumerate(categorical_features):\n    label_encoder_feat[feature] = LabelEncoder()\n    data_kaggle_cat[feature] = label_encoder_feat[feature].fit_transform(data_kaggle_cat[feature])\n\ndata_kaggle_cat.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above codelines of using a Label Encoder is inspired from a kernel I reviewed. It can be found here - https://www.kaggle.com/sumitm004/eda-and-income-predictions-86-75-accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection with Univariate Statistical Tests - for Categorical inputs\nfrom pandas import read_csv\nfrom numpy import set_printoptions\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.feature_selection import chi2\n\n# load data\nnames = ['workclass','education.num','marital.status','occupation','relationship','race','sex','native.country']\n#names = ['education.num','marital.status','relationship','race','sex','native.country']\n\nX= data_kaggle_cat[names]\nY= data_kaggle_cat['income']\n# Performing feature extraction using Chi-square method\ntest = SelectKBest(score_func=chi2, k=2)\nfit = test.fit(X, Y)\n# summarize scores\nfeature_list_cat = fit.scores_\nprint(fit.scores_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n* Highest scores are for - relationship, eduction.num, marital.status, and sex.\n* For workclas, occupation, native.country, and race the chi-square scores are very low and hence these variables can be discarded while building up the model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Few more observations about Encoding techniques used in this report -\n* When we do Label encoding, we inadvertently introduce ordinality in the categorical variables\n* This is fine as long as we are trying to finalise best variable using univariate approaches like chi-square, as performed above\n* One solution is using one hot encoding, which creates (n-1) fields with binary 0/1 values, where n is the number of levels available in the categorical field \n* When i have to actually use these categorical variables inside my model, i will be using both - label encoding and one hot encoding approach to decide the best performing model among them. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding Target variable as 0 or 1 \n#Changing Positive to 1 and Negative to 0 for ease of processing\ndata_kaggle.loc[data_kaggle[\"income\"] == \"<=50K\", \"income\"] = 1\ndata_kaggle.loc[data_kaggle[\"income\"] == \">50K\", \"income\"] = 0\ndata_kaggle.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle.income.value_counts()\n# 1 signifies income is less than equal to 50,000 $\n# 0 signifies income is more than 50,000 $","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the final dataset after all feature engineering\nfeature_list = ['age','capital.flow','hours.per.week', 'relationship', 'education.num', 'marital.status','sex','income']\ndata_kaggle_feature1 = data_kaggle[feature_list]\ndata_kaggle_feature1.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building\n### K-fold cross vaildation\nIt gives us a less biased results than a simple train-test splitting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_kaggle_feature1.income =data_kaggle_feature1.income.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Encoder - Encoding or feature engineering for categorical (non-ordinal) variables\nfrom sklearn.preprocessing import LabelEncoder\n#Creating a copy of my dataframe\n#data_kaggle_cat = data_kaggle\ncategorical_features = ['marital.status','relationship','sex']\n\nlabel_encoder_feat = {}\nfor i, feature in enumerate(categorical_features):\n    label_encoder_feat[feature] = LabelEncoder()\n    data_kaggle_feature1[feature] = label_encoder_feat[feature].fit_transform(data_kaggle_feature1[feature])\n\ndata_kaggle_feature1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Training(25,000)+Validation(15,000) and Test(10,000) sttartefied dataset - a split of 50-30-20% respectively\n#First splitting dataset of 50,000 instances into training (80%) and test (20%)\nfrom sklearn.model_selection import train_test_split\nX_training, X_test, Y_training, Y_test = train_test_split(data_kaggle_feature1.iloc[:,0:-1], data_kaggle_feature1.income,\n                                                    stratify=data_kaggle_feature1.income, \n                                                    test_size=0.10)\n\n\n\nprint(\"Shape of train split :\",X_training.shape,Y_training.shape)\nprint(\"Shape of test split :\",X_test.shape,Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Using Logistic Regression**","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# scikit-learn k-fold cross-validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom itertools import compress\nfrom numpy import array\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom statistics import mode\nfrom operator import itemgetter \nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\n\n# Prepare for 10-fold cross validation\nskf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X_training, Y_training)\naccu_kfold_list = []\ncounter_kfold =0\n# enumerate splits\nfor train, val in skf.split(X_training, Y_training):\n    counter_kfold+=1\n    #print(\"KFold validation iteration :\",counter_kfold)\n    X_train, X_val = X_training.iloc[train], X_training.iloc[val]\n    Y_train, Y_val = Y_training.iloc[train], Y_training.iloc[val]\n\n\n    # create a base classifier used to evaluate a subset of attributes\n    accu_list = []\n    for num_of_vars in range(1,len(data_kaggle_feature1.columns)):\n        \n        #Logistic Regression\n        logreg = LogisticRegression()\n        # create the RFE model and select 3 attributes\n        rfe = RFE(logreg, num_of_vars)\n        rfe = rfe.fit(X_train, Y_train)\n\n        # summarize the selection of the attributes\n        #print(\"Number of variables used :\",num_of_vars)\n        col_list = data_kaggle_feature1.columns.to_list()[:-1]\n        #print(col_list)\n        col_bool = rfe.support_\n        #print(col_bool)\n        col_list = list(compress(col_list, col_bool))  \n        #print(\"Variables used in building this classifier :\",col_list)\n\n        # fit\n        logreg.fit(X_train.filter(col_list), Y_train)\n\n        # predict\n        Y_pred = logreg.predict(X_val.filter(col_list))\n\n        accuracy = accuracy_score(Y_val, Y_pred)\n        #print('LogReg %s' % accuracy)\n\n        #Adding the accuracy to list\n        accu_list.append(accuracy)\n\n    #print(accu_list)\n    accu_kfold_list.append(accu_list)\n\n\n#List of all accuracies\n#print(accu_kfold_list)\n\n#Creating empty lists to calculate which variable configuration produced maximum acccuracy\nlst_rfe = []\nlst_acu = []\nfor lst in accu_kfold_list:\n    print(\"Index or number of variables used to build a model:\",lst.index(max(lst))+1, \"Max accuracy value :\",max(lst) )\n    lst_rfe.append(lst.index(max(lst))+1)\n    lst_acu.append(max(lst))\n    \nprint(\"List of 10 accuracies :\",lst_acu)\nprint(\"List of indices or number of variables used :\" ,lst_rfe)  \nmode_val = max(set(lst_rfe), key=lst_rfe.count)\nprint(\"The Final number of variables that i am using to build and report best model :\",mode_val)\nindices = [i for i, x in enumerate(lst_rfe) if x == mode_val]\nprint(\"The indices of most occuring k value :\",indices)\n\n# using operator.itemgetter() to get elements from list  \nres_list = list(itemgetter(*indices)(lst_acu))\nprint(\"The accuracy values present at these indices :\",res_list)\nprint(\"The Final mean cross validation accuracy for reporting purpose is :\",mean(res_list))\n#print(\"The number of variables used in the best model :\",mode(lst_avg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations from and explanation for the above step:\n* I am running an **inner loop** for running the RFE for 1 to maximum number of columns\n* This will help me in identifying the columns which together produce the best estimate (or accuracies)\n* The **outer loop** is to provide 10-fold cross validation.\n* Idea is that for every fold the RFE should run, because every fold gives a different set of observations and hence RFE results could certainly differ. This is evident from the above analysis, as in some fold 3 columns gave best results while in some folds 7 columns gave best reults. \n* This approach will minimize the bias.\n* Also, since i am using K-fold cross validation, I am going to get a distribution of accuracy values at the end and thus i can easily compare the performances of two models to determine which one is better. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Using Gradient Boosting Algorithm or GBC ","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# scikit-learn k-fold cross-validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom itertools import compress\nfrom numpy import array\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom statistics import mode\nfrom operator import itemgetter \nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\n# Prepare for 10-fold cross validation\nskf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X_training, Y_training)\naccu_kfold_list = []\ncounter_kfold =0\n# enumerate splits\nfor train, val in skf.split(X_training, Y_training):\n    counter_kfold+=1\n    #print(\"KFold validation iteration :\",counter_kfold)\n    X_train, X_val = X_training.iloc[train], X_training.iloc[val]\n    Y_train, Y_val = Y_training.iloc[train], Y_training.iloc[val]\n\n\n    # create a base classifier used to evaluate a subset of attributes\n    accu_list = []\n    for num_of_vars in range(1,len(data_kaggle_feature1.columns)):\n        \n        # Gradient Boosting Algorithm - fit\n        gbc = GradientBoostingClassifier()\n\n        # create the RFE model and select 3 attributes\n        rfe = RFE(gbc, num_of_vars)\n        rfe = rfe.fit(X_train, Y_train)\n\n        \n        # summarize the selection of the attributes\n        #print(\"Number of variables used :\",num_of_vars)\n        col_list = data_kaggle_feature1.columns.to_list()[:-1]\n        #print(col_list)\n        col_bool = rfe.support_\n        #print(col_bool)\n        col_list = list(compress(col_list, col_bool))  \n        #print(\"Variables used in building this classifier :\",col_list)\n\n        # fit\n        #logreg.fit(X_train.filter(col_list), Y_train)\n        gbc.fit(X_train.filter(col_list), Y_train)\n        accuracy = gbc.score(X_val.filter(col_list), Y_val)\n        #print('GBC %s' % accuracy)\n\n        #Adding the accuracy to list\n        accu_list.append(accuracy)\n\n    #print(accu_list)\n    accu_kfold_list.append(accu_list)\n\n\n#List of all accuracies\n#print(accu_kfold_list)\n\n#Creating empty lists to calculate which variable configuration produced maximum acccuracy\nlst_rfe = []\nlst_acu = []\nfor lst in accu_kfold_list:\n    print(\"Index or number of variables used to build a model:\",lst.index(max(lst))+1, \"Max accuracy value :\",max(lst) )\n    lst_rfe.append(lst.index(max(lst))+1)\n    lst_acu.append(max(lst))\n    \nprint(\"List of 10 accuracies :\",lst_acu)\nprint(\"List of indices or number of variables used :\" ,lst_rfe)\nmode_val = max(set(lst_rfe), key=lst_rfe.count)\nprint(\"The Final number of variables that i am using to build and report best model :\",mode_val)\nindices = [i for i, x in enumerate(lst_rfe) if x == mode_val]\nprint(\"The indices of most occuring k value :\",indices)\n\n# using operator.itemgetter() to get elements from list  \nres_list = list(itemgetter(*indices)(lst_acu))\nprint(\"The accuracy values present at these indices :\",res_list)\nprint(\"The Final mean cross validation accuracy for reporting purpose is :\",mean(res_list))\n#print(\"The number of variables used in the best model :\",mode(lst_avg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n* Best accuracy is given by models build with both 5 oand 6 variables. My algorithm picked the smaller mode of two numbers.\n* Mean Validation Accuracy is 86.02 %\n* This is significantly higher than our Baseline as well as logistic regression performance","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Algorithm ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# scikit-learn k-fold cross-validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom itertools import compress\nfrom numpy import array\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom statistics import mode\nfrom operator import itemgetter \nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# Prepare for 10-fold cross validation\nskf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X_training, Y_training)\naccu_kfold_list = []\ncounter_kfold =0\n# enumerate splits\nfor train, val in skf.split(X_training, Y_training):\n    counter_kfold+=1\n    #print(\"KFold validation iteration :\",counter_kfold)\n    X_train, X_val = X_training.iloc[train], X_training.iloc[val]\n    Y_train, Y_val = Y_training.iloc[train], Y_training.iloc[val]\n\n\n    # create a base classifier used to evaluate a subset of attributes\n    accu_list = []\n    for num_of_vars in range(1,len(data_kaggle_feature1.columns)):\n        \n        # Random Forest Algorithm \n        R_forest = RandomForestClassifier(n_estimators = 200)\n\n        # create the RFE model \n        rfe = RFE(R_forest, num_of_vars)\n        rfe = rfe.fit(X_train, Y_train)\n\n        \n        # summarize the selection of the attributes\n        #print(\"Number of variables used :\",num_of_vars)\n        col_list = data_kaggle_feature1.columns.to_list()[:-1]\n        #print(col_list)\n        col_bool = rfe.support_\n        #print(col_bool)\n        col_list = list(compress(col_list, col_bool))  \n        #print(\"Variables used in building this classifier :\",col_list)\n\n        # Training the model - Fitting\n        model_random = R_forest.fit(X_train.filter(col_list), Y_train)\n        \n        # Predictions\n        pred_random = model_random.predict(X_val.filter(col_list))\n        accuracy = accuracy_score(Y_val, pred_random)\n        #print (\"The accuracy of Random Forest model is : \",accuracy)\n\n        #Adding the accuracy to list\n        accu_list.append(accuracy)\n\n    #print(accu_list)\n    accu_kfold_list.append(accu_list)\n\n\n#List of all accuracies\n#print(accu_kfold_list)\n\n#Creating empty lists to calculate which variable configuration produced maximum acccuracy\nlst_rfe = []\nlst_acu = []\nfor lst in accu_kfold_list:\n    print(\"Index or number of variables used to build a model:\",lst.index(max(lst))+1, \"Max accuracy value :\",max(lst) )\n    lst_rfe.append(lst.index(max(lst))+1)\n    lst_acu.append(max(lst))\n    \nprint(\"List of 10 accuracies :\",lst_acu)\nprint(\"List of indices or number of variables used :\" ,lst_rfe)\nmode_val = max(set(lst_rfe), key=lst_rfe.count)\nprint(\"The Final number of variables that i am using to build and report best model :\",mode_val)\nindices = [i for i, x in enumerate(lst_rfe) if x == mode_val]\nprint(\"The indices of most occuring k value :\",indices)\n\n# using operator.itemgetter() to get elements from list  \nres_list = list(itemgetter(*indices)(lst_acu))\nprint(\"The accuracy values present at these indices :\",res_list)\nprint(\"The Final mean cross validation accuracy for reporting purpose is :\",mean(res_list))\n#print(\"The number of variables used in the best model :\",mode(lst_avg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n* For Random Forest, RFE has shown that using three variables you can get the best classifier accuracies. \n* Doing 10-fold validation has produced a Mean Validation accuracy of 85.82.\n* This accuracy is much higher than our baseline accuracy, but still fell short of Gradient Boosting Classifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Algorithm","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Uninstalling XGBoost and downloading an earlier version as RFE is not compatible with the latest XGBoost.\n!pip show xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip uninstall xgboost --y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade xgboost==0.90","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip show xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# scikit-learn k-fold cross-validation\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom itertools import compress\nfrom numpy import array\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom statistics import mode\nfrom operator import itemgetter \nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')\n\n# Prepare for 10-fold cross validation\nskf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X_training, Y_training)\naccu_kfold_list = []\ncounter_kfold =0\n# enumerate splits\nfor train, val in skf.split(X_training, Y_training):\n    counter_kfold+=1\n    #print(\"KFold validation iteration :\",counter_kfold)\n    X_train, X_val = X_training.iloc[train], X_training.iloc[val]\n    Y_train, Y_val = Y_training.iloc[train], Y_training.iloc[val]\n\n\n    # create a base classifier used to evaluate a subset of attributes\n    accu_list = []\n    for num_of_vars in range(1,len(data_kaggle_feature1.columns)):\n        \n        # XG Boost Algorithm \n        XGB = XGBClassifier(learning_rate = 0.35, n_estimator = 200, silent = True, verbosity = 0)\n\n        # create the RFE model \n        rfe = RFE(XGB, num_of_vars)\n        rfe = rfe.fit(X_train, Y_train)\n\n        \n        # summarize the selection of the attributes\n        #print(\"Number of variables used :\",num_of_vars)\n        col_list = data_kaggle_feature1.columns.to_list()[:-1]\n        #print(col_list)\n        col_bool = rfe.support_\n        #print(col_bool)\n        col_list = list(compress(col_list, col_bool))  \n        #print(\"Variables used in building this classifier :\",col_list)\n\n        # Training the model - Fitting\n        model_xgb = XGB.fit(X_train.filter(col_list), Y_train)\n        #model_random = R_forest.fit(X_train.filter(col_list), Y_train)\n        \n        # Predictions\n        #pred_random = model_random.predict(X_val.filter(col_list))\n        pred_xgb = model_xgb.predict(X_val.filter(col_list))\n\n        #accuracy = accuracy_score(Y_val, pred_random)\n        accuracy = accuracy_score(Y_val, pred_xgb)\n        #print (\"The accuracy of XGBoost model is : \",accuracy)\n\n        #Adding the accuracy to list\n        accu_list.append(accuracy)\n\n    #print(accu_list)\n    accu_kfold_list.append(accu_list)\n\n\n#List of all accuracies\n#print(accu_kfold_list)\n\n#Creating empty lists to calculate which variable configuration produced maximum acccuracy\nlst_rfe = []\nlst_acu = []\nfor lst in accu_kfold_list:\n    print(\"Index or number of variables used to build a model:\",lst.index(max(lst))+1, \"Max accuracy value :\",max(lst) )\n    lst_rfe.append(lst.index(max(lst))+1)\n    lst_acu.append(max(lst))\n    \nprint(\"List of 10 accuracies :\",lst_acu)\nprint(\"List of indices or number of variables used :\" ,lst_rfe)\nmode_val = max(set(lst_rfe), key=lst_rfe.count)\nprint(\"The Final number of variables that i am using to build and report best model :\",mode_val)\nindices = [i for i, x in enumerate(lst_rfe) if x == mode_val]\nprint(\"The indices of most occuring k value :\",indices)\n\n# using operator.itemgetter() to get elements from list  \nres_list = list(itemgetter(*indices)(lst_acu))\nprint(\"The accuracy values present at these indices :\",res_list)\nprint(\"The Final mean cross validation accuracy for reporting purpose is :\",mean(res_list))\n#print(\"The number of variables used in the best model :\",mode(lst_avg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n* All 7 variables have been used to build up the best performing XGBoost model. RFE has suggested to use all 7 variables to get the best classifier.\n* Please note that, my first fold validation gave 87.47 % accuracy, where as the best accuracy in this dataset on Kernel is 86.75%. I have done a review of this kernel in my report. Also note that, the author is reporting only a single accuracy, and that is prone to high bias and is also highly-optimistic.\n* From a 10-fold cross validation, my Mean Validation accuracy is coming as 86.29% .","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"data_kaggle[data_kaggle.workclass == 0]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#One hot Encoder - Encoding or feature engineering for categorical (non-ordinal) variables\n#from sklearn.preprocessing import LabelEncoder\n#Creating a copy of my dataframe\ndata_kaggle_ohe = data_kaggle.copy()\ncategorical_features_ohe = ['workclass','marital.status','occupation','relationship','race','sex','native.country']\n\nlabel_encoder_feat = {}\nnew_df = pd.DataFrame() #creates a new dataframe that's empty\ndf_temp = pd.get_dummies(data_kaggle_ohe['workclass'], prefix='workclass')\nfor i, feature in enumerate(categorical_features_ohe[1:]):\n    df_temp1 = pd.get_dummies(data_kaggle_ohe[feature], prefix=feature)\n    df_temp = pd.concat([df_temp, df_temp1], axis=1)\n    #label_encoder_feat[feature] = OneHotEncoder()\n    #data_kaggle_ohe[feature] = label_encoder_feat[feature].fit_transform(data_kaggle_ohe[feature])\n\n#data_kaggle_ohe.head()\nohe_columns_list = df_temp.columns.to_list()\nprint(ohe_columns_list)\n#Changuing datatypes of all columns thus generated - from uint8 to int\ndf_temp = df_temp.astype(int)\n\ndata_kaggle_ohe = data_kaggle_ohe.drop(categorical_features_ohe, axis=1)\ndata_kaggle_ohe = pd.concat([data_kaggle_ohe,df_temp], axis=1)\ndata_kaggle_ohe.head(5)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Feature Selection with Univariate Statistical Tests - for Categorical inputs\n#List of columns that i need to hot encode\nnames = ohe_columns_list\n\nX= data_kaggle_ohe[names]\nY= data_kaggle_ohe['income'].astype('int')\n# Performing feature extraction using Chi-square method\ntest = SelectKBest(score_func=chi2, k=3)\nfit = test.fit(X, Y)\n# summarize scores\nfeature_list_cat = fit.scores_\nnp.set_printoptions(formatter={'float_kind':'{:f}'.format})\n\nprint(\"scores :\",fit.scores_)\nprint(\"col names :\",names)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#Creating a dictionary and dataframe woith scores and col names\ndict_temp = {'scores': fit.scores_, 'cols': names}\ndf_scores = pd.DataFrame(dict_temp)\nprint (\"old shape :\",df_scores.shape)\n#Limiting the number of columns for next step by only picking scores higher than 100\ndf_scores = df_scores[df_scores.scores >= 450]\nprint (\"New shape :\",df_scores.shape)\n# a bar plot \ndf_scores.plot(kind='bar',x='cols',y='scores',color='red')\nplt.xticks(rotation=70)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"data_kaggle_ohe.columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#Getting the name of  variables in a list\n#These variables were identified using ANOVA analysis of numeric variables above\nlist1 = ['age', 'capital.flow','hours.per.week'] \n#This is the list of newly created variables using SelectKBest and One Hot ENcoding\nlist2 = df_scores.cols.to_list() \n#List of variables present in our dataset\nlist3 = data_kaggle_ohe.columns.to_list()\n\n#Getting all this together\nlist4 = ['income','education.num']\nfor items in list3:\n    if items in list1:\n        list4.append(items)\n    if items in list2:\n        list4.append(items)\n#Final list of variables for running RFE and Logistic regression\nprint(\"Final list of variables for building my model :\",list4)\n#Filtering dataset accordingly\nprint(\"Shape of final dataset :\",data_kaggle_ohe[list4].shape)\ndata_kaggle_ohe[list4].head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"print(list4)\ndata_kaggle_ohe[list4[1:]] #.iloc[:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Creating Training(25,000)+Validation(15,000) and Test(10,000) sttartefied dataset - a split of 50-30-20% respectively\n#First splitting dataset of 50,000 instances into training (80%) and test (20%)\nfrom sklearn.model_selection import train_test_split\nX_training, X_test, Y_training, Y_test = train_test_split(data_kaggle_ohe[list4[1:]], data_kaggle_ohe.income,\n                                                    stratify=data_kaggle_ohe.income, \n                                                    test_size=0.10)\n\n\nY_training, Y_test =  Y_training.astype(int), Y_test.astype(int)\nprint(\"Shape of train split :\",X_training.shape,Y_training.shape)\nprint(\"Shape of test split :\",X_test.shape,Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Using Logistic Regression**","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"X_training.columns.to_list() #18 variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# scikit-learn k-fold cross-validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom itertools import compress\nfrom numpy import array\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom statistics import mode\nfrom operator import itemgetter \nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# Prepare for 10-fold cross validation\nskf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X_training, Y_training)\naccu_kfold_list = []\ncounter_kfold =0\n# enumerate splits\nfor train, val in skf.split(X_training, Y_training):\n    counter_kfold+=1\n    #print(\"KFold validation iteration :\",counter_kfold)\n    X_train, X_val = X_training.iloc[train], X_training.iloc[val]\n    Y_train, Y_val = Y_training.iloc[train], Y_training.iloc[val]\n\n\n    # create a base classifier used to evaluate a subset of attributes\n    accu_list = []\n    for num_of_vars in range(1,len(X_training.columns)):\n        \n        #Logistic Regression\n        logreg = LogisticRegression()\n        # create the RFE model and select 3 attributes\n        rfe = RFE(logreg, num_of_vars)\n        rfe = rfe.fit(X_train, Y_train)\n\n        # summarize the selection of the attributes\n        #print(\"Number of variables used :\",num_of_vars)\n        col_list = X_training.columns.to_list()[:-1]\n        #print(col_list)\n        col_bool = rfe.support_\n        #print(col_bool)\n        col_list = list(compress(col_list, col_bool))  \n        #print(\"Variables used in building this classifier :\",col_list)\n\n        # fit\n        logreg.fit(X_train.filter(col_list), Y_train)\n\n        # predict\n        Y_pred = logreg.predict(X_val.filter(col_list))\n\n        accuracy = accuracy_score(Y_val, Y_pred)\n        #print('LogReg %s' % accuracy)\n\n        #Adding the accuracy to list\n        accu_list.append(accuracy)\n \n    #print(accu_list)\n    accu_kfold_list.append(accu_list)\n\n\n#List of all accuracies\n#print(accu_kfold_list)\n\n#Creating empty lists to calculate which variable configuration produced maximum acccuracy\nlst_rfe = []\nlst_acu = []\nfor lst in accu_kfold_list:\n    print(\"Index or number of variables used to build a model:\",lst.index(max(lst))+1, \"Max accuracy value :\",max(lst) )\n    lst_rfe.append(lst.index(max(lst))+1)\n    lst_acu.append(max(lst))\n    \nprint(\"List of 10 accuracies :\",lst_acu)\nprint(\"List of indices or number of variables used :\" ,lst_rfe)  \nmode_val = max(set(lst_rfe), key=lst_rfe.count)\nprint(\"The Final number of variables that i am using to build and report best model :\",mode_val)\nindices = [i for i, x in enumerate(lst_rfe) if x == mode_val]\nprint(\"The indices of most occuring k value :\",indices)\n\n# using operator.itemgetter() to get elements from list  \nres_list = list(itemgetter(*indices)(lst_acu))\nprint(\"The accuracy values present at these indices :\",res_list)\nprint(\"The Final mean cross validation accuracy for reporting purpose is :\",mean(res_list))\n#print(\"The number of variables used in the best model :\",mode(lst_avg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations:\n* First, I have **one hot encoded** the categorical variables here\n* Using **SelectKBest** method from Scikit I have chosen the top scoring variables, i.e. 14 of them\n* These variables along education.num, income and numeric columns (finalysed by ANOVA in earlier steps) are used to create the final dataset for our modeling purposes\n* Now using **RFE**, i have identified the best model or the model with best estimate or highest accuracy\n* Analysis of RFE output suggests that most stable and accuratly predicting model is build using 17 variables.\n* The most interesting bit here is thi - the accuracy is higher than the former Logistic Classifier prediction. In the former classifier I used Label encoded or ordinally encoded variables for predictin purposes.\n* My original hypotheses was that doing **Label encoding on categorical variables introduces ordinality** in the data, which is not the true picture and thus produces less accurate classifiers. The null hypothesis is rejected here it seems and as an outcome I can say that One hot encoding is the right thing to do when it comes to encoding categorical variables especially using Logistic regresion.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Classifier","execution_count":null},{"metadata":{"trusted":false,"_kg_hide-output":true},"cell_type":"code","source":"# scikit-learn k-fold cross-validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom itertools import compress\nfrom numpy import array\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom statistics import mode\nfrom operator import itemgetter \nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')\n\n# Prepare for 10-fold cross validation\nskf = StratifiedKFold(n_splits=10)\nskf.get_n_splits(X_training, Y_training)\naccu_kfold_list = []\ncounter_kfold =0\n# enumerate splits\nfor train, val in skf.split(X_training, Y_training):\n    counter_kfold+=1\n    #print(\"KFold validation iteration :\",counter_kfold)\n    X_train, X_val = X_training.iloc[train], X_training.iloc[val]\n    Y_train, Y_val = Y_training.iloc[train], Y_training.iloc[val]\n\n\n    # create a base classifier used to evaluate a subset of attributes\n    accu_list = []\n    for num_of_vars in range(1,len(X_training.columns)):\n        \n        # XG Boost Algorithm \n        XGB = XGBClassifier(learning_rate = 0.35, n_estimator = 200, silent = True, verbosity = 0)\n\n        # create the RFE model \n        rfe = RFE(XGB, num_of_vars)\n        rfe = rfe.fit(X_train, Y_train)\n\n        \n        # summarize the selection of the attributes\n        #print(\"Number of variables used :\",num_of_vars)\n        col_list = X_training.columns.to_list()[:-1]\n        #print(col_list)\n        col_bool = rfe.support_\n        #print(col_bool)\n        col_list = list(compress(col_list, col_bool))  \n        #print(\"Variables used in building this classifier :\",col_list)\n\n        # Training the model - Fitting\n        model_xgb = XGB.fit(X_train.filter(col_list), Y_train)\n        #model_random = R_forest.fit(X_train.filter(col_list), Y_train)\n        \n        # Predictions\n        #pred_random = model_random.predict(X_val.filter(col_list))\n        pred_xgb = model_xgb.predict(X_val.filter(col_list))\n\n        #accuracy = accuracy_score(Y_val, pred_random)\n        accuracy = accuracy_score(Y_val, pred_xgb)\n        #print (\"The accuracy of XGBoost model is : \",accuracy)\n\n        #Adding the accuracy to list\n        accu_list.append(accuracy)\n\n    #print(accu_list)\n    accu_kfold_list.append(accu_list)\n\n\n#List of all accuracies\n#print(accu_kfold_list)\n\n#Creating empty lists to calculate which variable configuration produced maximum acccuracy\nlst_rfe = []\nlst_acu = []\nfor lst in accu_kfold_list:\n    print(\"Index or number of variables used to build a model:\",lst.index(max(lst))+1, \"Max accuracy value :\",max(lst) )\n    lst_rfe.append(lst.index(max(lst))+1)\n    lst_acu.append(max(lst))\n    \nprint(\"List of 10 accuracies :\",lst_acu)\nprint(\"List of indices or number of variables used :\" ,lst_rfe)\nmode_val = max(set(lst_rfe), key=lst_rfe.count)\nprint(\"The Final number of variables that i am using to build and report best model :\",mode_val)\nindices = [i for i, x in enumerate(lst_rfe) if x == mode_val]\nprint(\"The indices of most occuring k value :\",indices)\n\n# using operator.itemgetter() to get elements from list  \nres_list = list(itemgetter(*indices)(lst_acu))\nprint(\"The accuracy values present at these indices :\",res_list)\nprint(\"The Final mean cross validation accuracy for reporting purpose is :\",mean(res_list))\n#print(\"The number of variables used in the best model :\",mode(lst_avg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations:\n* The Final number of variables that i am using to build and report best model : 11\n* The Final mean cross validation accuracy for reporting purpose is : 86.99% or 87%\n* This is the best performing model till now. \n* It is even better than the best Kaggle kernel accuracy or 86.75%. Plus, it is more robust reporting, ueto the usage of RFE and cross validation.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}