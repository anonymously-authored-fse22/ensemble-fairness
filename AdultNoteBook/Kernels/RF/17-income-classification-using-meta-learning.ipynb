{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Adult Census Income Classification using Meta Learning"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing the required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.model_selection import train_test_split\n\nfrom numpy import mean, std","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#reading the dataset and converting it to dataframe\ndf = pd.read_csv(\"../input/adult-census-income/adult.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Viewing the top 5 rows of our dataset\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"**Income - Target column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.income)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*As we can see, there is a **class imbalance**. The \">50K\" class is comparatively very less. So, we will do **Random Over-Sampling** during preprocessing.*\n"},{"metadata":{},"cell_type":"markdown","source":"**Age**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[df.income=='<=50K'].age, color='g')\nsns.distplot(df[df.income=='>50K'].age, color='r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*We can observe a rough margin **around 30**. We will divide age into 2 parts ie. under 30 and over 30. We need to check if its useful for our model during testing.*"},{"metadata":{},"cell_type":"markdown","source":"**Workclass**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xticks(rotation=90)\nsns.countplot(df.workclass, hue=df.income, palette='tab10')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Majority of the data falls under **Private**. So, we will convert this into Private and not-Private.*"},{"metadata":{},"cell_type":"markdown","source":"**fnlwgt**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[df.income=='<=50K'].fnlwgt, color='r')\nsns.distplot(df[df.income=='>50K'].fnlwgt, color='g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*This is a very **ambiguous** attribute. Will check during testing.*"},{"metadata":{},"cell_type":"markdown","source":"**Education**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xticks(rotation=90)\nsns.countplot(df.education, hue=df.income, palette='muted')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**education.num**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df[\"education.num\"], hue=df.income)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**marital.status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xticks(rotation=90)\nsns.countplot(df['marital.status'], hue=df.income)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*We observe that the majority of \">50K\" class is **Married-civ-spouse**. So we ll make it 1 and others 0*"},{"metadata":{},"cell_type":"markdown","source":"**occupation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xticks(rotation=90)\nsns.countplot(df.occupation, hue=df.income, palette='rocket')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**relationship**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xticks(rotation=90)\nsns.countplot(df.relationship, hue=df.income, palette='muted')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**race**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xticks(rotation=90)\nsns.countplot(df.race, hue=df.income, palette='Set2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**sex**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xticks(rotation=90)\nsns.countplot(df.sex, hue=df.income)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**capital.gain**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['capital.gain'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**capital.loss**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['capital.loss'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**hours.per.week**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[df.income=='<=50K']['hours.per.week'], color='b')\nsns.distplot(df[df.income=='>50K']['hours.per.week'], color='r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**native.country**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['native.country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### Finding and Handling Missing Data\n\n*Observing the dataset, I found that the null values are marked as \"?\", So, we will now convert them to numpy.nan(null values).*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.select_dtypes(\"object\") ==\"?\"] = np.nan\nnans = df.isnull().sum()\nif len(nans[nans>0]):\n    print(\"Missing values detected.\\n\")\n    print(nans[nans>0])\nelse:\n    print(\"No missing values. You are good to go.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#majority of the values are \"Private\". Lets fill the missing values as \"Private\".\ndf.workclass.fillna(\"Private\", inplace=True)\n\ndf.occupation.fillna(method='bfill', inplace=True)\n\n#majority of the values are \"United-States\". Lets fill the missing values as \"United-States\".\ndf['native.country'].fillna(\"United-States\", inplace=True)\n\nprint(\"Handled missing values successfully.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import column_or_1d\n\nclass MyLabelEncoder(LabelEncoder):\n\n    def fit(self, y, arr=[]):\n        y = column_or_1d(y, warn=True)\n        if arr == []:\n            arr=y\n        self.classes_ = pd.Series(arr).unique()\n        return self\n\nle = MyLabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering and Encoding the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# age_enc = pd.cut(df.age, bins=(0,25,45,65,100), labels=(0,1,2,3))\ndf['age_enc'] = df.age.apply(lambda x: 1 if x > 30 else 0)\n\ndef prep_workclass(x):\n    if x == 'Never-worked' or x == 'Without-pay':\n        return 0\n    elif x == 'Private':\n        return 1\n    elif x == 'State-gov' or x == 'Local-gov' or x == 'Federal-gov':\n        return 2\n    elif x == 'Self-emp-not-inc':\n        return 3\n    else:\n        return 4\n\ndf['workclass_enc'] = df.workclass.apply(prep_workclass)\n\ndf['fnlwgt_enc'] = df.fnlwgt.apply(lambda x: 0 if x>200000 else 1)\n\nle.fit(df.education, arr=['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th','10th', '11th', '12th', \n                                             'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', 'Some-college', 'Bachelors', 'Masters', 'Doctorate'])\ndf['education_enc'] = le.transform(df.education)\n\n\ndf['education.num_enc'] = df['education.num'].apply(lambda x: 1 if x>=9 else 0)\n\ndf['marital.status_enc'] = df['marital.status'].apply(lambda x: 1 if x=='Married-civ-spouse' or x == 'Married-AF-spouse' else 0)\n\ndef prep_occupation(x):\n    if x in ['Prof-specialty', 'Exec-managerial', 'Tech-support', 'Protective-serv']:\n        return 2\n    elif x in ['Sales', 'Craft-repair']:\n        return 1\n    else:\n        return 0\n\ndf['occupation_enc'] = df.occupation.apply(prep_occupation)\n\ndf['relationship_enc'] = df.relationship.apply(lambda x: 1 if x in ['Husband', 'Wife'] else 0)\n\ndf['race_enc'] = df.race.apply(lambda x: 1 if x=='White' else 0)\n\ndf['sex_enc'] = df.sex.apply(lambda x: 1 if x=='Male' else 0)\n\ndf['capital.gain_enc'] = pd.cut(df[\"capital.gain\"], \n                                bins=[-1,0,df[df[\"capital.gain\"]>0][\"capital.gain\"].median(), df[\"capital.gain\"].max()], labels=(0,1,2)).astype('int64')\n\ndf['capital.loss_enc'] = pd.cut(df[\"capital.loss\"], \n                                bins=[-1,0,df[df[\"capital.loss\"]>0][\"capital.loss\"].median(), df[\"capital.loss\"].max()], labels=(0,1,2)).astype('int64')\n\n# hpw_enc = pd.cut(df['hours.per.week'], bins= (0,30,40,53,168), labels=(0,1,2,3))\ndf['hours.per.week_enc'] = pd.qcut(df['hours.per.week'], q=5, labels=(0,1,2,3), duplicates='drop').astype('int64')\n\ndf['native.country_enc'] = df['native.country'].apply(lambda x: 1 if x=='United-States' else 0)\n\ndf['income_enc'] = df.income.apply(lambda x: 1 if x==\">50K\" else 0)\n\nprint(\"Encoding complete.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes(\"object\").info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping encoded columns - education, sex, income\ndf.drop(['education', 'sex', 'income'], 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding without Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in df.select_dtypes(\"object\").columns:\n    df[feature]=le.fit_transform(df[feature])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing the pearson correlation with the target class\npcorr = df.drop('income_enc',1).corrwith(df.income_enc)\nplt.figure(figsize=(10,6))\nplt.title(\"Pearson Correlation of Features with Income\")\nplt.xlabel(\"Features\")\nplt.ylabel(\"Correlation Coeff\")\nplt.xticks(rotation=90)\nplt.bar(pcorr.index, list(map(abs,pcorr.values)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the pearson correlation plot, we can see that correlation of few columns are very **low** with the target column, so, we ll drop them."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['workclass', 'fnlwgt','occupation', 'race', 'native.country', 'fnlwgt_enc', 'race_enc', 'native.country_enc'], 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr().apply(abs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dropping redundant features**"},{"metadata":{},"cell_type":"markdown","source":"We can see that **education_enc, education.num_enc and education.num** as well as **relationship_enc and marital.status_enc** have **high correlation**. So, we will only keep one of them based on their correlation with income_enc.\n\nWe also have some redundant feautres as we have engineered features from them(age, capital.gain, etc.)."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['age', 'education.num_enc', 'education_enc', 'marital.status_enc', 'capital.gain', 'capital.loss', 'hours.per.week'], 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('income_enc', 1)\ny = df.income_enc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Test Split (3:1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No. of rows in training data:\",X_train.shape[0])\nprint(\"No. of rows in testing data:\",X_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Over Sampling"},{"metadata":{},"cell_type":"markdown","source":"*We can see the class imbalance in our target. This results in models that have poor predictive performance, specifically for the minority class. So, we need to random over sampling*"},{"metadata":{"trusted":true},"cell_type":"code","source":"oversample = RandomOverSampler(sampling_strategy=0.5) #50% oversampling\nX_over, y_over = oversample.fit_resample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_over.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Imports\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, StackingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed= 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\n    'LR':LogisticRegression(random_state=seed),\n    'SVC':SVC(random_state=seed),\n    'AB':AdaBoostClassifier(random_state=seed),\n    'ET':ExtraTreesClassifier(random_state=seed),\n    'GB':GradientBoostingClassifier(random_state=seed),\n    'RF':RandomForestClassifier(random_state=seed),\n    'XGB':XGBClassifier(random_state=seed),\n    'LGBM':LGBMClassifier(random_state=seed)\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate a give model using cross-validation\ndef evaluate_models(model, xtrain, ytrain):\n    cv = StratifiedKFold(shuffle=True, random_state=seed)\n    scores = cross_val_score(model, xtrain, ytrain, scoring='accuracy', cv=cv, error_score='raise')\n    return scores\n\ndef plot_scores(xval,yval,show_value=False):\n    plt.ylim(ymax = max(yval)+0.5, ymin = min(yval)-0.5)\n    plt.xticks(rotation=45)\n    s = sns.barplot(xval,yval)\n    if show_value:\n        for x,y in zip(range(len(yval)),yval):\n            s.text(x,y+0.1,round(y,2),ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the models and store results for 100% oversampled minority class\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_models(model, X_train, y_train) \n    results.append(scores) \n    names.append(name) \n    print('*%s %.3f (%.3f)' % (name, mean(scores), std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(results, labels=names, showmeans=True)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grids = {\n    'LR':{'C':[0.001,0.01,0.1,1,10]},\n    'SVC':{'gamma':[0.01,0.02,0.05,0.08,0.1], 'C':range(1,8)},\n    \n    'AB':{'learning_rate': [0.05, 0.1, 0.2], 'n_estimators': [100, 200, 500]},\n    \n    'ET':{'max_depth':[5,8,10,12], 'min_samples_split': [5,9,12],\n          'n_estimators': [100,200,500,800]},\n    \n    'GB':{'learning_rate': [0.05, 0.1, 0.2], 'max_depth':[3,5,9],\n          'min_samples_split': [5,7,9], 'n_estimators': [100,200,500],\n          'subsample':[0.5,0.7,0.9]},\n    \n    'RF':{'max_depth':[3,5,9,15], 'n_estimators': [100, 200, 500, 1000],\n          'learning_rate': [0.05, 0.1, 0.2], 'min_samples_split': [5,9,12]},\n    \n    'XGB':{'max_depth':[3,5,7,9], 'n_estimators': [100, 200, 500],\n           'learning_rate': [0.05, 0.1, 0.2], 'subsample':[0.5,0.7,0.9]},\n    \n    'LGBM':{'n_estimators': [100,200,500],'learning_rate': [0.05, 0.1, 0.2],\n            'subsample':[0.5,0.7,0.9],'num_leaves': [25,31,50]}\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install sklearn-deap\n# from evolutionary_search import EvolutionaryAlgorithmSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the models and store results\n# best_params = []\n# names= []\n# for name, param_grid, model in zip(param_grids.keys(), param_grids.values(), models.values()):\n#     eascv = EvolutionaryAlgorithmSearchCV(model, param_grid, verbose=3, cv=3)\n#     eascv.fit(X_train,y_train)\n#     names.append(name)\n#     best_params.append(eascv.best_params_)\n#     print(name)\n#     print(\"best score:\",eascv.best_score_)\n#     print(\"best params:\",eascv.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params=[\n    {'C': 10},\n    {'gamma': 0.1, 'C': 2},\n    {'learning_rate': 0.1, 'n_estimators': 500},\n    {'max_depth': 12, 'min_samples_split': 9, 'n_estimators': 100},\n    {'learning_rate': 0.05, 'max_depth': 3, 'min_samples_split': 9, 'n_estimators': 200, 'subsample': 0.9},\n    {'max_depth': 9, 'n_estimators': 200, 'min_samples_split': 5},\n    {'max_depth': 3, 'n_estimators': 200, 'learning_rate': 0.1, 'subsample': 0.9},\n    {'n_estimators': 100, 'learning_rate': 0.05, 'subsample': 0.9, 'num_leaves': 25}\n            ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [\n    ('LR',LogisticRegression(random_state=seed)),\n    ('SVC',SVC(random_state=seed)),\n    ('AB',AdaBoostClassifier(random_state=seed)),\n    ('ET',ExtraTreesClassifier(random_state=seed)),\n    ('GB',GradientBoostingClassifier(random_state=seed)),\n    ('RF',RandomForestClassifier(random_state=seed)),\n    ('XGB',XGBClassifier(random_state=seed)),\n    ('LGBM',LGBMClassifier(random_state=seed))\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model, param in zip(models, best_params):\n    model[1].set_params(**param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models.append(('MLModel',StackingClassifier(estimators = models[:-1])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores=[]\npreds=[]\nfor model in models:\n    model[1].fit(X_train,y_train)\n    print(model[0],\"trained.\")\n    scores.append(model[1].score(X_test,y_test))\n    preds.append(model[1].predict(X_test))\nprint(\"Results are ready.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using Classification Based on Assocation"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyarc==1.0.23\n!pip install pyfim\nfrom pyarc import CBA, TransactionDB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txns_train = TransactionDB.from_DataFrame(X_train.join(y_train))\ntxns_test = TransactionDB.from_DataFrame(X_test.join(y_test))\n\n\ncba = CBA(support=0.15, confidence=0.5, algorithm=\"m1\")\ncba.fit(txns_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cba_score = cba.rule_model_accuracy(txns_test) \nscores.append(cba_score)\nmodels.append([\"CBA\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names= [i[0] for i in models]\nscores = list(map(lambda x: x*100, scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scores(model_names, scores, True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}