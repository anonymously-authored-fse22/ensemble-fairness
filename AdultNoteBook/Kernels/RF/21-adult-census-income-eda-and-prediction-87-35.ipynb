{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Adult Census Income EDA and Prediction\n\nIn this kernel I work with the UCI Adult Census Income dataset. The prediction task is to determine whether a person makes over $50K a year. I start with an exhaustive EDA, and I then train various models to solve the prediction task."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\ndata = pd.read_csv(\"../input/adult.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(data))\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['income'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sex distribution\nsns.countplot(data['sex'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age distribution\nages = data['age'].hist(bins=max(data['age'])-min(data['age']))\nmean_val = np.mean(data['age'])\nplt.axvline(mean_val, linestyle='dashed', linewidth=2, color='yellow', label='mean age')\nplt.xlabel('age')\nplt.ylabel('count')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['hours.per.week'].hist()\nplt.xlabel('hours per week')\nplt.ylabel('count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, nrows=4, figsize=(20, 20))\nplt.subplots_adjust(hspace=0.68)\nfig.delaxes(axs[3][1])\n\n\n# Workclass\nwc_plot = sns.countplot(data['workclass'], ax=axs[0][0])\nwc_plot.set_xticklabels(wc_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Native country\nnc_plot = sns.countplot(data['native.country'], ax=axs[0][1])\nnc_plot.set_xticklabels(nc_plot.get_xticklabels(), rotation=72, ha=\"right\")\n\n# Education\norder=['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th', 'HS-grad',\n       'Some-college', 'Assoc-acdm', 'Assoc-voc', 'Bachelors', 'Masters', 'Prof-school', 'Doctorate']\ned_plot = sns.countplot(data['education'], order=order, ax=axs[1][0])\ned_plot.set_xticklabels(ed_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Marital status\nms_plot = sns.countplot(data['marital.status'], ax=axs[1][1])\nms_plot.set_xticklabels(ms_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Relationship\nrel_plot = sns.countplot(data['relationship'], ax=axs[2][0])\nrel_plot.set_xticklabels(rel_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Race\nrace_plot = sns.countplot(data['race'], ax=axs[2][1])\nrace_plot.set_xticklabels(race_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Occupation\nocc_plot = sns.countplot(data['occupation'], ax=axs[3][0])\nocc_plot.set_xticklabels(occ_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### How do features relate to one another?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24, 6))\nro = sns.countplot(data['occupation'], hue=data['sex'])\nro.set_xticklabels(ro.get_xticklabels(), rotation=30, ha=\"right\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 6))\nro = sns.countplot(data['education'], hue=data['sex'], order=order)\nro.set_xticklabels(ro.get_xticklabels(), rotation=40, ha=\"right\")\n#ro.set_yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['income'] = data['income'].map({'<=50K': 0, '>50K': 1}) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How do features relate to income?"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, nrows=4, figsize=(24, 28))\n#fig.delaxes(axs[3][1])\nplt.subplots_adjust(hspace=0.4)\n\n# education and income\nsns.catplot(x=\"education\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", order=order, ax=axs[0][0])\naxs[0][0].set_xticklabels(axs[0][0].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[0][0].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"workclass\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[0][1])\naxs[0][1].set_xticklabels(axs[0][1].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[0][1].set_ylabel(\">50K probability\")\n\n\nsns.catplot(x=\"relationship\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[1][0])\naxs[1][0].set_xticklabels(axs[1][0].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[1][0].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"marital.status\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[1][1])\naxs[1][1].set_xticklabels(axs[1][1].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[1][1].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"race\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[2][0])\naxs[2][0].set_xticklabels(axs[2][0].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[2][0].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"native.country\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[2][1])\naxs[2][1].set_xticklabels(axs[2][1].axes.get_xticklabels(), rotation=55, ha=\"right\")\naxs[2][1].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"sex\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[3][0])\naxs[3][0].set_xticklabels(axs[3][0].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[3][0].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"occupation\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[3][1])\naxs[3][1].set_xticklabels(axs[3][1].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[3][1].set_ylabel(\">50K probability\")\n\n#ed_income.set_ylabels(\">50K probability\")\n\nfor i in range(2,10):\n        plt.close(i)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Another way of visualizing this"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 6))\nsns.countplot(data['marital.status'], hue=data['income'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation\n\nNow the data needs to be prepared for prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['sex'] = data['sex'].map({'Male': 1, 'Female': 0}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['race'] = data['race'].map({'White': 1, 'Asian-Pac-Islander': 1, 'Black':0, 'Amer-Indian-Eskimo':0, 'Other':0}) \ndata['relationship'] = data['relationship'].map({'Not-in-family':0, 'Unmarried':0, 'Own-child':0, 'Other-relative':0, 'Husband':1, 'Wife':1})\ndata['marital.status'] = data['marital.status'].map({'Widowed':0, 'Divorced':0, 'Separated':0, 'Never-married':0, 'Married-civ-spouse':1, 'Married-AF-spouse':1, 'Married-spouse-absent':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.heatmap(data[['relationship', 'marital.status']].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"relationship and marital.status contain the same information now, so one of them can be removed"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['marital.status'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LabelEncoder can be used to transform the rest of the categorical features."},{"metadata":{"trusted":true},"cell_type":"code","source":"# data.drop(['workclass', 'education', 'occupation', 'native.country'], axis=1,inplace=True)\n\ndata.drop(['education'], axis=1,inplace=True)\n\nlabels = ['workclass', 'occupation', 'native.country']\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor l in labels:\n    data[l]=le.fit_transform(data[l])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset is ready."},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{},"cell_type":"markdown","source":"#### Importing the relevant libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, StratifiedKFold, learning_curve, train_test_split, KFold\n# from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Preparing data for training and testing with k-fold Cross-Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 42\n\nfrom sklearn.preprocessing import StandardScaler\n\nX = StandardScaler().fit_transform(data.loc[:, data.columns != 'income'])\nY = data['income']\n\n# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n\nkf = KFold(n_splits=10, shuffle=True, random_state=seed)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = len(data.loc[data.income==0])/len(data)\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One would get a 76% accuracy by just always predicting <=50k. Our model has to do better than that or it's not learning anything."},{"metadata":{},"cell_type":"markdown","source":"### Starting with some simple models"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, axs = plt.subplots(ncols=2, nrows=2, figsize=(24, 14))\n\n\nclassifiers = [\n    LogisticRegression(solver='newton-cg'),\n    KNeighborsClassifier(n_neighbors=17), # Some trial and error I don't show went into this hyperpa\n    LinearDiscriminantAnalysis(),\n    GaussianNB()\n]\n\n\nfor i, c in enumerate(classifiers):\n    \n    x_axs = i%2\n    y_axs = int(i/2)\n    # print(c)\n    print(type(c).__name__)\n    pred = cross_val_predict(c, X, Y, cv=kf)\n    print(\"Accuracy score:\", round(accuracy_score(Y, pred), 4), '\\n')\n\n    sns.heatmap(confusion_matrix(Y, pred), annot=True, fmt='g', ax=axs[y_axs][x_axs])\n    axs[y_axs][x_axs].set_xlabel('Predicted')\n    axs[y_axs][x_axs].set_ylabel('Real')\n    axs[y_axs][x_axs].set_title(type(c).__name__)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic regression performs best with 84.25% accuracy. \n"},{"metadata":{},"cell_type":"markdown","source":"### More complex models"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(action='ignore')\nfig, axs = plt.subplots(ncols=2, nrows=3, figsize=(24, 21))\n\nclassifiers = [\n    DecisionTreeClassifier(),\n    BaggingClassifier(),\n    RandomForestClassifier(),\n    ExtraTreesClassifier(),\n    GradientBoostingClassifier(),\n    AdaBoostClassifier()\n]\n\n\nfor i, c in enumerate(classifiers):\n    \n    x_axs = i%2\n    y_axs = int(i/2)\n    \n    # print(c)\n    print(type(c).__name__)\n    pred = cross_val_predict(c, X, Y, cv=kf)\n    print(\"Accuracy score:\", round(accuracy_score(Y, pred), 4), '\\n')\n    \n    sns.heatmap(confusion_matrix(Y, pred), annot=True, fmt='g', ax=axs[y_axs][x_axs])\n    axs[y_axs][x_axs].set_xlabel('Predicted')\n    axs[y_axs][x_axs].set_ylabel('Real')\n    axs[y_axs][x_axs].set_title(type(c).__name__)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient Boosting with no hyperparameter tuning gets to 86.58% accuracy. Not bad. Let's see if we can do better."},{"metadata":{},"cell_type":"markdown","source":"### Model Tuning"},{"metadata":{},"cell_type":"markdown","source":"GridSearchCV allows to try out a lot of hyperparameters at once."},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# This takes about 2 hours to run\nparams = {'max_depth': [5, 6, 7], \n         'n_estimators': [100, 150, 200],\n          'learning_rate': [0.1, 0.07, 0.05],\n          'max_features': ['sqrt', 'log2', 3, 4, 5]\n         }\n'''\n\n\nparams = {'max_depth': [6], \n         'n_estimators': [200],\n          'learning_rate': [0.07, 0.06],\n          'max_features': [3,4]\n         }\n\nclassifier = GradientBoostingClassifier()\n\ngrid = GridSearchCV(classifier, param_grid=params, cv=kf)\nsearch_result = grid.fit(X, Y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GridSearch results\nmeans = search_result.cv_results_['mean_test_score']\nparams = search_result.cv_results_['params']\nfor m, p in zip(means, params):\n    print(f\"{m} with: {p}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = np.argmax(means)\nbest_param = params[p]\n\nfinal_model = GradientBoostingClassifier(**best_param)\n\nprint(final_model)\npred = cross_val_predict(final_model, X, Y, cv=kf)\nprint(\"Accuracy score:\", round(accuracy_score(Y, pred), 4), '\\n')\n\nsns.heatmap(confusion_matrix(Y, pred), annot=True, fmt='g')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Final prediction accuracy: 87.35%"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}