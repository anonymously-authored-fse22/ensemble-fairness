{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi scoring Hyperparemeter Tuning using GCU(Generic classifier Utility)\n",
    "\n",
    "While finetuning hyperparameter for a specific scoring strategy there is a chances other scores dropping.\n",
    "e.g: Accuracy might be increasing but Precision or Recall or ROC dropping.\n",
    "In order to balance the lossess in other metrics we need multiple scoring evaluation in a single graph.\n",
    "\n",
    "For this I developed a <b><u>Generic classifier Utility</u></b> library which will display multiple scoring for different Tree based Boosting technique.\n",
    "i.e: A single library can accomodate multiple Tree Boosting technique along with multiple scoring.\n",
    "\n",
    "Source code available [here](https://github.com/KeshavShetty/kesh-utils/tree/master/KUtils/classifier) and PyPi package [here](https://pypi.org/project/kesh-utils/)\n",
    "\n",
    "For this demo I used Adult Census Income dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, make_scorer, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "import matplotlib.patches as patches\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "#from packages import *\n",
    "#from ml_fairness import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n",
      "Invalid requirement: '#'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels==0.10.0rc2 --pre  # Statsmodel has sme problem with factorial in latest lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kesh-utils\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/49/c98a0cd11386dddc8d0b7465e3e9aea45996f507be0f285b24a812484497/kesh-utils-0.4.9.tar.gz\n",
      "Building wheels for collected packages: kesh-utils\n",
      "  Building wheel for kesh-utils (setup.py): started\n",
      "  Building wheel for kesh-utils (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Usman Gohar\\AppData\\Local\\pip\\Cache\\wheels\\04\\4f\\12\\161e1106e024583ba970104a2f13a0030907b5d380395ca112\n",
      "Successfully built kesh-utils\n",
      "Installing collected packages: kesh-utils\n",
      "Successfully installed kesh-utils-0.4.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n"
     ]
    }
   ],
   "source": [
    "# Install the Library (Refer: https://pypi.org/project/kesh-utils/ )\n",
    "!pip install kesh-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the warnings if any\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "adult_income_df = pd.read_csv('../../Data/adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_income_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick known cleanup for this dataset\n",
    "adult_income_df['workclass']=adult_income_df['workclass'].replace('?','Unknown') # Treat ? workclass as unknown\n",
    "adult_income_df = adult_income_df[adult_income_df['occupation'] != '?'] # Remove rows with occupation =?\n",
    "adult_income_df['native.country']=adult_income_df['native.country'].replace('?', adult_income_df['native.country'].mode()[0]) # Replace ? with mode\n",
    "adult_income_df['fnlwgt']=np.log(adult_income_df['fnlwgt']) # Convert to antural log\n",
    "adult_income_df.loc[adult_income_df['native.country']!='United-States','native.country'] = 'non_usa' # Two many category level, convert just US and Non-US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use Label encoder for all categorical variables\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# encode categorical variables using Label Encoder\n",
    "# select all categorical variables\n",
    "df_categorical = adult_income_df.select_dtypes(include=['object'])\n",
    "df_categorical.head()\n",
    "\n",
    "# apply Label encoder to df_categorical\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_categorical = df_categorical.apply(le.fit_transform)\n",
    "df_categorical.head()\n",
    "\n",
    "# concat df_categorical with original df\n",
    "adult_income_df = adult_income_df.drop(df_categorical.columns, axis=1)\n",
    "adult_income_df = pd.concat([adult_income_df, df_categorical], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numerical features using StandardScalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "numerical_column_names = ['age','fnlwgt','education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "adult_income_df[numerical_column_names] = scaler.fit_transform(\n",
    "    adult_income_df[numerical_column_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.320351</td>\n",
       "      <td>-0.298396</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>10.519126</td>\n",
       "      <td>-1.914806</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.185882</td>\n",
       "      <td>-0.211235</td>\n",
       "      <td>-2.392386</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>9.395006</td>\n",
       "      <td>-0.079207</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194878</td>\n",
       "      <td>0.796972</td>\n",
       "      <td>-0.050856</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>9.395006</td>\n",
       "      <td>-0.079207</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.338739</td>\n",
       "      <td>0.480345</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>9.074533</td>\n",
       "      <td>0.337974</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.033815</td>\n",
       "      <td>-0.099279</td>\n",
       "      <td>-1.611876</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>9.074533</td>\n",
       "      <td>-0.079207</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "1  3.320351 -0.298396      -0.441111     -0.147516     10.519126   \n",
       "3  1.185882 -0.211235      -2.392386     -0.147516      9.395006   \n",
       "4  0.194878  0.796972      -0.050856     -0.147516      9.395006   \n",
       "5 -0.338739  0.480345      -0.441111     -0.147516      9.074533   \n",
       "6 -0.033815 -0.099279      -1.611876     -0.147516      9.074533   \n",
       "\n",
       "   hours.per.week  workclass  education  marital.status  occupation  \\\n",
       "1       -1.914806          2         11               6           3   \n",
       "3       -0.079207          2          5               0           6   \n",
       "4       -0.079207          2         15               5           9   \n",
       "5        0.337974          2         11               0           7   \n",
       "6       -0.079207          2          0               5           0   \n",
       "\n",
       "   relationship  race  sex  native.country  income  \n",
       "1             1     4    0               0       0  \n",
       "3             4     4    0               0       0  \n",
       "4             3     4    0               0       0  \n",
       "5             4     4    0               0       0  \n",
       "6             4     4    1               0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final cleaned dataset \n",
    "adult_income_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for model building and evaluation\n",
    "X = adult_income_df.drop('income', axis=1)\n",
    "y = adult_income_df['income'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCU in Action\n",
    "### The method used is KUtils.classifier.single_hyperparameter_multiple_scoring_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the custom library\n",
    "from KUtils.classifier import generic_classifier_utils as gcu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier\n",
    "- XGBClassifier\n",
    "- LGBMClassifier\n",
    "\n",
    "For scoring we will use\n",
    "\n",
    "model_scoring = {'F1': make_scorer(f1_score),\n",
    "    'AUC': make_scorer(roc_auc_score),\n",
    "    'Accuracy': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "At a time you can send single hyper parameter and multiple scoring for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DecisionTreeClassifier() and Hyperparameter 'max_depth' with range range(3, 21, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scores = gcu.single_hyperparameter_multiple_scoring_tuning(\n",
    "    X_train, y_train,\n",
    "    cv_folds=5, \n",
    "    hyper_parameter_name='max_depth',\n",
    "    hyper_parameter_range = range(3, 21, 3),\n",
    "    model_scoring = {'F1': make_scorer(f1_score),\n",
    "                     'AUC': make_scorer(roc_auc_score),\n",
    "                     'Accuracy': make_scorer(accuracy_score)        #  'Accuracy': make_scorer(accuracy_score),\n",
    "                    },\n",
    "    refit='AUC',\n",
    "    classifier_algo=DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a single chart you can see which scoring is improving and which one deteriorating\n",
    "\n",
    "In the above chart at max_depth=9 all three (AUC, Accuracy, F1) are at its best**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RandonForestClassifier() and Hyperparameter 'n_estimator' with range range(5, 200, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scores = gcu.single_hyperparameter_multiple_scoring_tuning(\n",
    "    X_train, y_train,\n",
    "    cv_folds=10, \n",
    "    hyper_parameter_name='n_estimators',\n",
    "    hyper_parameter_range =range(5, 200, 25),   \n",
    "    model_scoring = {'F1': make_scorer(f1_score),\n",
    "                     'AUC': make_scorer(roc_auc_score),\n",
    "                     'Accuracy': make_scorer(accuracy_score)        #  'Accuracy': make_scorer(accuracy_score),\n",
    "                    },\n",
    "    refit='AUC',\n",
    "    classifier_algo=RandomForestClassifier(max_depth=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. XGBClassifier() and Hyperparameter 'learning_rate' with values [0.1, 0.2, 0.3, 0.4, 0.5, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "scores = gcu.single_hyperparameter_multiple_scoring_tuning(\n",
    "    X_train, y_train,\n",
    "    cv_folds=10, \n",
    "    hyper_parameter_name='learning_rate',\n",
    "    hyper_parameter_range = [0.1, 0.2, 0.3, 0.4, 0.5, 0.9],\n",
    "    model_scoring = {'F1': make_scorer(f1_score),\n",
    "                     'AUC': make_scorer(roc_auc_score),\n",
    "                     'Accuracy': make_scorer(accuracy_score)        #  'Accuracy': make_scorer(accuracy_score),\n",
    "                    },\n",
    "    refit='AUC',\n",
    "    classifier_algo=XGBClassifier(objective= 'binary:logistic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy best at learning rate 0.3, however F1 best at 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. lightgbm - LGBMClassifier() and Hyperparameter 'num_leaves' with values [2, 5, 10, 50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "scores = gcu.single_hyperparameter_multiple_scoring_tuning(\n",
    "    X_train, y_train,\n",
    "    cv_folds=10,\n",
    "    hyper_parameter_name='num_leaves',\n",
    "    hyper_parameter_range = [2, 5, 10, 50, 100, 200],\n",
    "    model_scoring = {'F1': make_scorer(f1_score),\n",
    "                     'AUC': make_scorer(roc_auc_score),\n",
    "                     'Accuracy': make_scorer(accuracy_score)        #  'Accuracy': make_scorer(accuracy_score),\n",
    "                    },\n",
    "    refit='Accuracy',\n",
    "    classifier_algo=lgb.LGBMClassifier(n_jobs=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will stop here. This is just a demo how to use the library for using multiple Classifer with different scoring.\n",
    "\n",
    "#### You can try to finetune for different classifier with different scoring and different hyperparamaters.\n",
    "\n",
    "### Check other methods in the library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upvote if you liked the Kernel. Leave comments if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This DataFrame is created to stock differents models and fair metrics that we produce in this notebook\n",
    "algo_metrics = pd.DataFrame(columns=['model', 'fair_metrics', 'prediction', 'probs'])\n",
    "\n",
    "def add_to_df_algo_metrics(algo_metrics, model, fair_metrics, preds, probs, name):\n",
    "    return algo_metrics.append(pd.DataFrame(data=[[model, fair_metrics, preds, probs]], columns=['model', 'fair_metrics', 'prediction', 'probs'], index=[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_metrics(dataset, pred, pred_is_dataset=False):\n",
    "    if pred_is_dataset:\n",
    "        dataset_pred = pred\n",
    "    else:\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = pred\n",
    "    \n",
    "    cols = ['statistical_parity_difference', 'equal_opportunity_difference', 'average_abs_odds_difference',  'disparate_impact', 'theil_index']\n",
    "    obj_fairness = [[0,0,0,1,0]]\n",
    "    \n",
    "    fair_metrics = pd.DataFrame(data=obj_fairness, index=['objective'], columns=cols)\n",
    "    \n",
    "    for attr in dataset_pred.protected_attribute_names:\n",
    "        idx = dataset_pred.protected_attribute_names.index(attr)\n",
    "        privileged_groups =  [{attr:dataset_pred.privileged_protected_attributes[idx][0]}] \n",
    "        unprivileged_groups = [{attr:dataset_pred.unprivileged_protected_attributes[idx][0]}] \n",
    "        \n",
    "        classified_metric = ClassificationMetric(dataset, \n",
    "                                                     dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        metric_pred = BinaryLabelDatasetMetric(dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        acc = classified_metric.accuracy()\n",
    "\n",
    "        row = pd.DataFrame([[metric_pred.mean_difference(),\n",
    "                                classified_metric.equal_opportunity_difference(),\n",
    "                                classified_metric.average_abs_odds_difference(),\n",
    "                                metric_pred.disparate_impact(),\n",
    "                                classified_metric.theil_index()]],\n",
    "                           columns  = cols,\n",
    "                           index = [attr]\n",
    "                          )\n",
    "        fair_metrics = fair_metrics.append(row)    \n",
    "    \n",
    "    fair_metrics = fair_metrics.replace([-np.inf, np.inf], 2)\n",
    "        \n",
    "    return fair_metrics\n",
    "\n",
    "def plot_fair_metrics(fair_metrics):\n",
    "    fig, ax = plt.subplots(figsize=(20,4), ncols=5, nrows=1)\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        left    =  0.125, \n",
    "        bottom  =  0.1, \n",
    "        right   =  0.9, \n",
    "        top     =  0.9, \n",
    "        wspace  =  .5, \n",
    "        hspace  =  1.1\n",
    "    )\n",
    "\n",
    "    y_title_margin = 1.2\n",
    "\n",
    "    plt.suptitle(\"Fairness metrics\", y = 1.09, fontsize=20)\n",
    "    sns.set(style=\"dark\")\n",
    "\n",
    "    cols = fair_metrics.columns.values\n",
    "    obj = fair_metrics.loc['objective']\n",
    "    size_rect = [0.2,0.2,0.2,0.4,0.25]\n",
    "    rect = [-0.1,-0.1,-0.1,0.8,0]\n",
    "    bottom = [-1,-1,-1,0,0]\n",
    "    top = [1,1,1,2,1]\n",
    "    bound = [[-0.1,0.1],[-0.1,0.1],[-0.1,0.1],[0.8,1.2],[0,0.25]]\n",
    "\n",
    "    display(Markdown(\"### Check bias metrics :\"))\n",
    "    display(Markdown(\"A model can be considered bias if just one of these five metrics show that this model is biased.\"))\n",
    "    for attr in fair_metrics.index[1:len(fair_metrics)].values:\n",
    "        display(Markdown(\"#### For the %s attribute :\"%attr))\n",
    "        check = [bound[i][0] < fair_metrics.loc[attr][i] < bound[i][1] for i in range(0,5)]\n",
    "        display(Markdown(\"With default thresholds, bias against unprivileged group detected in **%d** out of 5 metrics\"%(5 - sum(check))))\n",
    "\n",
    "    for i in range(0,5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        ax = sns.barplot(x=fair_metrics.index[1:len(fair_metrics)], y=fair_metrics.iloc[1:len(fair_metrics)][cols[i]])\n",
    "        \n",
    "        for j in range(0,len(fair_metrics)-1):\n",
    "            a, val = ax.patches[j], fair_metrics.iloc[j+1][cols[i]]\n",
    "            marg = -0.2 if val < 0 else 0.1\n",
    "            ax.text(a.get_x()+a.get_width()/5, a.get_y()+a.get_height()+marg, round(val, 3), fontsize=15,color='black')\n",
    "\n",
    "        plt.ylim(bottom[i], top[i])\n",
    "        plt.setp(ax.patches, linewidth=0)\n",
    "        ax.add_patch(patches.Rectangle((-5,rect[i]), 10, size_rect[i], alpha=0.3, facecolor=\"green\", linewidth=1, linestyle='solid'))\n",
    "        plt.axhline(obj[i], color='black', alpha=0.3)\n",
    "        plt.title(cols[i])\n",
    "        ax.set_ylabel('')    \n",
    "        ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fair_metrics_and_plot(data, model, plot=False, model_aif=False):\n",
    "    pred = model.predict(data).labels if model_aif else model.predict(data.features)\n",
    "    # fair_metrics function available in the metrics.py file\n",
    "    fair = fair_metrics(data, pred)\n",
    "\n",
    "    if plot:\n",
    "        # plot_fair_metrics function available in the visualisations.py file\n",
    "        # The visualisation of this function is inspired by the dashboard on the demo of IBM aif360 \n",
    "        plot_fair_metrics(fair)\n",
    "        display(fair)\n",
    "    \n",
    "    return fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.320351</td>\n",
       "      <td>-0.298396</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>10.519126</td>\n",
       "      <td>-1.914806</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.185882</td>\n",
       "      <td>-0.211235</td>\n",
       "      <td>-2.392386</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>9.395006</td>\n",
       "      <td>-0.079207</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194878</td>\n",
       "      <td>0.796972</td>\n",
       "      <td>-0.050856</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>9.395006</td>\n",
       "      <td>-0.079207</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.338739</td>\n",
       "      <td>0.480345</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>9.074533</td>\n",
       "      <td>0.337974</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.033815</td>\n",
       "      <td>-0.099279</td>\n",
       "      <td>-1.611876</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>9.074533</td>\n",
       "      <td>-0.079207</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>-1.253512</td>\n",
       "      <td>1.049090</td>\n",
       "      <td>-0.050856</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>-0.219179</td>\n",
       "      <td>-0.079207</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>-0.872356</td>\n",
       "      <td>0.752134</td>\n",
       "      <td>0.729654</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>-0.219179</td>\n",
       "      <td>-0.246080</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0.118647</td>\n",
       "      <td>-0.059946</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>-0.219179</td>\n",
       "      <td>-0.079207</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>1.490806</td>\n",
       "      <td>-0.085522</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>-0.219179</td>\n",
       "      <td>-0.079207</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>-1.253512</td>\n",
       "      <td>0.363461</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-0.147516</td>\n",
       "      <td>-0.219179</td>\n",
       "      <td>-1.747934</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30718 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "1      3.320351 -0.298396      -0.441111     -0.147516     10.519126   \n",
       "3      1.185882 -0.211235      -2.392386     -0.147516      9.395006   \n",
       "4      0.194878  0.796972      -0.050856     -0.147516      9.395006   \n",
       "5     -0.338739  0.480345      -0.441111     -0.147516      9.074533   \n",
       "6     -0.033815 -0.099279      -1.611876     -0.147516      9.074533   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "32556 -1.253512  1.049090      -0.050856     -0.147516     -0.219179   \n",
       "32557 -0.872356  0.752134       0.729654     -0.147516     -0.219179   \n",
       "32558  0.118647 -0.059946      -0.441111     -0.147516     -0.219179   \n",
       "32559  1.490806 -0.085522      -0.441111     -0.147516     -0.219179   \n",
       "32560 -1.253512  0.363461      -0.441111     -0.147516     -0.219179   \n",
       "\n",
       "       hours.per.week  workclass  education  marital.status  occupation  \\\n",
       "1           -1.914806          2         11               6           3   \n",
       "3           -0.079207          2          5               0           6   \n",
       "4           -0.079207          2         15               5           9   \n",
       "5            0.337974          2         11               0           7   \n",
       "6           -0.079207          2          0               5           0   \n",
       "...               ...        ...        ...             ...         ...   \n",
       "32556       -0.079207          2         15               4          10   \n",
       "32557       -0.246080          2          7               2          12   \n",
       "32558       -0.079207          2         11               2           6   \n",
       "32559       -0.079207          2         11               6           0   \n",
       "32560       -1.747934          2         11               4           0   \n",
       "\n",
       "       relationship  race  sex  native.country  income  \n",
       "1                 1     4    0               0       0  \n",
       "3                 4     4    0               0       0  \n",
       "4                 3     4    0               0       0  \n",
       "5                 4     4    0               0       0  \n",
       "6                 4     4    1               0       0  \n",
       "...             ...   ...  ...             ...     ...  \n",
       "32556             1     4    1               0       0  \n",
       "32557             5     4    0               0       0  \n",
       "32558             0     4    1               0       1  \n",
       "32559             4     4    0               0       0  \n",
       "32560             3     4    1               0       0  \n",
       "\n",
       "[30718 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_income_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X)\n",
    "\n",
    "\n",
    "#combine_final = [train_df, test_df]\n",
    "#result = pd.concat(combine_final)\n",
    "#print(result.ifany())\n",
    "#print(result)\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "dataset_orig = StandardDataset(adult_income_df,\n",
    "                                  label_name='income',\n",
    "                                  protected_attribute_names=['sex'],\n",
    "                                  favorable_classes=[1],\n",
    "                                  privileged_classes=[[1]])\n",
    "\n",
    "#metric_orig_train = BinaryLabelDatasetMetric(dataset_orig, \n",
    "#                                             unprivileged_groups=unprivileged_groups,\n",
    "#                                             privileged_groups=privileged_groups)\n",
    "#display(Markdown(\"#### Original training dataset\"))\n",
    "#print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.200292\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "nb_fname = ipynbname.name()\n",
    "nb_path = ipynbname.path()\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "data_orig_train, data_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "X_train = data_orig_train.features\n",
    "y_train = data_orig_train.labels.ravel()\n",
    "\n",
    "X_test = data_orig_test.features\n",
    "y_test = data_orig_test.labels.ravel()\n",
    "num_estimators = 100\n",
    "\n",
    "model = XGBClassifier(n_estimators= 1,objective= 'binary:logistic', learning_rate =0.3)\n",
    "\n",
    "mdl = model.fit(X_train, y_train)\n",
    "with open('../../Results/XGBoost/' + nb_fname + '.pkl', 'wb') as f:\n",
    "        pickle.dump(mdl, f)\n",
    "\n",
    "with open('../../Results/XGBoost/' + nb_fname + '_Train' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_train, f) \n",
    "    \n",
    "with open('../../Results/XGBoost/' + nb_fname + '_Test' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_test, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "final_metrics = []\n",
    "accuracy = []\n",
    "f1= []\n",
    "\n",
    "for i in range(1,num_estimators+1):\n",
    "    \n",
    "    model = XGBClassifier(n_estimators= i, objective= 'binary:logistic', learning_rate =0.3)\n",
    "    mdl = model.fit(X_train, y_train)\n",
    "    yy = mdl.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, yy))\n",
    "    f1.append(f1_score(y_test, yy))\n",
    "    fair = get_fair_metrics_and_plot(data_orig_test, mdl)                           \n",
    "    fair_list = fair.iloc[1].tolist()\n",
    "    fair_list.insert(0, i)\n",
    "    final_metrics.append(fair_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>...</th>\n",
       "      <th>T90</th>\n",
       "      <th>T91</th>\n",
       "      <th>T92</th>\n",
       "      <th>T93</th>\n",
       "      <th>T94</th>\n",
       "      <th>T95</th>\n",
       "      <th>T96</th>\n",
       "      <th>T97</th>\n",
       "      <th>T98</th>\n",
       "      <th>T99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.866645</td>\n",
       "      <td>0.853733</td>\n",
       "      <td>0.855360</td>\n",
       "      <td>0.856120</td>\n",
       "      <td>0.857096</td>\n",
       "      <td>0.857856</td>\n",
       "      <td>0.860135</td>\n",
       "      <td>0.861003</td>\n",
       "      <td>0.861979</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867730</td>\n",
       "      <td>0.867730</td>\n",
       "      <td>0.867839</td>\n",
       "      <td>0.867405</td>\n",
       "      <td>0.867296</td>\n",
       "      <td>0.866862</td>\n",
       "      <td>0.866319</td>\n",
       "      <td>0.866536</td>\n",
       "      <td>0.866753</td>\n",
       "      <td>0.866645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.712649</td>\n",
       "      <td>0.657172</td>\n",
       "      <td>0.655467</td>\n",
       "      <td>0.658775</td>\n",
       "      <td>0.660829</td>\n",
       "      <td>0.663585</td>\n",
       "      <td>0.671090</td>\n",
       "      <td>0.673464</td>\n",
       "      <td>0.675013</td>\n",
       "      <td>0.698906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712974</td>\n",
       "      <td>0.713379</td>\n",
       "      <td>0.713950</td>\n",
       "      <td>0.712876</td>\n",
       "      <td>0.712573</td>\n",
       "      <td>0.711498</td>\n",
       "      <td>0.710798</td>\n",
       "      <td>0.712079</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.712649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <td>-0.188499</td>\n",
       "      <td>-0.113481</td>\n",
       "      <td>-0.151758</td>\n",
       "      <td>-0.137031</td>\n",
       "      <td>-0.147017</td>\n",
       "      <td>-0.138807</td>\n",
       "      <td>-0.147283</td>\n",
       "      <td>-0.142441</td>\n",
       "      <td>-0.144990</td>\n",
       "      <td>-0.179575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184705</td>\n",
       "      <td>-0.185165</td>\n",
       "      <td>-0.185963</td>\n",
       "      <td>-0.185644</td>\n",
       "      <td>-0.186979</td>\n",
       "      <td>-0.188155</td>\n",
       "      <td>-0.188774</td>\n",
       "      <td>-0.189195</td>\n",
       "      <td>-0.189195</td>\n",
       "      <td>-0.188499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <td>-0.022432</td>\n",
       "      <td>0.128475</td>\n",
       "      <td>-0.047136</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>-0.010563</td>\n",
       "      <td>0.025373</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>0.018016</td>\n",
       "      <td>0.010652</td>\n",
       "      <td>-0.056103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013673</td>\n",
       "      <td>-0.015196</td>\n",
       "      <td>-0.016719</td>\n",
       "      <td>-0.018878</td>\n",
       "      <td>-0.025735</td>\n",
       "      <td>-0.038941</td>\n",
       "      <td>-0.039449</td>\n",
       "      <td>-0.031956</td>\n",
       "      <td>-0.028781</td>\n",
       "      <td>-0.022432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_abs_odds_difference</th>\n",
       "      <td>0.048587</td>\n",
       "      <td>0.078961</td>\n",
       "      <td>0.047826</td>\n",
       "      <td>0.032606</td>\n",
       "      <td>0.028811</td>\n",
       "      <td>0.033695</td>\n",
       "      <td>0.023287</td>\n",
       "      <td>0.030016</td>\n",
       "      <td>0.027122</td>\n",
       "      <td>0.060549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042796</td>\n",
       "      <td>0.043601</td>\n",
       "      <td>0.044595</td>\n",
       "      <td>0.045486</td>\n",
       "      <td>0.049220</td>\n",
       "      <td>0.055634</td>\n",
       "      <td>0.056280</td>\n",
       "      <td>0.053116</td>\n",
       "      <td>0.051718</td>\n",
       "      <td>0.048587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disparate_impact</th>\n",
       "      <td>-1.144513</td>\n",
       "      <td>-0.750015</td>\n",
       "      <td>-1.165519</td>\n",
       "      <td>-0.993335</td>\n",
       "      <td>-1.098828</td>\n",
       "      <td>-1.004127</td>\n",
       "      <td>-1.067321</td>\n",
       "      <td>-1.015212</td>\n",
       "      <td>-1.048543</td>\n",
       "      <td>-1.207883</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.135936</td>\n",
       "      <td>-1.134998</td>\n",
       "      <td>-1.137919</td>\n",
       "      <td>-1.136752</td>\n",
       "      <td>-1.149570</td>\n",
       "      <td>-1.161941</td>\n",
       "      <td>-1.161489</td>\n",
       "      <td>-1.154963</td>\n",
       "      <td>-1.154963</td>\n",
       "      <td>-1.144513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil_index</th>\n",
       "      <td>0.105018</td>\n",
       "      <td>0.129112</td>\n",
       "      <td>0.130559</td>\n",
       "      <td>0.129274</td>\n",
       "      <td>0.128669</td>\n",
       "      <td>0.127639</td>\n",
       "      <td>0.124889</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>0.123722</td>\n",
       "      <td>0.112659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105514</td>\n",
       "      <td>0.105259</td>\n",
       "      <td>0.104970</td>\n",
       "      <td>0.105366</td>\n",
       "      <td>0.105486</td>\n",
       "      <td>0.105883</td>\n",
       "      <td>0.105974</td>\n",
       "      <td>0.105309</td>\n",
       "      <td>0.105153</td>\n",
       "      <td>0.105018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               classifier        T0        T1        T2  \\\n",
       "accuracy                         0.866645  0.853733  0.855360  0.856120   \n",
       "f1                               0.712649  0.657172  0.655467  0.658775   \n",
       "statistical_parity_difference   -0.188499 -0.113481 -0.151758 -0.137031   \n",
       "equal_opportunity_difference    -0.022432  0.128475 -0.047136  0.024100   \n",
       "average_abs_odds_difference      0.048587  0.078961  0.047826  0.032606   \n",
       "disparate_impact                -1.144513 -0.750015 -1.165519 -0.993335   \n",
       "theil_index                      0.105018  0.129112  0.130559  0.129274   \n",
       "\n",
       "                                     T3        T4        T5        T6  \\\n",
       "accuracy                       0.857096  0.857856  0.860135  0.861003   \n",
       "f1                             0.660829  0.663585  0.671090  0.673464   \n",
       "statistical_parity_difference -0.147017 -0.138807 -0.147283 -0.142441   \n",
       "equal_opportunity_difference  -0.010563  0.025373 -0.001031  0.018016   \n",
       "average_abs_odds_difference    0.028811  0.033695  0.023287  0.030016   \n",
       "disparate_impact              -1.098828 -1.004127 -1.067321 -1.015212   \n",
       "theil_index                    0.128669  0.127639  0.124889  0.124074   \n",
       "\n",
       "                                     T7        T8  ...       T90       T91  \\\n",
       "accuracy                       0.861979  0.865560  ...  0.867730  0.867730   \n",
       "f1                             0.675013  0.698906  ...  0.712974  0.713379   \n",
       "statistical_parity_difference -0.144990 -0.179575  ... -0.184705 -0.185165   \n",
       "equal_opportunity_difference   0.010652 -0.056103  ... -0.013673 -0.015196   \n",
       "average_abs_odds_difference    0.027122  0.060549  ...  0.042796  0.043601   \n",
       "disparate_impact              -1.048543 -1.207883  ... -1.135936 -1.134998   \n",
       "theil_index                    0.123722  0.112659  ...  0.105514  0.105259   \n",
       "\n",
       "                                    T92       T93       T94       T95  \\\n",
       "accuracy                       0.867839  0.867405  0.867296  0.866862   \n",
       "f1                             0.713950  0.712876  0.712573  0.711498   \n",
       "statistical_parity_difference -0.185963 -0.185644 -0.186979 -0.188155   \n",
       "equal_opportunity_difference  -0.016719 -0.018878 -0.025735 -0.038941   \n",
       "average_abs_odds_difference    0.044595  0.045486  0.049220  0.055634   \n",
       "disparate_impact              -1.137919 -1.136752 -1.149570 -1.161941   \n",
       "theil_index                    0.104970  0.105366  0.105486  0.105883   \n",
       "\n",
       "                                    T96       T97       T98       T99  \n",
       "accuracy                       0.866319  0.866536  0.866753  0.866645  \n",
       "f1                             0.710798  0.712079  0.712547  0.712649  \n",
       "statistical_parity_difference -0.188774 -0.189195 -0.189195 -0.188499  \n",
       "equal_opportunity_difference  -0.039449 -0.031956 -0.028781 -0.022432  \n",
       "average_abs_odds_difference    0.056280  0.053116  0.051718  0.048587  \n",
       "disparate_impact              -1.161489 -1.154963 -1.154963 -1.144513  \n",
       "theil_index                    0.105974  0.105309  0.105153  0.105018  \n",
       "\n",
       "[7 rows x 101 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "final_result = pd.DataFrame(final_metrics)\n",
    "final_result[4] = np.log(final_result[4])\n",
    "final_result = final_result.transpose()\n",
    "final_result.loc[0] = f1  # add f1 and acc to df\n",
    "acc = pd.DataFrame(accuracy).transpose()\n",
    "acc = acc.rename(index={0: 'accuracy'})\n",
    "final_result = pd.concat([acc,final_result])\n",
    "final_result = final_result.rename(index={0: 'f1', 1: 'statistical_parity_difference', 2: 'equal_opportunity_difference', 3: 'average_abs_odds_difference', 4: 'disparate_impact', 5: 'theil_index'})\n",
    "final_result.columns = ['T' + str(col) for col in final_result.columns]\n",
    "final_result.insert(0, \"classifier\", final_result['T' + str(num_estimators - 1)])   ##Add final metrics add the beginning of the df\n",
    "final_result.to_csv('../../Results/XGBoost/' + nb_fname + '.csv')\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
