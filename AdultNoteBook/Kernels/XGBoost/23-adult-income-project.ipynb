{"cells":[{"metadata":{},"cell_type":"markdown","source":"Import all needed libraries as numpy,pandas and sklearn etc.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom numpy import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read our Adult Census Income data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/adult-census-income/adult.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do Data Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# The amount of rows and columns od data-set\nprint(df.shape)\ndf.count()[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Information about data-set\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Before dropping the duplicate Rows\nprint(df.shape)\n#After Dropping the duplicate Rows\ndf = df.drop_duplicates(keep = 'first')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the null values in the columns\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Code will Count the occuring of the '?' in all the columns\ndef check(x):\n    return sum(x=='?')\ndf.apply(check)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the rows whose workclass is '?' \ndf = df[df.workclass != '?']\n\ndf['workclass'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the rows whose occupation is '?' \ndf = df[df.occupation != '?']\n\ndf['occupation'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the rows whose country is '?' \ndf = df[df['native.country'] != '?']\n\ndf['native.country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for cleanliness\ndf.apply(check)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Counting the values of column \"sex\"\ndf['sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing the plot\nsns.countplot(df['sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing the age histogram\ndf['age'].hist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing the sex histogram where sex = 'female'\n\ndf[df['sex']=='Female'].age.hist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing the age mean where sex = 'female'\ndf[df['sex']=='Female'].age.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing the sex histogram where sex = 'male'\ndf[df['sex']=='Male'].age.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing the age mean where sex = 'male'\ndf[df['sex']=='Male'].age.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This distribution plot shows the distribution of Age of people across the Data Set\nplt.rcParams['figure.figsize'] = [12, 8]\nsns.set(style = 'whitegrid')\n\nsns.distplot(df['age'], bins = 90, color = 'mediumslateblue')\nplt.ylabel(\"Distribution\", fontsize = 15)\nplt.xlabel(\"Age\", fontsize = 15)\nplt.margins(x = 0)\n\nprint (\"The maximum age is\", df['age'].max())\nprint (\"The minimum age is\", df['age'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of age according to their workclass\nfig=sns.FacetGrid(df,hue='workclass',aspect=3)\nfig.map(sns.kdeplot,'age',shade=True)\na=df['age'].max()\nfig.set(xlim=(0,a))\nfig.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['native.country']!='United-States','native.country'] = 'non_usa'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating different plots\nfig, ((a,b),(c,d),(e,f)) = plt.subplots(3,2,figsize=(15,20))\nplt.xticks(rotation=45)\nsns.countplot(df['workclass'],hue=df['income'],ax=f)\nsns.countplot(df['relationship'],hue=df['income'],ax=b)\nsns.countplot(df['marital.status'],hue=df['income'],ax=c)\nsns.countplot(df['race'],hue=df['income'],ax=d)\nsns.countplot(df['sex'],hue=df['income'],ax=e)\nsns.countplot(df['native.country'],hue=df['income'],ax=a)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing amount of hours per week according to their workclass\ndf.groupby(by='workclass')['hours.per.week'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This heatmap shows the Correlation between the different variables\nplt.rcParams['figure.figsize'] = [10,7]\nsns.heatmap(df.corr(), annot = True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This shows the hours per week according to the education of the person\nsns.set(rc={'figure.figsize':(12,8)})\nsns_grad = sns.barplot(x = df['education'], y = df['hours.per.week'], data = df)\nplt.setp(sns_grad.get_xticklabels(), rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This bar graph shows the difference of hours per week between male and female \nsns.set(style = 'whitegrid', rc={'figure.figsize':(8,6)})\nsns.barplot(x = df['sex'], y = df['hours.per.week'], data = df,\n            estimator = mean, hue = 'sex', palette = 'winter');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the income column into Numerical Value\ndf['income'] = df['income'].map({'<=50K':0, '>50K':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the Categorical Values to Numerical values using the Label Encoder\nfrom sklearn.preprocessing import LabelEncoder\n\ncategorical_features = list(df.select_dtypes(include=['object']).columns)\nlabel_encoder_feat = {}\nfor i, feature in enumerate(categorical_features):\n    label_encoder_feat[feature] = LabelEncoder()\n    df[feature] = label_encoder_feat[feature].fit_transform(df[feature])\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split your data into train and test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data set into train and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(df[['age', 'workclass', 'education','marital.status', 'occupation', 'relationship', 'race',\n       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country']],df['income'],test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing train and test size\nprint (\"Train data set size : \", X_train.shape)\nprint (\"Test data set size : \", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the feature importances using the Boosted Gradient Descent\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\n\n# Training the model\nmodel = XGBClassifier()\nmodel_importance = model.fit(X_train, y_train)\n\n# Plotting the Feature importance bar graph\nplt.rcParams['figure.figsize'] = [14,12]\nsns.set(style = 'darkgrid')\nplot_importance(model_importance);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select algorithms","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the required libraries\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport warnings; warnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model 1\nNB = BernoulliNB(alpha = 0.3)\nmodel_1 = NB.fit(X_train, y_train)\n\n# Predictions\npred_1 = model_1.predict(X_test)\n\nprint(\"Accuracy for BerNoulliNB Model: %.2f\" % (accuracy_score(y_test, pred_1) * 100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model_2\nnbc = GaussianNB()\nmodel_2 = nbc.fit(X_train, y_train)\n\n# Predictions\npred_2 = model_2.predict(X_test)\nprint(\"Accuracy for Naive Bayes Model: %.2f\" % (accuracy_score(y_test, pred_2) * 100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model_3\nclf5 = MLPClassifier()\nmodel_3 = clf5.fit(X_train, y_train)\n\n# Predictions\npred_3 = model_3.predict(X_test)\nprint(\"Accuracy for ANN Model: %.2f\" % (accuracy_score(y_test, pred_3) * 100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model_4\nlogistic = LogisticRegression(C = 0.5, max_iter = 500)\nmodel_4 = logistic.fit(X_train, y_train)\n\n# Predictions\npred_4 = model_4.predict(X_test)\nprint(\"Accuracy for Logistic Regression Model: %.2f\" % (accuracy_score(y_test, pred_4) * 100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model_5\ndrugTree = DecisionTreeClassifier(criterion=\"gini\")\nmodel_5 = drugTree.fit(X_train, y_train)\n\n# Predictions\npred_5 = model_5.predict(X_test)\nprint(\"Accuracy for Decision Tree Model: %.2f\" % (accuracy_score(y_test, pred_5) * 100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model_6\nR_forest = RandomForestClassifier(n_estimators = 200)\nmodel_6 = R_forest.fit(X_train, y_train)\n\n# Predictions\npred_6 = model_6.predict(X_test)\nprint(\"Accuracy for Random Forest Model: %.2f\" % (accuracy_score(y_test, pred_6) * 100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model 7\nboosted_gd = xgb.XGBClassifier(learning_rate = 0.35, n_estimator = 200)\nmodel_7 = boosted_gd.fit(X_train, y_train)\n\n# Predictions\npred_7 = model_7.predict(X_test)\n\nprint(\"Accuracy for XGB Model: %.2f\" % (accuracy_score(y_test, pred_7) * 100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_pred = [pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7]\nmodel_names = [ \"Bernoulli NB\",\"Naive Bayes\",\"ANN\",\"Logistic Regression\",\"Decision Tree\" ,\"Random Forest Classifier\", \"Boosted Gradient Descent\"]\n\nfor i, predictions in enumerate(list_pred) :\n    print (\"Classification Report of \", model_names[i])\n    print ()\n    print (classification_report(y_test, predictions, target_names = [\"<=50K\", \">50K\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, pred in enumerate(list_pred) :\n    print (\"The Confusion Matrix of : \", model_names[i])\n    print (pd.DataFrame(confusion_matrix(y_test, pred)))\n    print ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC Curve for the classification models\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\nmodels = [model_1, model_2, model_3, model_4, model_5, model_6, model_7]\n\n# Setting the parameters for the ROC Curve\nplt.rcParams['figure.figsize'] = [10,8]\nplt.style.use(\"bmh\")\n\ncolor = ['red', 'blue', 'green', 'fuchsia', 'cyan','yellow','brown']\nplt.title(\"ROC CURVE\", fontsize = 15)\nplt.xlabel(\"Specificity\", fontsize = 15)\nplt.ylabel(\"Sensitivity\", fontsize = 15)\ni = 1\n\nfor i, model in enumerate(models) :\n    prob = model.predict_proba(X_test)\n    prob_positive = prob[:,1]\n    fpr, tpr, threshold = roc_curve(y_test, prob_positive)\n    plt.plot(fpr, tpr, color = color[i])\n    plt.gca().legend(model_names, loc = 'lower right', frameon = True)\n\nplt.plot([0,1],[0,1], linestyle = '--', color = 'black')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}