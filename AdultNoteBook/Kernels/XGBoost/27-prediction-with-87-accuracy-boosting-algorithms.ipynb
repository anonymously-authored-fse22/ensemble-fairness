{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, I have tried to use the three boosting algorithms - Adaboost, gradient boosting and xgboost - to solve the classification problem in the Adult Income dataset. This is my first notebook while learning boosting algorithms and I would appreciate any kind of suggestions or improvements."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport io \nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"file = ('../input/adult-census-income/adult.csv')\ndf = pd.read_csv(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count the occuring of the '?' in all the columns\nfor i in df.columns:\n    t = df[i].value_counts()\n    index = list(t.index)\n    print (\"Count of ? in\", i)\n    for i in index:\n        temp = 0\n        if i == '?':\n            print (t['?'])\n            temp = 1\n            break\n    if temp == 0:\n        print (\"0\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.loc[(df['workclass'] != '?') & (df['native.country'] != '?')]\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"income\"] = [1 if i=='>50K' else 0 for i in df[\"income\"]]\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_more=df.loc[df['income'] == 1]\nprint(df_more.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"workclass_types = df_more['workclass'].value_counts()\nlabels = list(workclass_types.index) \naggregate = list(workclass_types)\nprint(workclass_types)\nprint(aggregate)\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,7))\nplt.pie(aggregate, labels=labels, autopct='%1.1f%%', shadow = True)\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count plot on single categorical variable \nsns.countplot(x ='income', data = df)\nplt.show() \ndf['income'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot figsize\nplt.figure(figsize=(10,7))\nsns.heatmap(df.corr(), cmap='coolwarm', annot=True)\nprint(plt.show())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.distplot(df['age'], color=\"red\", bins=100)\nplt.ylabel(\"Distribution\", fontsize = 10)\nplt.xlabel(\"Age\", fontsize = 10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To find distribution of categorical columns w.r.t income\nfig, axes = plt.subplots(figsize=(20, 10))\n\nplt.subplot(231)\nsns.countplot(x ='workclass', \n              hue='income', \n              data = df,\n              palette=\"BuPu\") \nplt.xticks(rotation=90)\n\nplt.subplot(232)\nsns.countplot(x ='marital.status', \n              hue='income', \n              data = df,\n              palette=\"deep\") \nplt.xticks(rotation=90)\n\nplt.subplot(233)\nsns.countplot(x ='education', \n              hue='income', \n              data = df,\n              palette = \"autumn\") \nplt.xticks(rotation=90)\n\nplt.subplot(234)\nsns.countplot(x ='relationship', \n              hue='income', \n              data = df,\n              palette = \"inferno\") \nplt.xticks(rotation=90)\n\nplt.subplot(235)\nsns.countplot(x ='sex', \n              hue='income', \n              data = df,\n              palette = \"coolwarm\") \nplt.xticks(rotation=90)\n\nplt.subplot(236)\nsns.countplot(x ='race', \n              hue='income', \n              data = df,\n              palette = \"cool\") \nplt.xticks(rotation=90)\nplt.subplots_adjust(hspace=1) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = list(df1.select_dtypes(include=['object']).columns)\nprint(categorical_features)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor feat in categorical_features:\n    df1[feat] = le.fit_transform(df1[feat].astype(str))\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df1.drop(columns = ['income'])\ny = df1['income'].values\n\n# Splitting the data set into train and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state = 0)\n\nprint (\"Train set size: \", X_train.shape)\nprint (\"Test set size: \", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\n# Train Adaboost Classifer\nabc = AdaBoostClassifier(n_estimators = 300, learning_rate=1)\nabc_model = abc.fit(X_train, y_train)\n\n#Prediction\ny_pred_abc = abc_model.predict(X_test)\n\nprint(\"Accuracy: \", accuracy_score(y_test, y_pred_abc))\nprint(\"F1 score :\",f1_score(y_test, y_pred_abc, average='binary'))\nprint(\"Precision : \", precision_score(y_test, y_pred_abc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_abc)\nplt.figure(figsize=(5,5))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = \"coolwarm\");\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nplt.title('Confusion Matrix - score:' + str(round(accuracy_score(y_test, y_pred_abc), 2)), size = 15);\nplt.show()\nprint(classification_report(y_test, y_pred_abc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier \n\n#Training the model with gradient boosting\ngbc = GradientBoostingClassifier(\n    learning_rate = 0.1, \n    n_estimators = 500,\n    max_depth = 5, \n    subsample = 0.9,\n    min_samples_split = 100,\n    max_features='sqrt', \n    random_state=10)\ngbc.fit(X_train,y_train)\n\n# Predictions\ny_pred_gbc = gbc.predict(X_test)\n\nprint(\"Accuracy : \",accuracy_score(y_test, y_pred_gbc))\nprint(\"F1 score : \", f1_score(y_test, y_pred_gbc, average = 'binary'))\nprint(\"Precision : \", precision_score(y_test, y_pred_gbc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rms = np.sqrt(mean_squared_error(y_test, y_pred_gbc))\nprint(\"RMSE for gradient boost: \", rms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_gbc)\nplt.figure(figsize=(5,5))\nsns.heatmap(cm, annot = True, fmt=\".3f\", linewidths = 0.5, square = True, cmap = \"coolwarm\");\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nplt.title('Confusion Matrix - score:' + str(round(accuracy_score(y_test, y_pred_gbc),2)), size = 15);\nplt.show()\nprint(classification_report(y_test, y_pred_gbc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier\n\n#Training the model with gradient boosting\nxgboost = XGBClassifier(learning_rate=0.01,  \n                      colsample_bytree = 0.4,\n                      n_estimators=1000, \n                      max_depth=20, \n                      gamma=1)\n                      \nxgboost_model = xgboost.fit(X_train, y_train)\n\n# Predictions\ny_pred_xgboost = xgboost_model.predict(X_test)\n\nprint(\"Accuracy : \",accuracy_score(y_test, y_pred_xgboost))\nprint(\"F1 score : \", f1_score(y_test, y_pred_xgboost, average = 'binary'))\nprint(\"Precision : \", precision_score(y_test, y_pred_xgboost))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rms = np.sqrt(mean_squared_error(y_test, y_pred_xgboost))\nprint(\"RMSE for xgboost: \", rms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_xgboost)\nplt.figure(figsize=(5,5))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = \"coolwarm\");\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nplt.title('Confusion Matrix - score:'+str(round(accuracy_score(y_test, y_pred_xgboost),2)), size = 15);\nplt.show()\nprint(classification_report(y_test,y_pred_xgboost))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, xgboost.predict_proba(X_test)[:,1])  \nplt.figure(figsize = (10,5))\nplt.plot([0,1],[0,1], 'k--')                                                 \nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC CURVE for Xgboost')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nI would like to conclude this notebook by mentioning that here, I have tuned the hyperparameters myself instead of using Grid Search or random search as it didn't seem to increase my accuracies. I would appreciate any suggestions or improvements that I can make to make this better."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}