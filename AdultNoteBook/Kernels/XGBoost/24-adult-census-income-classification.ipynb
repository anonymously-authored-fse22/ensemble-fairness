{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Adult Census Income Classification\n\nIn this notebook, we will perform exploratory data analysis and explore various classification algorithms to determine whether a person makes over $50K a year (i.e. perform binary classification). Moreover, topics like features selection, cross-validation, model assessment and evaluation will be performed.\n\n## Description of Dataset\nThe dataset has** 32561 observations** (rows) and **15 features** (columns), and was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). A set of reasonably clean records was extracted using the following conditions: (**(AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0))**. Let's take a closer look at each of the variables.\n\n1. **Continuous variables**\n\n    * **age** - Age of an individual.\n    * **fnlwgt** - The term estimate refers to population totals derived from CPS by creating \"weighted tallies\" of any specified socio-economic characteristics of the population. People with similar demographic characteristics should have similar weights. \n    * **education.num** - Level of education (represented as integer)\n    * **capital.gain **\n    * **capital.loss**\n    * **hours.per.week ** - Individual's working hour per week\n\n\n2. **Categorical variables**\n\n    * **workclass** - ['Private', 'State-gov', 'Federal-gov', 'Self-emp-not-inc', 'Self-emp-inc', 'Local-gov', 'Without-pay', 'Never-worked']\n    * **education** - ['HS-grad', 'Some-college', '7th-8th', '10th', 'Doctorate', 'Prof-school', 'Bachelors', 'Masters', '11th', 'Assoc-acdm', 'Assoc-voc', '1st-4th', '5th-6th', '12th', '9th', 'Preschool']\n    * **marital.status** - ['Widowed', 'Divorced', 'Separated', 'Never-married', 'Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse']\n    * **occupation** - ['Exec-managerial', 'Machine-op-inspct', 'Prof-specialty',\n       'Other-service', 'Adm-clerical', 'Craft-repair',\n       'Transport-moving', 'Handlers-cleaners', 'Sales',\n       'Farming-fishing', 'Tech-support', 'Protective-serv',\n       'Armed-Forces', 'Priv-house-serv']\n    * **relationship** - ['Not-in-family', 'Unmarried', 'Own-child', 'Other-relative', 'Husband', 'Wife']\n    * **race** - ['White', 'Black', 'Asian-Pac-Islander', 'Other', 'Amer-Indian-Eskimo']\n    * **sex** - ['Female', 'Male']\n    * **native.country** - ['United-States', '?', 'Mexico', 'Greece', 'Vietnam', 'China',\n       'Taiwan', 'India', 'Philippines', 'Trinadad&Tobago', 'Canada',\n       'South', 'Holand-Netherlands', 'Puerto-Rico', 'Poland', 'Iran',\n       'England', 'Germany', 'Italy', 'Japan', 'Hong', 'Honduras', 'Cuba',\n       'Ireland', 'Cambodia', 'Peru', 'Nicaragua', 'Dominican-Republic',\n       'Haiti', 'El-Salvador', 'Hungary', 'Columbia', 'Guatemala',\n       'Jamaica', 'Ecuador', 'France', 'Yugoslavia', 'Scotland',\n       'Portugal', 'Laos', 'Thailand', 'Outlying-US(Guam-USVI-etc)']"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfiles = list()\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## A quick look at the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"income_census_df = pd.read_csv(files[0])\nincome_census_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's further investigate, are there any null-values?\n\nThere are no null-values in the dataset, however, columns **workclass** and **occupation** use **\"?\"** to represent missing records. We will take care of these values going forward."},{"metadata":{"trusted":true},"cell_type":"code","source":"income_census_df.info()\nincome_census_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Next, let's perform EDA\n\nBefore that, \n\n1. Let's impute the missing values represented by **\"?\"** for columns occupation and workclass to **Unknown**.\n2. Clean the data to obtain feature values that can be easily understood."},{"metadata":{"trusted":true},"cell_type":"code","source":"income_census_df['occupation'].replace({'?' : 'Unknown'}, inplace=True)\nincome_census_df['workclass'].replace({'?' : 'Unknown'}, inplace=True)\n\nincome_census_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cleaning Marital Status column"},{"metadata":{"trusted":true},"cell_type":"code","source":"income_census_df['marital.status'].replace({'Married-civ-spouse' : 'Married' ,\n                                            'Divorced' : 'Separated', \n                                            'Married-AF-spouse' : 'Married' , \n                                            'Married-spouse-absent':'Separated'}, inplace = True)\nplt.figure(figsize=(10,4))\nsns.countplot(income_census_df['marital.status'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cleaning education column"},{"metadata":{"trusted":true},"cell_type":"code","source":"income_census_df['education'].replace({'HS-grad':'HighSchool', \n                                       'Some-college':'College', \n                                       'Bachelors' : 'University', \n                                       'Masters' : 'University',\n                                       'Assoc-voc' : 'College', \n                                       'Assoc-acdm':'College',\n                                       'Prof-school' : 'University', \n                                       'Doctorate' : 'University', \n                                       '11th' : 'Dropout',\n                                       '10th' : 'Dropout',\n                                       '7th-8th' : 'Dropout',\n                                       '9th' : 'Dropout', \n                                       '12th' : 'Dropout',\n                                       '5th-6th': 'Dropout',\n                                       '1st-4th': 'Dropout',\n                                       'Preschool':'Dropout'}, inplace = True)\n\nplt.figure(figsize=(10,4))\nsns.countplot(income_census_df['education'])\nplt.xlabel('Education')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. What is the average working hours per week for each gender in different occupations?"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_hours_occ = income_census_df.groupby(['sex','occupation'])['hours.per.week'].mean().reset_index()\nplt.figure(figsize=(10, 7))\nsns.barplot(x='occupation', y='hours.per.week', hue='sex', data=avg_hours_occ)\nplt.xlabel('Occupation')\nplt.ylabel('Average work hours per week')\nplt.title('Mean number of hours worked by each gender for given occupation')\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. What is the average working hours per week based on education?"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_hours_edu = income_census_df.groupby(['education'])['hours.per.week'].mean().reset_index()\nplt.figure(figsize=(7, 5))\nsns.barplot(x='education', y='hours.per.week', data=avg_hours_edu)\nplt.xlabel('Education')\nplt.ylabel('Average work hours per week')\nplt.title('Mean number of hours worked based on Education')\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Is there a relationship between age and average hours worked per week?"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_hours_age = income_census_df.groupby(['sex','age'])['hours.per.week'].mean().reset_index()\nplt.figure(figsize=(7, 5))\nsns.scatterplot(x='age', y='hours.per.week', hue='sex', data=avg_hours_age)\nplt.xlabel('Age')\nplt.ylabel('Average work hours per week')\nplt.title('Mean number of hours worked based on Age')\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Do people who have an income > 50K a year, work for more hours on average than people with income <= 50K?"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_hours_income = income_census_df.groupby(['sex','income'])['hours.per.week'].mean().reset_index()\nplt.figure(figsize=(7, 5))\nsns.barplot(x='income', y='hours.per.week', hue='sex', data=avg_hours_income)\nplt.xlabel('Income')\nplt.ylabel('Average work hours per week')\nplt.title('Mean number of hours worked based on Age')\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Number of male and female workers with income > 50K based on Occupation"},{"metadata":{"trusted":true},"cell_type":"code","source":"income_df = income_census_df[['sex', 'occupation', 'income']].copy()\nincome_df['income_grt50K'] = income_df['income'].apply(lambda x: 1 if x == '>50K' else 0)\nincome_grt50K = income_df.groupby(['sex','occupation'])['income_grt50K'].sum().reset_index()\n\nplt.figure(figsize=(10, 7))\nsns.barplot(x='occupation', y='income_grt50K', hue='sex', data=income_grt50K)\nplt.xlabel('')\nplt.ylabel('Number of people (income > 50K)')\nplt.title('Number of male and female workers with income > 50K based on Occupation')\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Number of male and female workers with income > 50K based on Working class"},{"metadata":{"trusted":true},"cell_type":"code","source":"income_df = income_census_df[['sex', 'workclass', 'income']].copy()\nincome_df['income_grt50K'] = income_df['income'].apply(lambda x: 1 if x == '>50K' else 0)\nincome_grt50K = income_df.groupby(['sex','workclass'])['income_grt50K'].sum().reset_index()\n\nplt.figure(figsize=(10, 7))\nsns.barplot(x='workclass', y='income_grt50K', hue='sex', data=income_grt50K)\nplt.xlabel('')\nplt.ylabel('Number of people (income > 50K)')\nplt.title('Number of male and female workers with income > 50K based on Working class')\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7. Number of male and female workers with income > 50K based on Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"income_df = income_census_df[['sex', 'age', 'income']].copy()\nincome_df['income_grt50K'] = income_df['income'].apply(lambda x: 1 if x == '>50K' else 0)\nincome_grt50K = income_df.groupby(['sex','age'])['income_grt50K'].sum().reset_index()\nincome_grt50K\n\nplt.figure(figsize=(10, 7))\nax = sns.barplot(x='age', y='income_grt50K', hue='sex', data=income_grt50K)\nax.xaxis.set_major_locator(ticker.MultipleLocator(4))\nax.xaxis.set_major_formatter(ticker.ScalarFormatter())\nplt.xlabel('Age')\nplt.title('Number of people (income > 50K) by Age')\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8. Number of male and female workers with income > 50K based on Education"},{"metadata":{"trusted":true},"cell_type":"code","source":"income_df = income_census_df[['sex', 'education', 'income']].copy()\nincome_df['income_grt50K'] = income_df['income'].apply(lambda x: 1 if x == '>50K' else 0)\nincome_grt50K = income_df.groupby(['sex','education'])['income_grt50K'].sum().reset_index()\n\nplt.figure(figsize=(10, 7))\nsns.barplot(x='education', y='income_grt50K', hue='sex', data=income_grt50K)\nplt.xlabel('')\nplt.ylabel('Number of people (income > 50K)')\nplt.title('Number of male and female workers with income > 50K based on Education')\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 9. Number of male and female workers with income <= 50K based on Education"},{"metadata":{"trusted":true},"cell_type":"code","source":"income_df = income_census_df[['sex', 'education', 'income']].copy()\nincome_df['income_leq50K'] = income_df['income'].apply(lambda x: 1 if x == '<=50K' else 0)\nincome_leq50K = income_df.groupby(['sex','education'])['income_leq50K'].sum().reset_index()\n\nplt.figure(figsize=(10, 7))\nsns.barplot(x='education', y='income_leq50K', hue='sex', data=income_leq50K)\nplt.xlabel('')\nplt.ylabel('Number of people (income <= 50K)')\nplt.title('Number of male and female workers with income <= 50K based on Education')\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 10. Do the continuous features have correlation?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.heatmap(income_census_df.corr(), annot=True , cmap='summer')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no correlation between any of the continuous predictors\n\n\n#### EDA is done for our dataset"},{"metadata":{},"cell_type":"markdown","source":"## Prepare data for modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performing One-Hot Encoding and Label Encoding\nincome_census_df.head()\n\n# Remove variables: workclass, education, marital.status, occupation, relationship, race, native.country","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"income_census_df = income_census_df.drop(columns=['native.country', 'marital.status', 'education'])\nincome_census_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dummy variables\ndef get_dummy(data):\n    cat_vars = []\n    df = data.copy()\n    for col in df.columns:\n        if (df[col].dtype.name == 'object' and col != 'income'):\n            cat_vars.append(col)\n    df_preprocessed = pd.get_dummies(df, prefix_sep=\"_\", columns=cat_vars)\n    return df_preprocessed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preprocessed = get_dummy(income_census_df)\ndf_preprocessed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nsns.countplot(df_preprocessed['income'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The class imbalance is clearly evident from the plot above. We will apply down-sampling method to handle this imbalance in the target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map income variable to 1 and 0\ndf_preprocessed['target_income'] = df_preprocessed['income'].apply(lambda x: 1 if x == '>50K' else 0)\ndf_preprocessed.drop(['income'], axis=1, inplace=True)\ndf_preprocessed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standardize the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardize the data\n\ndef standardize(df):\n    X = df.drop(columns='target_income')\n    y = df['target_income']\n    \n    ss = StandardScaler()\n    X[X.columns] = ss.fit_transform(X[X.columns])\n    return(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orig_X, orig_y = standardize(df_preprocessed)\norig_X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Downsampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform downsampling\n\ndf_majority = df_preprocessed[df_preprocessed.target_income==0]\ndf_minority = df_preprocessed[df_preprocessed.target_income==1]\n\ndf_majority_downsampled = resample(df_majority, \n                                   replace=False, \n                                   n_samples=len(df_minority), \n                                   random_state=123)\n\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\ndf_downsampled.target_income.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_X, ds_y = standardize(df_downsampled)\nds_X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apply PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# PCA on original dataset\n\npca = PCA()\ndf_orig_pca = pca.fit_transform(orig_X)\ndf_cumvar = pd.DataFrame(np.cumsum(pca.explained_variance_ratio_)*100, \n                         index = range(1, orig_X.shape[1]+1) , columns=['CumVar'])\ndf_cumvar[df_cumvar['CumVar'] >= 95].T\n# 96% variance is explained by 34 components.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=34)\ndf_orig_pca1 = pca.fit_transform(orig_X)\norig_pca_X = pd.DataFrame(df_orig_pca1 , columns=['PC '+str(i) for i in range(1,35)])\norig_pca_X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-Test Split"},{"metadata":{},"cell_type":"markdown","source":"We will now use the following dfs to build our classification models:\n\n* orig_X, orig_y       \n* orig_pca_X, orig_y\n* ds_X, ds_y  -> (ds = downsampled)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_test_split(x, y):\n    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=2)\n    return(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orig_trainX, orig_testX, orig_trainY, orig_testY = get_train_test_split(orig_X, orig_y)\n\nprint('X_train shape', orig_trainX.shape)\nprint('y_train shape', orig_trainY.shape)\nprint('X_test  shape', orig_testX.shape)\nprint('y_test  shape', orig_testY.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logisticRegression(trainX, trainY, testX, testY):\n\n    lr_model = LogisticRegression(fit_intercept=True, solver='liblinear')\n    lr_model.fit(trainX, trainY)\n    \n    y_pred = lr_model.predict(trainX)\n    thres_acc = metrics.accuracy_score(trainY, y_pred, normalize = True)\n    print('Logistic Regression (Train Accuracy) : ', thres_acc)\n    \n\n    probs = lr_model.predict_proba(testX)\n    fpr, tpr, t = metrics.roc_curve(testY, probs[:,1])\n\n    y_pred = lr_model.predict(testX)\n    thres_acc = metrics.accuracy_score(testY, y_pred, normalize = True)\n\n    roc_auc = metrics.auc(fpr, tpr)\n\n    plt.figure(figsize=(7, 5))\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr, tpr, 'b', label = 'Test AUC = %0.2f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()\n\n    y_true = testY.apply(lambda x: '<=50k' if x == 0 else '>50k')\n    y_preds = np.where(y_pred == 0,'<=50k', '>50k')\n\n    labels = ['<=50k', '>50k']\n    cm = confusion_matrix(y_true, y_preds, labels)\n    print(cm)\n    fig = plt.figure(figsize=(7, 5))\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(cm)\n    fig.colorbar(cax)\n    ax.set_xticklabels([''] + labels)\n    ax.set_yticklabels([''] + labels)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\n\n    print('Logistic Regression (Test Accuracy) : ', thres_acc)\n    print('Precision Score: ', precision_score(testY, y_pred))\n    print('Recall Score: ', recall_score(testY, y_pred))\n    print('F1 Score: ', f1_score(testY, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression on original dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlogisticRegression(orig_trainX, orig_trainY, orig_testX, orig_testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression using Principal Components"},{"metadata":{"trusted":true},"cell_type":"code","source":"orig_trainX, orig_testX, orig_trainY, orig_testY = get_train_test_split(orig_pca_X, orig_y)\nlogisticRegression(orig_trainX, orig_trainY, orig_testX, orig_testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regresion with Optimal Threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    \"\"\"\n    Modified from:\n    Hands-On Machine learning with Scikit-Learn\n    and TensorFlow; p.89\n    \"\"\"\n    plt.figure(figsize=(7, 5))\n    plt.title(\"Precision and Recall Scores as a function of the decision threshold\")\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n    plt.ylabel(\"Score\")\n    plt.xlabel(\"Decision Threshold\")\n    plt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression with cross-validation to choose optimal threshold for binary classification\n\nX_train = orig_trainX.reset_index().drop(columns=['index'])\ny_train = orig_trainY.reset_index().drop(columns=['index'])\n\nlr_model = LogisticRegression(fit_intercept=True, solver='liblinear')\nskf = StratifiedKFold(n_splits=3)\n\nbest_accuracy = 0\nopt_threshold = 0\nfpr = None\ntpr = None\np = None\nr = None\nt = None\n\nfor train, test in skf.split(X_train, y_train):\n    print(train, test)\n    lr_model.fit(X_train.loc[train], y_train.loc[train].values.ravel())\n    probs = lr_model.predict_proba(X_train.loc[test])\n    fpr, tpr, thresholds = metrics.roc_curve(y_train.loc[test], probs[:,1])\n    p, r, t = metrics.precision_recall_curve(y_train.loc[test], probs[:,1])\n    \n    for thres in thresholds:\n        y_pred = np.where(probs[:,1] > thres,1,0)\n        #Apply desired utility function to y_preds, for example accuracy.\n        thres_acc = metrics.accuracy_score(y_train.loc[test], y_pred)\n        if thres_acc > best_accuracy:\n            best_accuracy = thres_acc\n            opt_threshold = thres\n\nroc_auc = metrics.auc(fpr, tpr)\nplt.figure(figsize=(7, 5))\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'Train AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nprint('Optimal Threshold: ', opt_threshold, ' gives Train Accuracy: ', best_accuracy)\n\nplot_precision_recall_vs_threshold(p, r, t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = lr_model.predict_proba(orig_testX)\nfpr, tpr, t = metrics.roc_curve(orig_testY, probs[:,1])\n\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.figure(figsize=(7, 5))\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'Test AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n\ny_pred = np.where(probs[:,1] > opt_threshold,1,0)\nthres_acc = metrics.accuracy_score(orig_testY, y_pred, normalize = True)\nprint('Logistic Regression (Test Accuracy): ', thres_acc)\n\ny_true = orig_testY.apply(lambda x: '<=50k' if x == 0 else '>50k')\ny_preds = np.where(probs[:,1] > opt_threshold,'>50k','<=50k')\n\nlabels = ['<=50k', '>50k']\ncm = confusion_matrix(y_true, y_preds, labels)\nprint(cm)\nfig = plt.figure(figsize=(7, 5))\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nfig.colorbar(cax)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Precision Score: ', precision_score(orig_testY, y_pred))\nprint('Recall Score: ', recall_score(orig_testY, y_pred))\nprint('F1 Score: ', f1_score(orig_testY, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression using Downsampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_trainX, ds_testX, ds_trainY, ds_testY = get_train_test_split(ds_X, ds_y)\nlogisticRegression(ds_trainX, ds_trainY, ds_testX, ds_testY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<b>Analysis</b>\n\nWe trained a logistic regression model on the original dataset, principal components, \noptimal threshold for classification using cross-validation, and downsampling. From the above plots, \nwe can confirm that the best results were obtained with the downsampled dataset. \nAccuracy score of 0.82, Precision score of 0.80, Recall score of 0.85, and F1 score of 0.83.\n\nPrecision: This tells when you predict something positive, how many times they were actually positive. whereas, \nRecall: This tells out of actual positive data, how many times you predicted correctly.\n\nTherefore, it would be right to say that logistic regression trained and tested using downsampling technique \ngives us a relatively balanced model."},{"metadata":{},"cell_type":"markdown","source":"### Let's fit a model to find out features that have significant impact in predicting income category."},{"metadata":{"trusted":true},"cell_type":"code","source":"orig_trainX, orig_testX, orig_trainY, orig_testY = get_train_test_split(orig_X, orig_y)\n\n# Training the model\nmodel = XGBClassifier()\nmodel_importance = model.fit(orig_trainX, orig_trainY)\n\n# Plotting the Feature importance bar graph\nplt.rcParams['figure.figsize'] = [14,12]\nsns.set(style = 'darkgrid')\nplot_importance(model_importance);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Next, let's try a non-parametric model: Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_trainX, ds_testX, ds_trainY, ds_testY = get_train_test_split(ds_X, ds_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyperparameter tuning relies more on experimental results than theory, and thus the best method to determine the optimal settings is to try many different combinations and evaluate the performance of each model."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(random_state = 42)\nfrom pprint import pprint\n# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(rf.get_params())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We will try adjusting the following set of hyperparameters:\n\n* **n_estimators** = number of trees in the foreset\n* **max_features** = max number of features considered for splitting a node\n* **max_depth** = max number of levels in each decision tree\n* **min_samples_split** = min number of data points placed in a node before the node is split\n* **min_samples_leaf** = min number of data points allowed in a leaf node\n* **bootstrap** = method for sampling data points (with or without replacement)"},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameters Tuning:\n\nWe will generate a Random Hyperparameter Grid to narrow down the range of each hyperparameter using RandomizedSearchCV. The results of Random Search will be used in GridSearchCV to find the optimal parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\npprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n                               n_iter = 100, cv = 3, verbose = 2, random_state = 42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(ds_trainX, ds_trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    acc = metrics.accuracy_score(test_labels, predictions, normalize = True)\n    metrics.classification_report(test_labels, predictions)\n    print('Model Performance')\n    print(metrics.classification_report(test_labels, predictions))\n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate Baseline Model\n\nbase_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\nbase_model.fit(ds_trainX, ds_trainY)\nbase_accuracy = evaluate(base_model, ds_testX, ds_testY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_random = rf_random.best_estimator_\nrandom_acc = evaluate(best_random, ds_testX, ds_testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We achieved an improvement in accuracy of 2.46% with RandomSearchCV from the baseline model.**"},{"metadata":{},"cell_type":"markdown","source":"We can further improve our results by using grid search to focus on the most promising hyperparameters ranges found in the random search."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'bootstrap': [True],\n    'max_features': ['auto'],\n    'min_samples_leaf': [2, 3, 4],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300, 1000]\n}\n\nrf = RandomForestClassifier()\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                           cv = 3, n_jobs = -1, verbose = 2)\ngrid_search.fit(ds_trainX, ds_trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_grid = grid_search.best_estimator_\ngrid_accuracy = evaluate(best_grid, ds_testX, ds_testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems we have about maxed out performance"},{"metadata":{},"cell_type":"markdown","source":"There is not much to choose from Random Forest with GridSearchCV and RandomSearchCV. Moreover, Random Forest does not perform any better than the Logistic Regression to predict income category. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}