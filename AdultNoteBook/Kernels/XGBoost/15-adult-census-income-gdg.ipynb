{"cells":[{"metadata":{"_uuid":"ed80567ac432681d85bd1ce432baae91030ba348"},"cell_type":"markdown","source":"# Adult Census Income Data Analysis"},{"metadata":{"_uuid":"e35da627182d8569aa29b703ef8bbd3113aa5576"},"cell_type":"markdown","source":"### **Abstract**: Predict whether income exceeds  50K /year based on census data.  Also known as \"Census Income\" dataset.  \nData Set: https://archive.ics.uci.edu/ml/datasets/adult"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d4ee8458c445751d2466e31db347dc2720123ec"},"cell_type":"markdown","source":"## 1. Import Data Set"},{"metadata":{"_uuid":"150cea425cdc67e5ddec95780e3f8a361369bd97"},"cell_type":"markdown","source":"The dataset contains featured attributes like age, workclass, education, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week & native-country which has characterisation of categorical & integer values. The missing data is represented using '?' symbol."},{"metadata":{"_uuid":"17cfdec79293477637f29f60c98606aa2c8161d0"},"cell_type":"markdown","source":"Import Pandas and Numpy Library"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/adult.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"014eaebe4c25ed6497317b52d4cb52c3706a98ec"},"cell_type":"markdown","source":"## 2. Data Preprocessing"},{"metadata":{"_uuid":"6a90e44c8bb011b92b126286a34af8f5fa57cf98"},"cell_type":"markdown","source":"During data filtering the '?' symbol is replaced with \"NaN\" to get a definite information from the dataset."},{"metadata":{"_uuid":"00f520fb31fcf78543c07fdabef485f5bebcfe2b"},"cell_type":"markdown","source":"### Replace \" ? \" by NaN (Handling ' ? ' symbols)"},{"metadata":{"trusted":true,"_uuid":"86dbf2e1b2b2f7b8008b00ba92427d39030e93fe"},"cell_type":"code","source":"# replace \"?\" to NaN\ndf.replace(\"?\", np.nan, inplace = True)\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"595a881042c32f3d21ec459de0beb19a80248c0b"},"cell_type":"markdown","source":"###  Check for missing Data"},{"metadata":{"_uuid":"d0e5f7d37e6422dff5246eb09eeb531dfd9f3965"},"cell_type":"markdown","source":"Since the symbol is now replaced with NaN which is null value, these are easily recognised and computed to check for the summation of the missing data available in the dataset."},{"metadata":{"trusted":true,"_uuid":"44dc1d0cc56af6f92eccfc1c1048d198a796875f"},"cell_type":"code","source":"missing_data = df.isnull()\nmissing_data.sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"780753fa7f75c297799e327a7364efb32753a545"},"cell_type":"markdown","source":"From this statistics we get a total no of 1836 workclass data, 1843 occupation data, and 583 native country data missing from the existing dataset."},{"metadata":{"_uuid":"acf71bb2e91b16ce602e371b5c63b5615234854c"},"cell_type":"markdown","source":"### Collect more statistics about Missing data"},{"metadata":{"_uuid":"eb5886b37e99274599f187595d8607f29530adc0"},"cell_type":"markdown","source":"Visualization of impact of data."},{"metadata":{"trusted":true,"_uuid":"24590caf1451433e6953ceff273e85c7187b97ee"},"cell_type":"code","source":"missing_col = []\nfor column in missing_data.columns.values.tolist():\n    if(missing_data[column].sum() > 0):\n        print(\"Column: \",column)\n        print(\"Missing Data: {} ({:.2f}%)\".format(missing_data[column].sum(), (missing_data[column].sum() * 100/ len(df))))\n        print(\"Data Type: \",df[column].dtypes)\n        print(\"\")\n        missing_col.append(column)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"249e3db15ef41474f19b221afa759fc498fa8935"},"cell_type":"markdown","source":"### As we can see from above statistics, we have 3 missing columns,  \n1. workclass : 1836 missing data  \n2. occupation: 1843 missing data  \n3. native.country: 583 missing data  \n  \n### Note:  All the missing data are categorical data  "},{"metadata":{"_uuid":"f525099ad8ecd6f479a686cec7ea4b40e447684b"},"cell_type":"markdown","source":"### Impact of Missing Data on Data set"},{"metadata":{"trusted":true,"_uuid":"b37b6ef470e3d15559bca60ead864cbaac2945f8"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18e41087e2259b5f0e7d1c5007a14bd15b8d99b8"},"cell_type":"code","source":"fig1 = plt.figure(figsize=(18,5))\ni = 0\nfor column in missing_col:\n    bad = missing_data[column].sum()\n    good = len(df) - missing_data[column].sum()\n    x = [bad, good]\n    labels = [\"Missing Data\", \"Good Data\"]\n    explode = (0.1, 0)\n    i = i+1\n    ax = fig1.add_subplot(1,3,i)\n    ax.pie(x,explode = explode, labels = labels, shadow = True,autopct='%1.1f%%', colors = ['#ff6666', '#99ff99'],rotatelabels = True, textprops={'fontsize': 18})\n    centre_circle = plt.Circle((0,0),0.4,color='black', fc='white',linewidth=0)\n    fig = plt.gcf()\n    fig.gca().add_artist(centre_circle)\n    ax.axis('equal')\n    ax.set_title(column, fontsize = 25)\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"607e0ba3b2887867ea477a7311720e3c0d2061f3"},"cell_type":"markdown","source":"## Fix Missing Data"},{"metadata":{"_uuid":"cf4aed7fa857e96c6d8dcc82252f8e9fb97fb9af"},"cell_type":"markdown","source":"Now here the missing data is dealt-with accordingly based on certain rules."},{"metadata":{"trusted":true,"_uuid":"931a206844a50defd9b91e9fcfffa1640b37cba2"},"cell_type":"markdown","source":"<a id=\"ref3\"></a>\n## Deal with missing data\n**How to deal with missing data:**\n\n    \n    1. Drop data \n        a. drop the whole row\n        b. drop the whole column\n    2. Replace data\n        a. replace it by mean\n        b. replace it by frequency\n        c. replace it based on other functions"},{"metadata":{"_uuid":"05659f0a244c89f1fb975e9c71943c2cc5c62856"},"cell_type":"markdown","source":"### As we have only categorical missing data we will use \" Replace by Frequency or Mode\" Method"},{"metadata":{"_uuid":"c8c837ac7ee307e30846133446ad03cc93a0301d"},"cell_type":"markdown","source":"The mode of each category is computed to fix the missing data based on frequency. The null values present in any column of dataset is replaced by the mode of the same column data."},{"metadata":{"trusted":true,"_uuid":"d34e82e915db26fa69832035bf4bdf293c67bc4a"},"cell_type":"code","source":"# Calculate Mode\nworkclass_mode = df['workclass'].value_counts().idxmax()\noccupation_mode = df['occupation'].value_counts().idxmax()\nnative_country_mode = df['native.country'].value_counts().idxmax()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d77f45d8dd961238211a3bbafa065d0932858d80"},"cell_type":"code","source":"print(\"Mode of workclass: \",workclass_mode)\nprint(\"Mode of Occupation: \",occupation_mode)\nprint(\"Mode of natice.country: \",native_country_mode)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f703d05ab6ea170de80e153e65c6df9d0b84e8fd"},"cell_type":"markdown","source":"**Copy our original data frame to a dummy data frame**"},{"metadata":{"trusted":true,"_uuid":"4f68e827cff0c375b21b4b69001b574b6df2e6c4"},"cell_type":"code","source":"df_manual = df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0423c7dc43ad58ec66973238e293d053bffea982"},"cell_type":"markdown","source":"### Replace the missing categorical values by the most frequent value"},{"metadata":{"trusted":true,"_uuid":"a606bad5611e457b03e5a727f3ba8521654b3421"},"cell_type":"code","source":"#replace the missing categorical values by the most frequent value\ndf_manual[\"workclass\"].replace(np.nan, workclass_mode, inplace = True)\ndf_manual[\"occupation\"].replace(np.nan, occupation_mode, inplace = True)\ndf_manual[\"native.country\"].replace(np.nan, native_country_mode, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c7d722dce3f7101d0d5d7edef0b016c9b93b5c7"},"cell_type":"markdown","source":"1. **Check for any Null Values**"},{"metadata":{"_uuid":"da1201aa1f9c4d316b4fee074b095a770106265b"},"cell_type":"markdown","source":"After being replaced by the mode values effectively the algorithm doesnt find any missing values. The null value is computed zero for each attribute item."},{"metadata":{"trusted":true,"_uuid":"50a5d9550d49da0b4c10feb1c10fce5c8c6bf11b"},"cell_type":"code","source":"df_manual.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10b03d5f191e3d64132e582492b6af0ea0ff0163"},"cell_type":"markdown","source":"**NO Null Values are present**"},{"metadata":{"_uuid":"9bc0ea590c9afc322c2896fc754573bf98e2d464"},"cell_type":"markdown","source":"# Convert Categorical Variables to Continuous Variable (Label Encoding with Binarization)"},{"metadata":{"_uuid":"4bb43c14b6773d12e60cd24c895ad801a2ac249c"},"cell_type":"markdown","source":"**Without any numerical precedence**"},{"metadata":{"_uuid":"68536a13e03b4b7ff8f1188bbcaf2ee9c4925533"},"cell_type":"markdown","source":"**Print all the categorical variables**"},{"metadata":{"trusted":true,"_uuid":"ccae235fced1de882624aded6d57d7f92ccfdcf0"},"cell_type":"code","source":"count = 0\nfor column in df_manual.columns.values.tolist():\n    if df_manual[column].dtype == 'object':\n        print(\"Column Name: \",column)\n        print(\"Data Type: \", df_manual[column].dtypes)\n        print(\"\")\n        count = count + 1\nprint(\"Count : \",count)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99a6aa600283bd1e7c624598ac06a2a201e78ffc"},"cell_type":"markdown","source":"## We have above 9 Categorical Variables"},{"metadata":{"_uuid":"52c1a02ba0242a5fa70f83abd6cb756179913fec"},"cell_type":"markdown","source":"**Encode all the categorical values **"},{"metadata":{"_uuid":"66c7ff850702849e2e938510a2356b8a222ccdcd"},"cell_type":"markdown","source":"### Encoding \"workclass\""},{"metadata":{"trusted":true,"_uuid":"1e1d64e0263e2f9c3e7e891a5c21ef0e878a72d6"},"cell_type":"code","source":"dummy = pd.get_dummies(df_manual[\"workclass\"])\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16cca8dd9abdec075f5929df08a514d5b17d83fb"},"cell_type":"markdown","source":"Here we used pd.get_dummies function to convert categorical values into label encoded binary values\n**1** indicates the positive verification while, **0** indicates negative verification.\n\nThese are Dummy variables alternatively called as indicator variables that take discrete values such as 1 or 0 marking the presence or absence of a particular category."},{"metadata":{"trusted":true,"_uuid":"02f0cfac2446454a7635c2ce7cfe584b5942c0d4"},"cell_type":"code","source":"#Rename column names\ndummy.rename(columns={'Federal-gov':'work-Federal-gov', \n                      'Local-gov':'work-Local-gov',\n                      'Private': 'work-Private',\n                      'Self-emp-inc': 'work-Self-emp-inc',\n                      'Self-emp-not-inc': 'Self-emp-not-inc',\n                      'State-gov': 'work-State-gov',\n                      'Without-pay' : 'work-Without-pay'}, inplace=True)\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ea5b65d9c07a52e99a5a47b3824108973675c87"},"cell_type":"markdown","source":"We renamed the attribute for our convinience"},{"metadata":{"_uuid":"7d55598fde02e37c55827068fd53a018f205d13c"},"cell_type":"markdown","source":"# What is Dummy Variable Trap?  \nThe Dummy Variable trap is a scenario in which the independent variables are multicollinear - a scenario in which two or more variables are highly correlated; in simple terms one variable can be predicted from the others.   \n<img src = \"https://qph.fs.quoracdn.net/main-qimg-4445db89d9218ba35ceedcf8d1e73d35.webp\"></img>   \nLets encode the categorical column called “Country” and its values are -** [India, Germany, France]**  \nIn ML regression models, predictions will do the good job if categorical values are converted into numerical (binary vectors ) values. Encoding categorical data technique to apply for the above categorical set and the values a.k.a dummy variables will become  \n<img src = \"https://qph.fs.quoracdn.net/main-qimg-c9ee21fe8c9294294f81ee7d39dddedb.webp\"></img>  \nWhich dummy variable column do we need drop?   \nThe answer is - we can drop any of one dummy variables column. It can predict the dropped column’s value based on other two columns. **Let’s take the record no 3 in the above table, both dummy variable values are ‘0’. So obviously another dummy variable column value is ‘1’ and categorical value is ‘Germany’**"},{"metadata":{"_uuid":"c5fb240f4bae3d784314ca7f094ecf1444de8101"},"cell_type":"markdown","source":"### Drop one column to avoid Dummy Variable Trap. Here we dropped \"Never-worked\" column and took it as base value.  \nHere we reduced the multi-colinearity."},{"metadata":{"trusted":true,"_uuid":"a9912d283b89b0450d7557894877baf9b8b06d99"},"cell_type":"code","source":"dummy.drop(\"Never-worked\", axis = 1, inplace=True)\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fd2e5f2291df06cb53c7a6d83740661d1f46851"},"cell_type":"markdown","source":"### Add the dummy variables to Main Data Frame  \nWe append the dummy variable with the main dataframe and drop the original column workplace."},{"metadata":{"trusted":true,"_uuid":"97fa16328b6c18d4e7de13349a533dbfe20f84c3"},"cell_type":"code","source":"# merge data frame \"df\" and \"dummy\" \ndf_manual = pd.concat([df_manual, dummy], axis=1)\n\n# drop original column \"workplace\" from \"df\"\ndf_manual.drop(\"workclass\", axis = 1, inplace=True)\ndf_manual.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26ebffab8afe00a625305a8690d49a402a2455a3"},"cell_type":"markdown","source":"The above table shows the label encoded category."},{"metadata":{"_uuid":"3873b618e73a1a31ae7df8a1dec738caae739043"},"cell_type":"markdown","source":"## Encode \"education\""},{"metadata":{"trusted":true,"_uuid":"12b25c3aec2338f2a0a2704ca41b2364f7b83fe0"},"cell_type":"code","source":"dummy = pd.get_dummies(df_manual[\"education\"])\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5db8cfc3174abd17e1171dd8569b52162606db97"},"cell_type":"code","source":"dummy.drop(\"Some-college\", axis = 1, inplace=True)\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36523a0d96a7438675572cb1c88113952819d25f"},"cell_type":"code","source":"# merge data frame \"df\" and \"dummy_variable_1\" \ndf_manual = pd.concat([df_manual, dummy], axis=1)\n\n# drop original column \"fuel-type\" from \"df\"\ndf_manual.drop(\"education\", axis = 1, inplace=True)\ndf_manual.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"191d0fca3fe740cc40530d76a6ecbddf03789318"},"cell_type":"markdown","source":"## Encode \"marital.status\""},{"metadata":{"trusted":true,"_uuid":"ee0f9cd37ddc2a8aa0acb054ac16e206e1423fff"},"cell_type":"code","source":"dummy = pd.get_dummies(df_manual[\"marital.status\"])\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0934e1b0e8d7806140f8858c31c4833178588917"},"cell_type":"code","source":"dummy.drop(\"Never-married\", axis = 1, inplace=True)\n# merge data frame \"df\" and \"dummy_variable_1\" \ndf_manual = pd.concat([df_manual, dummy], axis=1)\n\n# drop original column \"fuel-type\" from \"df\"\ndf_manual.drop(\"marital.status\", axis = 1, inplace=True)\ndf_manual.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ccbdaae49ec2bc6dec1d5aa32f40060de886978"},"cell_type":"markdown","source":"## Encode \"occupation\""},{"metadata":{"trusted":true,"_uuid":"fdfd93f3c39a747a3101189198f5f36f03aa4fdf"},"cell_type":"code","source":"dummy = pd.get_dummies(df_manual[\"occupation\"])\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1819e3784352108c5e8aa452723d07759a03323c"},"cell_type":"code","source":"dummy.drop(\"Other-service\", axis = 1, inplace=True)\n# merge data frame \"df\" and \"dummy_variable_1\" \ndf_manual = pd.concat([df_manual, dummy], axis=1)\n\n# drop original column \"fuel-type\" from \"df\"\ndf_manual.drop(\"occupation\", axis = 1, inplace=True)\ndf_manual.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"168329813585907a24753bfe195139f8a2e8f986"},"cell_type":"markdown","source":"## Encode \"relationship\""},{"metadata":{"trusted":true,"_uuid":"f9354247ecef31e4fbb2cf0ca3d2a76803099a5e"},"cell_type":"code","source":"dummy = pd.get_dummies(df_manual[\"relationship\"])\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"318ead910b3e842216df097e43a57ec2f949ed5a"},"cell_type":"code","source":"dummy.drop(\"Other-relative\", axis = 1, inplace=True)\n# merge data frame \"df\" and \"dummy_variable_1\" \ndf_manual = pd.concat([df_manual, dummy], axis=1)\n\n# drop original column \"fuel-type\" from \"df\"\ndf_manual.drop(\"relationship\", axis = 1, inplace=True)\ndf_manual.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"206ef305f94752b3ee608f8cff3ed9415e2003bb"},"cell_type":"markdown","source":"## Encode \"race\""},{"metadata":{"trusted":true,"_uuid":"2cd4c51cbed768bf1742e2ddfe67734eb663bb9d"},"cell_type":"code","source":"dummy = pd.get_dummies(df_manual[\"race\"])\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"984e1fb3fea585eb05d30caf2a3e1440f8e93d46"},"cell_type":"code","source":"dummy.drop(\"Other\", axis = 1, inplace=True)\n# merge data frame \"df\" and \"dummy_variable_1\" \ndf_manual = pd.concat([df_manual, dummy], axis=1)\n\n# drop original column \"fuel-type\" from \"df\"\ndf_manual.drop(\"race\", axis = 1, inplace=True)\ndf_manual.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10cb022dd682b1f19513fde0b56d65fb5f78ff88"},"cell_type":"markdown","source":"## Encode \"sex\""},{"metadata":{"trusted":true,"_uuid":"75b9ab26cd0590f457b03bfa8888a7ed75499e4a"},"cell_type":"code","source":"dummy = pd.get_dummies(df_manual[\"sex\"])\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a105ee7a7dbdd5822b12caf58a40138fc81d8c0"},"cell_type":"code","source":"dummy.drop(\"Male\", axis = 1, inplace=True)\ndummy.rename(columns={ 'Female' : 'Female/Male'}, inplace = True)\n# merge data frame \"df\" and \"dummy_variable_1\" \ndf_manual = pd.concat([df_manual, dummy], axis=1)\n# drop original column \"fuel-type\" from \"df\"\ndf_manual.drop(\"sex\", axis = 1, inplace=True)\ndf_manual.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58a9ec39c4e182ea8b4e24898504094cd34589ec"},"cell_type":"markdown","source":"## Encode \"native.country\""},{"metadata":{"trusted":true,"_uuid":"f425efb6615bdb6171342fb49deb0b04e7dd6a32"},"cell_type":"code","source":"dummy = pd.get_dummies(df_manual[\"native.country\"])\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaefe022d00bcdc3c563e1560891f9c5d133d63c"},"cell_type":"code","source":"# merge data frame \"df\" and \"dummy_variable_1\" \ndf_manual = pd.concat([df_manual, dummy], axis=1)\n# drop original column \"fuel-type\" from \"df\"\ndf_manual.drop(\"native.country\", axis = 1, inplace=True)\ndf_manual.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43a2762f7df8271c1afaf0f6b8dae913d34c2533"},"cell_type":"markdown","source":"## Encode \"Income\"  (Target Variable)\n**Income > 50K = 1, otherwise 0**"},{"metadata":{"trusted":true,"_uuid":"44dfad193d8b7160122062a45f5efb4959e836aa"},"cell_type":"code","source":"dummy = pd.get_dummies(df_manual[\"income\"])\ndummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93a3eafb7b891d7d605bf4921e4757df11a0f7b4"},"cell_type":"code","source":"dummy.rename(columns={ '>50K' : 'Income > 50K'}, inplace = True)\ndummy.drop('<=50K', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad561a959331e3701272b00b03aa69bd805dd6d2"},"cell_type":"code","source":"df_manual = pd.concat([df_manual, dummy], axis=1)\ndf_manual.drop(\"income\", axis = 1, inplace=True)\ndf_manual.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c54fdece24fb598b4d1de0b813875c36eaa73673"},"cell_type":"markdown","source":"## Check for any \"object\" datatype  \n**object = string + numerical data**\n\nHere we check for any remaining categorical variables."},{"metadata":{"trusted":true,"_uuid":"aa790af139f501821cb3972e9920f6895e543351"},"cell_type":"code","source":"df_manual.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80e47b05935f471fcf5370d005bbc207d4c3de93"},"cell_type":"markdown","source":"# Lets divide out dataframe into feature variable(X) and target variable(Y)"},{"metadata":{"trusted":true,"_uuid":"91da09743ca10833f8c55a09bb846057d8ec7194"},"cell_type":"code","source":"X = df_manual.iloc[:,:-1].values\ny = df_manual[\"Income > 50K\"].iloc[:].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b3afbd0f9927cacbfea834d2308e826abf337de"},"cell_type":"markdown","source":"## After Encoding Categorical Data to Numeric Value"},{"metadata":{"trusted":true,"_uuid":"5acbe0724a0fa70dcc02d07f16f5e2c568fd3b05"},"cell_type":"code","source":"df_manual.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65080f8eb42307af05a2afab264c8a9b9ba3c4fc"},"cell_type":"markdown","source":"## Data Standardization  \n**Data standardization is the process of rescaling one or more attributes so that they have a mean value of 0 and a standard deviation of 1.**"},{"metadata":{"trusted":true,"_uuid":"0036c0194c749ff175b2cedc914f475d754069d6"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05cc808f9171800e7df739828333e04b73da33bc"},"cell_type":"markdown","source":"## See Target Variable Distribution"},{"metadata":{"trusted":true,"_uuid":"3aec293b92e8641e2f107cf175bef055011a68c5"},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0aedbaed7d39a5e76e6ac283e326e8b43c6e6f9a"},"cell_type":"markdown","source":"### Here the observation is highly imbalanced because there are more observations where Income <= 50K than >50K"},{"metadata":{"_uuid":"48a16553ce81357f2887128b09242a1861d1d8ff"},"cell_type":"markdown","source":"### Split Train Test Split"},{"metadata":{"trusted":true,"_uuid":"5272119608689f5b5acf99b2bc1837f60d0ea945"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06ecaaa11ba3ab23c8d721469608fbfa03daeda9"},"cell_type":"markdown","source":"# 3. Build Model"},{"metadata":{"_uuid":"a8c96ed43dad9ff55a9325ab903137ce9d626929"},"cell_type":"markdown","source":"## Implement XGBoost (Gradient Boosting) Classifier Model"},{"metadata":{"trusted":true,"_uuid":"6d7ffcf820bda848db6976391f8a77a46f1a3663"},"cell_type":"code","source":"from xgboost import XGBClassifier\nclassifier = XGBClassifier(learning_rate = 0.1, n_estimators = 100)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Applying k-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Model Accuracy = {:.2f}%\".format(accuracies.mean()* 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4739d37e4e6ec43231fd7d0f9bbbe9747607db50"},"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\nfig, ax = plot_confusion_matrix(conf_mat=cm,\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,\n                               cmap = 'Dark2')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a895361cc463984222063d468c9f4bd142fd06b2","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"# import lightgbm as lgb\n# d_train = lgb.Dataset(X_train, label = y_train)\n# params = {}\n# params['learning_rate'] = 0.01\n# params['boosting_type'] = 'gbdt'\n# params['objective'] = 'binary'\n# params['metric'] = 'binary_logloss'\n# params['sub_feature'] = 0.5\n# params['num_leaves'] = 10\n# params['min_data'] = 50\n# params['max_depth'] = 10\n# clf = lgb.train({},train_set = d_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60250e64ff218ed87a0ddcfe7aa6f41a76dd111a","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# #Prediction\n# y_pred=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0069ae09b995a673b308b56614c3fa6fa832d88","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# for i in range(0,y_pred.shape[0]):\n#     if y_pred[i]>=0.5:       # setting threshold to .5\n#        y_pred[i]=1\n#     else:  \n#        y_pred[i]=0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe306a29538048bfe194a05b037002257b41d665"},"cell_type":"markdown","source":"## Fixing Missing Data with ML Models"},{"metadata":{"_uuid":"6c14dd69879d11a2fde29e23cbbaedabb622066e"},"cell_type":"markdown","source":"### 1. Take all the rows from the dataframe without any missing value and make a training dataset  \n### 2. Build and Train a Model (Classifier / Regressor) with the Training Data  \n### 3. Take all rows with missing values and predict for missing value using the trained model  \n### 4. Fill the Null Values with predicted values \n### 5. Repeat above steps for all other values  "},{"metadata":{"_uuid":"cde8ebb37328371749ed61f717828222969ac203"},"cell_type":"markdown","source":"## Available Missing Values"},{"metadata":{"trusted":true,"_uuid":"1d6d7b985597778b26feb2b51fb335b4361ae294"},"cell_type":"code","source":"missing_col = []\nfor column in missing_data.columns.values.tolist():\n    if(missing_data[column].sum() > 0):\n        print(\"Column: \",column)\n        print(\"Missing Data: {} ({:.2f}%)\".format(missing_data[column].sum(), (missing_data[column].sum() * 100/ len(df))))\n        print(\"Data Type: \",df[column].dtypes)\n        print(\"\")\n        missing_col.append(column)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5e6b523ce8ee126cc5e3621b56002aa1af3d7f4"},"cell_type":"markdown","source":"## Replace \"?\" to NaN"},{"metadata":{"trusted":true,"_uuid":"5d1f28e5c678db5148b0380d84cb6c709c87ff63"},"cell_type":"code","source":"df_dl_method = pd.read_csv(\"../input/adult.csv\")\n# replace \"?\" to NaN\ndf_dl_method.replace(\"?\", np.nan, inplace = True)\ndf_dl_method.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56ee4b6d8010d7c2490da96e7559ccd558d5af95"},"cell_type":"markdown","source":"## Let's make a dataframe without any Null Values"},{"metadata":{"trusted":true,"_uuid":"9027b7c6247cc28c619dc511ad7517ef40e2c5c4"},"cell_type":"code","source":"df_without_null = df_dl_method.dropna()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea711b62ad9a7ec2cd927349b67dec715ce59317"},"cell_type":"markdown","source":"## Fix 'workclass'"},{"metadata":{"trusted":true,"_uuid":"892b6b4641a657433e9c98e84d41f46a4b52af00"},"cell_type":"code","source":"# reset index, because we droped two rows\ndf_without_null.reset_index(drop = True, inplace = True)\ndf_without_null.drop([\"occupation\", \"native.country\"], axis = 1, inplace = True)\ndf_without_null.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7070af8f892707e5133b46696e3211c65da2abca"},"cell_type":"code","source":"def encoder(dataframe, col, drop_dummy_trap = \"\"):\n    dummy = pd.get_dummies(dataframe[col])\n    dataframe = pd.concat([dataframe, dummy], axis=1)\n    if(len(drop_dummy_trap) != 0):\n        # drop original column \"fuel-type\" from \"df\"\n        dataframe.drop(drop_dummy_trap, axis = 1, inplace=True)\n    dataframe.drop(col, axis = 1, inplace = True)\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65ea40959ff21d574ffe9a4e1d43178482e690f6"},"cell_type":"code","source":"df_without_null = encoder(dataframe = df_without_null, col = \"education\", drop_dummy_trap = \"Some-college\")\n#df_without_null = encoder(df = df_without_null, col = \"occupation\", drop_dummy_trap = \"Other-service\")\ndf_without_null = encoder(dataframe = df_without_null, col = \"marital.status\", drop_dummy_trap = \"Never-married\")\ndf_without_null = encoder(dataframe = df_without_null, col = \"relationship\", drop_dummy_trap = \"Other-relative\")\ndf_without_null = encoder(dataframe = df_without_null, col = \"race\", drop_dummy_trap = \"Other\")\ndf_without_null = encoder(dataframe = df_without_null, col = \"sex\", drop_dummy_trap = \"Male\")\ndf_without_null = encoder(dataframe = df_without_null, col = \"income\", drop_dummy_trap = \"<=50K\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31e065ae93e71b5e9c8c966d33de7c05e5347b78"},"cell_type":"code","source":"X_train = df_without_null.drop([\"workclass\"], axis = 1).iloc[:].values\ny_train = df_without_null.iloc[:,1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0abd98c522384a8b70c911c734acddabffc5a45d"},"cell_type":"code","source":"df_test=df_dl_method.loc[pd.isnull(df_dl_method[\"workclass\"])]\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f4d77fb459d112276d0074041bdba74a74209b9"},"cell_type":"code","source":"df_test.drop([\"workclass\", \"occupation\", \"native.country\"], axis = 1, inplace = True)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90a5c9d70ac5073f4fbfb61b922cbe3938837996"},"cell_type":"code","source":"df_test = encoder(df_test, col = \"education\", drop_dummy_trap = \"Some-college\")\n#df_test = encoder(df_test, col = \"occupation\", drop_dummy_trap = \"Other-service\")\ndf_test = encoder(df_test, col = \"marital.status\", drop_dummy_trap = \"Never-married\")\ndf_test = encoder(df_test, col = \"relationship\", drop_dummy_trap = \"Other-relative\")\ndf_test = encoder(df_test, col = \"race\", drop_dummy_trap = \"Other\")\ndf_test = encoder(df_test, col = \"sex\", drop_dummy_trap = \"Male\")\n#df_test = encoder(df_test, col = \"native.country\", drop_dummy_trap = \"\")\ndf_test = encoder(df_test, col = \"income\", drop_dummy_trap = \"<=50K\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8592f58e1f6a1014ee62eaca000032acaee24df"},"cell_type":"code","source":"X_test = df_test.iloc[:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c88f4a092bdfd38dc0ce585ff8f6659907cfc80b"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78a518205630c306ce8db00f3fdbe7e0db0869b2"},"cell_type":"code","source":"y_train[:] = labelencoder.fit_transform(y_train[:])\ny_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"669387a86668cd80e2177c808a3eef647c35fa87"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0b6857127117ff5152d901ccaa9ebdf6cf12ef0"},"cell_type":"markdown","source":"## Predict Missing Values using XGBoost"},{"metadata":{"trusted":true,"_uuid":"1bfa6c2db69f69e76dcf1998c2097fb54359693d"},"cell_type":"code","source":"from xgboost import XGBClassifier\nclassifier = XGBClassifier(learning_rate = 0.1, n_estimators = 100)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22cce3f8ee6811c8b81c3f871508454e1c46a4c4"},"cell_type":"code","source":"decode = dict(zip(labelencoder.transform(labelencoder.classes_), labelencoder.classes_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37dbdbdd4df6062d476baacc99afec4a9337c518"},"cell_type":"code","source":"for i in range(0,y_pred.shape[0]):\n    y_pred[i] = decode[y_pred[i]]\ny_pred    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2edc5bfbbf691204ebae7d23526d09ad52ba68f5"},"cell_type":"code","source":"df_dl_method.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b201d2d153d0e69254e7ccafbfcb942cb67b1eb4"},"cell_type":"markdown","source":"## Fill the Missing Values of \"workclass\" using our Predicted Values"},{"metadata":{"trusted":true,"_uuid":"833a53764eed81e98983d71f0be62a59e5f6633e"},"cell_type":"code","source":"fill = pd.DataFrame(y_pred, columns = [\"workclass\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f2e5ead0941b335b48d80c2734da2403297666a"},"cell_type":"code","source":"j = 0\nfor i in range(0, df_dl_method.shape[0]):\n    if(pd.isnull(df_dl_method.workclass[i])):\n        df_dl_method.workclass[i] = y_pred[j]\n        j = j+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8da7aaad886b31d664eb0bf1aa788c47139f86e2"},"cell_type":"code","source":"df_dl_method.workclass.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"694f6bece18832f903dab576933f987a23f052f6"},"cell_type":"code","source":"df_viz = pd.read_csv(\"../input/adult.csv\")\n# replace \"?\" to NaN\ndf_viz.replace(\"?\", np.nan, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0ccf976750388b9ea6153a19195922d01e98902"},"cell_type":"code","source":"fig1 = plt.figure(figsize=(20,5))\ni = 1\ncolumn = \"workclass\"\n\nbad = df_viz[column].isnull().sum()\ngood = len(df_viz) - df_viz[column].isnull().sum()\nx = [bad, good]\nlabels = [\"Missing Data\", \"Good Data\"]\nexplode = (0.1, 0)\nax = fig1.add_subplot(1,2,i)\nax.pie(x,explode = explode, labels = labels, shadow = True,autopct='%1.1f%%', colors = ['#ff6666', '#99ff99'],rotatelabels = True, textprops={'fontsize': 18})\ncentre_circle = plt.Circle((0,0),0.4,color='black', fc='white',linewidth=0)\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nax.axis('equal')\nax.set_title(column + \"(before)\", fontsize = 25) \ni = i+1\n\nbad = df_dl_method[column].isnull().sum()\ngood = len(df) - df_dl_method[column].isnull().sum()\nx = [bad, good]\nlabels = [\"Missing Data\", \"Good Data\"]\nexplode = (0.1, 0)\nax = fig1.add_subplot(1,2,i)\nax.pie(x,explode = explode, labels = labels, shadow = True,autopct='%1.1f%%', colors = ['#ff6666', '#99ff99'],rotatelabels = True, textprops={'fontsize': 18})\ncentre_circle = plt.Circle((0,0),0.4,color='black', fc='white',linewidth=0)\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nax.axis('equal')\nax.set_title(column + \"(after)\", fontsize = 25)\n\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13662ad22d64a01cb62585d21c2df423f943eecd"},"cell_type":"markdown","source":"# Thank You!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}