{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "25b1e1db-8bc5-7029-f719-91da523bd121"
   },
   "source": [
    "## Introduction ##\n",
    "\n",
    "This is my first work of machine learning. the notebook is written in python and has inspired from [\"Exploring Survival on Titanic\" by Megan Risdal, a Kernel in R on Kaggle][1].\n",
    "\n",
    "\n",
    "  [1]: https://www.kaggle.com/mrisdal/titanic/exploring-survival-on-the-titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "2ce68358-02ec-556d-ba88-e773a50bc18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "\n",
    "train = pd.read_csv('../../Data/train.csv', header = 0, dtype={'Age': np.float64})\n",
    "test  = pd.read_csv('../../Data/test.csv' , header = 0, dtype={'Age': np.float64})\n",
    "full_data = [train, test]\n",
    "\n",
    "print (train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "import matplotlib.patches as patches\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "#from packages import *\n",
    "#from ml_fairness import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f9595646-65c9-6fc4-395f-0befc4d122ce"
   },
   "source": [
    "# Feature Engineering #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9b4c278b-aaca-e92c-ba77-b9b48379d1f1"
   },
   "source": [
    "## 1. Pclass ##\n",
    "there is no missing value on this feature and already a numerical value. so let's check it's impact on our train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "4680d950-cf7d-a6ae-e813-535e2247d88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n"
     ]
    }
   ],
   "source": [
    "print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e70f81c-d4e2-1823-f0ba-a7c9b46984ff"
   },
   "source": [
    "## 2. Sex ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "6729681d-7915-1631-78d2-ddf3c35a424c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n"
     ]
    }
   ],
   "source": [
    "print (train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c58b7ee-d6a1-0cc9-2346-81c47846a54a"
   },
   "source": [
    "## 3. SibSp and Parch ##\n",
    "With the number of siblings/spouse and the number of children/parents we can create new feature called Family Size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "1a537f10-7cec-d0b7-8a34-fa9975655190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FamilySize  Survived\n",
      "0           1  0.303538\n",
      "1           2  0.552795\n",
      "2           3  0.578431\n",
      "3           4  0.724138\n",
      "4           5  0.200000\n",
      "5           6  0.136364\n",
      "6           7  0.333333\n",
      "7           8  0.000000\n",
      "8          11  0.000000\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "print (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e4861d3e-10db-1a23-8728-44e4d5251844"
   },
   "source": [
    "it seems has a good effect on our prediction but let's go further and categorize people to check whether they are alone in this ship or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "8c35e945-c928-e3bc-bd9c-d6ddb287e4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   IsAlone  Survived\n",
      "0        0  0.505650\n",
      "1        1  0.303538\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "print (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2780ca4e-7923-b845-0b6b-5f68a45f6b93"
   },
   "source": [
    "good! the impact is considerable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8aa419c0-6614-7efc-7797-97f4a5158b19"
   },
   "source": [
    "## 4. Embarked ##\n",
    "the embarked feature has some missing value. and we try to fill those with the most occurred value ( 'S' )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "0e70e9af-d7cc-8c40-b7d4-2643889c376d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.339009\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "print (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e08c9ee8-d6d1-99b7-38bd-f0042c18a5d9"
   },
   "source": [
    "## 5. Fare ##\n",
    "Fare also has some missing value and we will replace it with the median. then we categorize it into 4 ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "a21335bd-4e8d-66e8-e6a5-5d2173b72d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CategoricalFare  Survived\n",
      "0   (-0.001, 7.91]  0.197309\n",
      "1   (7.91, 14.454]  0.303571\n",
      "2   (14.454, 31.0]  0.454955\n",
      "3  (31.0, 512.329]  0.581081\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "print (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ec8d1b22-a95f-9f16-77ab-7b60d2103852"
   },
   "source": [
    "## 6. Age ##\n",
    "we have plenty of missing values in this feature. # generate random numbers between (mean - std) and (mean + std).\n",
    "then we categorize age into 5 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "b90c2870-ce5d-ae0e-a33d-59e35445500e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CategoricalAge  Survived\n",
      "0  (-0.08, 16.0]  0.517241\n",
      "1   (16.0, 32.0]  0.354023\n",
      "2   (32.0, 48.0]  0.373077\n",
      "3   (48.0, 64.0]  0.434783\n",
      "4   (64.0, 80.0]  0.090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    age_avg \t   = dataset['Age'].mean()\n",
    "    age_std \t   = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    \n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "print (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd25ec3f-b601-c1cc-d701-991fac1621f9"
   },
   "source": [
    "## 7. Name ##\n",
    "inside this feature we can find the title of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "ad042f43-bfe0-ded0-4171-379d8caaa749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex       female  male\n",
      "Title                 \n",
      "Capt           0     1\n",
      "Col            0     2\n",
      "Countess       1     0\n",
      "Don            0     1\n",
      "Dr             1     6\n",
      "Jonkheer       0     1\n",
      "Lady           1     0\n",
      "Major          0     2\n",
      "Master         0    40\n",
      "Miss         182     0\n",
      "Mlle           2     0\n",
      "Mme            1     0\n",
      "Mr             0   517\n",
      "Mrs          125     0\n",
      "Ms             1     0\n",
      "Rev            0     6\n",
      "Sir            0     1\n"
     ]
    }
   ],
   "source": [
    "def get_title(name):\n",
    "\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "\t# If the title exists, extract and return it.\n",
    "\tif title_search:\n",
    "\t\treturn title_search.group(1)\n",
    "\treturn \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "\n",
    "print(pd.crosstab(train['Title'], train['Sex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca5fff8c-7a0d-6c18-2173-b8df6293c50a"
   },
   "source": [
    " so we have titles. let's categorize it and check the title impact on survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "8357238b-98fe-632a-acd5-33674a6132ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Title  Survived\n",
      "0  Master  0.575000\n",
      "1    Miss  0.702703\n",
      "2      Mr  0.156673\n",
      "3     Mrs  0.793651\n",
      "4    Rare  0.347826\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "print (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68fa2057-e27a-e252-0d1b-869c00a303ba"
   },
   "source": [
    "# Data Cleaning #\n",
    "great! now let's clean our data and map our features into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "2502bb70-ce6f-2497-7331-7d1f80521470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex  Age  Fare  Embarked  IsAlone  Title\n",
      "0         0       3    0    1     0         0        0      1\n",
      "1         1       1    1    2     3         1        0      3\n",
      "2         1       3    1    1     1         0        1      2\n",
      "3         1       1    1    2     3         0        0      3\n",
      "4         0       3    0    2     1         0        1      1\n",
      "5         0       3    0    2     1         2        1      1\n",
      "6         0       1    0    3     3         0        1      1\n",
      "7         0       3    0    0     2         0        0      4\n",
      "8         1       3    1    1     1         0        0      3\n",
      "9         1       2    1    0     2         1        0      3\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n",
    "\n",
    "# Feature Selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp',\\\n",
    "                 'Parch', 'FamilySize']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "\n",
    "test  = test.drop(drop_elements, axis = 1)\n",
    "\n",
    "print (train.head(10))\n",
    "train_df = train\n",
    "train = train.values\n",
    "test  = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8aaaf2bc-e282-79cc-008a-e2e801b51b07"
   },
   "source": [
    "good! now we have a clean dataset and ready to predict. let's find which classifier works better on this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "23b55b45-572b-7276-32e7-8f7a0dcfd25e"
   },
   "source": [
    "# Classifier Comparison #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "31ded30a-8de4-6507-e7f7-5805a0f1eaf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Classifier Accuracy'}, xlabel='Accuracy', ylabel='Classifier'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "\tAdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()]\n",
    "\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "log \t = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "X = train[0::, 1::]\n",
    "y = train[0::, 0]\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "\tX_train, X_test = X[train_index], X[test_index]\n",
    "\ty_train, y_test = y[train_index], y[test_index]\n",
    "\t\n",
    "\tfor clf in classifiers:\n",
    "\t\tname = clf.__class__.__name__\n",
    "\t\tclf.fit(X_train, y_train)\n",
    "\t\ttrain_predictions = clf.predict(X_test)\n",
    "\t\tacc = accuracy_score(y_test, train_predictions)\n",
    "\t\tif name in acc_dict:\n",
    "\t\t\tacc_dict[name] += acc\n",
    "\t\telse:\n",
    "\t\t\tacc_dict[name] = acc\n",
    "\n",
    "for clf in acc_dict:\n",
    "\tacc_dict[clf] = acc_dict[clf] / 10.0\n",
    "\tlog_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n",
    "\tlog = log.append(log_entry)\n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "438585cf-b7ad-73ba-49aa-87688ff21233"
   },
   "source": [
    "# Prediction #\n",
    "now we can use SVC classifier to predict our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "24967b57-732b-7180-bfd5-005beff75974"
   },
   "outputs": [],
   "source": [
    "candidate_classifier = SVC()\n",
    "candidate_classifier.fit(train[0::, 1::], train[0::, 0])\n",
    "result = candidate_classifier.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This DataFrame is created to stock differents models and fair metrics that we produce in this notebook\n",
    "algo_metrics = pd.DataFrame(columns=['model', 'fair_metrics', 'prediction', 'probs'])\n",
    "\n",
    "def add_to_df_algo_metrics(algo_metrics, model, fair_metrics, preds, probs, name):\n",
    "    return algo_metrics.append(pd.DataFrame(data=[[model, fair_metrics, preds, probs]], columns=['model', 'fair_metrics', 'prediction', 'probs'], index=[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_metrics(dataset, pred, pred_is_dataset=False):\n",
    "    if pred_is_dataset:\n",
    "        dataset_pred = pred\n",
    "    else:\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = pred\n",
    "    \n",
    "    cols = ['statistical_parity_difference', 'equal_opportunity_difference', 'average_abs_odds_difference',  'disparate_impact', 'theil_index']\n",
    "    obj_fairness = [[0,0,0,1,0]]\n",
    "    \n",
    "    fair_metrics = pd.DataFrame(data=obj_fairness, index=['objective'], columns=cols)\n",
    "    \n",
    "    for attr in dataset_pred.protected_attribute_names:\n",
    "        idx = dataset_pred.protected_attribute_names.index(attr)\n",
    "        privileged_groups =  [{attr:dataset_pred.privileged_protected_attributes[idx][0]}] \n",
    "        unprivileged_groups = [{attr:dataset_pred.unprivileged_protected_attributes[idx][0]}] \n",
    "        \n",
    "        classified_metric = ClassificationMetric(dataset, \n",
    "                                                     dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        metric_pred = BinaryLabelDatasetMetric(dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        acc = classified_metric.accuracy()\n",
    "\n",
    "        row = pd.DataFrame([[metric_pred.mean_difference(),\n",
    "                                classified_metric.equal_opportunity_difference(),\n",
    "                                classified_metric.average_abs_odds_difference(),\n",
    "                                metric_pred.disparate_impact(),\n",
    "                                classified_metric.theil_index()]],\n",
    "                           columns  = cols,\n",
    "                           index = [attr]\n",
    "                          )\n",
    "        fair_metrics = fair_metrics.append(row)    \n",
    "    \n",
    "    fair_metrics = fair_metrics.replace([-np.inf, np.inf], 2)\n",
    "        \n",
    "    return fair_metrics\n",
    "\n",
    "def plot_fair_metrics(fair_metrics):\n",
    "    fig, ax = plt.subplots(figsize=(20,4), ncols=5, nrows=1)\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        left    =  0.125, \n",
    "        bottom  =  0.1, \n",
    "        right   =  0.9, \n",
    "        top     =  0.9, \n",
    "        wspace  =  .5, \n",
    "        hspace  =  1.1\n",
    "    )\n",
    "\n",
    "    y_title_margin = 1.2\n",
    "\n",
    "    plt.suptitle(\"Fairness metrics\", y = 1.09, fontsize=20)\n",
    "    sns.set(style=\"dark\")\n",
    "\n",
    "    cols = fair_metrics.columns.values\n",
    "    obj = fair_metrics.loc['objective']\n",
    "    size_rect = [0.2,0.2,0.2,0.4,0.25]\n",
    "    rect = [-0.1,-0.1,-0.1,0.8,0]\n",
    "    bottom = [-1,-1,-1,0,0]\n",
    "    top = [1,1,1,2,1]\n",
    "    bound = [[-0.1,0.1],[-0.1,0.1],[-0.1,0.1],[0.8,1.2],[0,0.25]]\n",
    "\n",
    "    display(Markdown(\"### Check bias metrics :\"))\n",
    "    display(Markdown(\"A model can be considered bias if just one of these five metrics show that this model is biased.\"))\n",
    "    for attr in fair_metrics.index[1:len(fair_metrics)].values:\n",
    "        display(Markdown(\"#### For the %s attribute :\"%attr))\n",
    "        check = [bound[i][0] < fair_metrics.loc[attr][i] < bound[i][1] for i in range(0,5)]\n",
    "        display(Markdown(\"With default thresholds, bias against unprivileged group detected in **%d** out of 5 metrics\"%(5 - sum(check))))\n",
    "\n",
    "    for i in range(0,5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        ax = sns.barplot(x=fair_metrics.index[1:len(fair_metrics)], y=fair_metrics.iloc[1:len(fair_metrics)][cols[i]])\n",
    "        \n",
    "        for j in range(0,len(fair_metrics)-1):\n",
    "            a, val = ax.patches[j], fair_metrics.iloc[j+1][cols[i]]\n",
    "            marg = -0.2 if val < 0 else 0.1\n",
    "            ax.text(a.get_x()+a.get_width()/5, a.get_y()+a.get_height()+marg, round(val, 3), fontsize=15,color='black')\n",
    "\n",
    "        plt.ylim(bottom[i], top[i])\n",
    "        plt.setp(ax.patches, linewidth=0)\n",
    "        ax.add_patch(patches.Rectangle((-5,rect[i]), 10, size_rect[i], alpha=0.3, facecolor=\"green\", linewidth=1, linestyle='solid'))\n",
    "        plt.axhline(obj[i], color='black', alpha=0.3)\n",
    "        plt.title(cols[i])\n",
    "        ax.set_ylabel('')    \n",
    "        ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fair_metrics_and_plot(data, model, plot=False, model_aif=False):\n",
    "    pred = model.predict(data).labels if model_aif else model.predict(data.features)\n",
    "    # fair_metrics function available in the metrics.py file\n",
    "    fair = fair_metrics(data, pred)\n",
    "\n",
    "    if plot:\n",
    "        # plot_fair_metrics function available in the visualisations.py file\n",
    "        # The visualisation of this function is inspired by the dashboard on the demo of IBM aif360 \n",
    "        plot_fair_metrics(fair)\n",
    "        display(fair)\n",
    "    \n",
    "    return fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  Fare  Embarked  IsAlone  Title\n",
       "0           0       3    0    1     0         0        0      1\n",
       "1           1       1    1    2     3         1        0      3\n",
       "2           1       3    1    1     1         0        1      2\n",
       "3           1       1    1    2     3         0        0      3\n",
       "4           0       3    0    2     1         0        1      1\n",
       "..        ...     ...  ...  ...   ...       ...      ...    ...\n",
       "886         0       2    0    1     1         0        1      5\n",
       "887         1       1    1    1     2         0        1      2\n",
       "888         0       3    1    2     2         0        0      2\n",
       "889         1       1    0    1     2         1        1      1\n",
       "890         0       3    0    1     0         2        1      1\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##train['Sex'] = train['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "train_df\n",
    "\n",
    "#features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Survived\"]\n",
    "#X = pd.get_dummies(train_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Sex': 1}]\n",
    "unprivileged_groups = [{'Sex': 0}]\n",
    "dataset_orig = StandardDataset(train_df,\n",
    "                                  label_name='Survived',\n",
    "                                  protected_attribute_names=['Sex'],\n",
    "                                  favorable_classes=[1],\n",
    "                                  privileged_classes=[[1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.553130\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "nb_fname = ipynbname.name()\n",
    "nb_path = ipynbname.path()\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pickle\n",
    "\n",
    "data_orig_train, data_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "X_train = data_orig_train.features\n",
    "y_train = data_orig_train.labels.ravel()\n",
    "\n",
    "X_test = data_orig_test.features\n",
    "y_test = data_orig_test.labels.ravel()\n",
    "num_estimators = 100\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=1)\n",
    "\n",
    "mdl = model.fit(X_train, y_train)\n",
    "with open('../../Results/AdaBoost/' + nb_fname + '.pkl', 'wb') as f:\n",
    "        pickle.dump(mdl, f)\n",
    "\n",
    "with open('../../Results/AdaBoost/' + nb_fname + '_Train' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_train, f) \n",
    "    \n",
    "with open('../../Results/AdaBoost/' + nb_fname + '_Test' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_test, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "final_metrics = []\n",
    "accuracy = []\n",
    "f1= []\n",
    "\n",
    "for i in range(1,num_estimators+1):\n",
    "    \n",
    "    model = AdaBoostClassifier(n_estimators=i)\n",
    "    \n",
    "    mdl = model.fit(X_train, y_train)\n",
    "    yy = mdl.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, yy))\n",
    "    f1.append(f1_score(y_test, yy))\n",
    "    fair = get_fair_metrics_and_plot(data_orig_test, mdl)                           \n",
    "    fair_list = fair.iloc[1].tolist()\n",
    "    fair_list.insert(0, i)\n",
    "    final_metrics.append(fair_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>...</th>\n",
       "      <th>T90</th>\n",
       "      <th>T91</th>\n",
       "      <th>T92</th>\n",
       "      <th>T93</th>\n",
       "      <th>T94</th>\n",
       "      <th>T95</th>\n",
       "      <th>T96</th>\n",
       "      <th>T97</th>\n",
       "      <th>T98</th>\n",
       "      <th>T99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.764925</td>\n",
       "      <td>0.764925</td>\n",
       "      <td>0.779851</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.779851</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.729614</td>\n",
       "      <td>0.729614</td>\n",
       "      <td>0.735426</td>\n",
       "      <td>0.621469</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.730594</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.729858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.867052</td>\n",
       "      <td>-0.867052</td>\n",
       "      <td>-0.908549</td>\n",
       "      <td>-0.489565</td>\n",
       "      <td>-0.578096</td>\n",
       "      <td>-0.947977</td>\n",
       "      <td>-0.708549</td>\n",
       "      <td>-0.799574</td>\n",
       "      <td>-0.793794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.793794</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.793794</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.793794</td>\n",
       "      <td>-0.814846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.731707</td>\n",
       "      <td>-0.731707</td>\n",
       "      <td>-0.766974</td>\n",
       "      <td>-0.477917</td>\n",
       "      <td>-0.531641</td>\n",
       "      <td>-0.853659</td>\n",
       "      <td>-0.759064</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>-0.775214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_abs_odds_difference</th>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.820399</td>\n",
       "      <td>0.820399</td>\n",
       "      <td>0.864548</td>\n",
       "      <td>0.322833</td>\n",
       "      <td>0.370799</td>\n",
       "      <td>0.915466</td>\n",
       "      <td>0.539705</td>\n",
       "      <td>0.675223</td>\n",
       "      <td>0.671435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.671435</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.671435</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.671435</td>\n",
       "      <td>0.702001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disparate_impact</th>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.017797</td>\n",
       "      <td>-2.017797</td>\n",
       "      <td>-2.503652</td>\n",
       "      <td>-2.248073</td>\n",
       "      <td>-1.713065</td>\n",
       "      <td>-2.956067</td>\n",
       "      <td>-2.277845</td>\n",
       "      <td>-2.608239</td>\n",
       "      <td>-2.521227</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.521227</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.521227</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.521227</td>\n",
       "      <td>-2.545325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil_index</th>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.157679</td>\n",
       "      <td>0.157679</td>\n",
       "      <td>0.164565</td>\n",
       "      <td>0.265484</td>\n",
       "      <td>0.193705</td>\n",
       "      <td>0.171370</td>\n",
       "      <td>0.193705</td>\n",
       "      <td>0.181456</td>\n",
       "      <td>0.182624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.182624</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.182624</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.182624</td>\n",
       "      <td>0.179316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               classifier        T0        T1        T2  \\\n",
       "accuracy                         0.787313  0.764925  0.764925  0.779851   \n",
       "f1                               0.729858  0.729614  0.729614  0.735426   \n",
       "statistical_parity_difference   -0.814846 -0.867052 -0.867052 -0.908549   \n",
       "equal_opportunity_difference    -0.775214 -0.731707 -0.731707 -0.766974   \n",
       "average_abs_odds_difference      0.702001  0.820399  0.820399  0.864548   \n",
       "disparate_impact                -2.545325 -2.017797 -2.017797 -2.503652   \n",
       "theil_index                      0.179316  0.157679  0.157679  0.164565   \n",
       "\n",
       "                                     T3        T4        T5        T6  \\\n",
       "accuracy                       0.750000  0.783582  0.779851  0.783582   \n",
       "f1                             0.621469  0.715686  0.730594  0.715686   \n",
       "statistical_parity_difference -0.489565 -0.578096 -0.947977 -0.708549   \n",
       "equal_opportunity_difference  -0.477917 -0.531641 -0.853659 -0.759064   \n",
       "average_abs_odds_difference    0.322833  0.370799  0.915466  0.539705   \n",
       "disparate_impact              -2.248073 -1.713065 -2.956067 -2.277845   \n",
       "theil_index                    0.265484  0.193705  0.171370  0.193705   \n",
       "\n",
       "                                     T7        T8  ...       T90       T91  \\\n",
       "accuracy                       0.791045  0.787313  ...  0.787313  0.787313   \n",
       "f1                             0.730769  0.727273  ...  0.729858  0.729858   \n",
       "statistical_parity_difference -0.799574 -0.793794  ... -0.814846 -0.814846   \n",
       "equal_opportunity_difference  -0.761701 -0.761701  ... -0.775214 -0.775214   \n",
       "average_abs_odds_difference    0.675223  0.671435  ...  0.702001  0.702001   \n",
       "disparate_impact              -2.608239 -2.521227  ... -2.545325 -2.545325   \n",
       "theil_index                    0.181456  0.182624  ...  0.179316  0.179316   \n",
       "\n",
       "                                    T92       T93       T94       T95  \\\n",
       "accuracy                       0.787313  0.787313  0.787313  0.787313   \n",
       "f1                             0.729858  0.727273  0.729858  0.729858   \n",
       "statistical_parity_difference -0.814846 -0.793794 -0.814846 -0.814846   \n",
       "equal_opportunity_difference  -0.775214 -0.761701 -0.775214 -0.775214   \n",
       "average_abs_odds_difference    0.702001  0.671435  0.702001  0.702001   \n",
       "disparate_impact              -2.545325 -2.521227 -2.545325 -2.545325   \n",
       "theil_index                    0.179316  0.182624  0.179316  0.179316   \n",
       "\n",
       "                                    T96       T97       T98       T99  \n",
       "accuracy                       0.787313  0.787313  0.787313  0.787313  \n",
       "f1                             0.727273  0.729858  0.727273  0.729858  \n",
       "statistical_parity_difference -0.793794 -0.814846 -0.793794 -0.814846  \n",
       "equal_opportunity_difference  -0.761701 -0.775214 -0.761701 -0.775214  \n",
       "average_abs_odds_difference    0.671435  0.702001  0.671435  0.702001  \n",
       "disparate_impact              -2.521227 -2.545325 -2.521227 -2.545325  \n",
       "theil_index                    0.182624  0.179316  0.182624  0.179316  \n",
       "\n",
       "[7 rows x 101 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "final_result = pd.DataFrame(final_metrics)\n",
    "final_result[4] = np.log(final_result[4])\n",
    "final_result = final_result.transpose()\n",
    "final_result.loc[0] = f1  # add f1 and acc to df\n",
    "acc = pd.DataFrame(accuracy).transpose()\n",
    "acc = acc.rename(index={0: 'accuracy'})\n",
    "final_result = pd.concat([acc,final_result])\n",
    "final_result = final_result.rename(index={0: 'f1', 1: 'statistical_parity_difference', 2: 'equal_opportunity_difference', 3: 'average_abs_odds_difference', 4: 'disparate_impact', 5: 'theil_index'})\n",
    "final_result.columns = ['T' + str(col) for col in final_result.columns]\n",
    "final_result.insert(0, \"classifier\", final_result['T' + str(num_estimators - 1)])   ##Add final metrics add the beginning of the df\n",
    "final_result.to_csv('../../Results/AdaBoost/' + nb_fname + '.csv')\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
