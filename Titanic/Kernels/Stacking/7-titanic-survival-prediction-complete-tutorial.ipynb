{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction\n",
    "\n",
    "1. [Import Libraries](#heading1)\n",
    "2. [Read Data](#heading2)\n",
    "3. [Data Cleaning & Feature Engineering](#heading3)\n",
    "4. [Exploratory Data Analysis](#heading4)\n",
    "5. [Model Building & Evaluation](#heading5)\n",
    "  * [Logistic Regression](#subheading1)\n",
    "  * [Gaussian Naive Bayes](#subheading2)\n",
    "  * [Linear Discriminant Analysis (LDA)](#subheading3)\n",
    "  * [k Nearest Neighbors (kNN)](#subheading4)\n",
    "  * [Support Vector Machine (SVM)](#subheading5)\n",
    "  * [Decision Tree](#subheading6)\n",
    "  * [Random Forest](#subheading7)\n",
    "  * [XGBoost](#subheading8)\n",
    "  * [Model Stacking](#subheading9)\n",
    "  * [Result Comparison](#subheading10)\n",
    "6. [Conclusion](#heading6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries <a id=\"heading1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "import matplotlib.patches as patches\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "#from packages import *\n",
    "#from ml_fairness import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed value for reproducing the same results\n",
    "seed = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read Data <a id=\"heading2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../Data/train.csv\")\n",
    "test_data = pd.read_csv(\"../../Data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data preview\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data preview\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the 'Survived' column is missing in the test set. We have to predict that label for each passenger in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Summary of train data\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Summary of test data\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning & Feature Engineering <a id=\"heading3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data descriptive statistics\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data descriptive statistics\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both train and test datasets, the statistics for 'Fare' column seem a bit strange. The minimum fare is 0 and the maximum is around 512, with 75% of values less than 31.5 and the mean being 35.6. We need to analyze this further to see if there are any outliers.\n",
    "\n",
    "For this purpose, we can make use of a boxplot. It will help us understand the variation in the 'Fare' values by visually displaying the distribution of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAE/CAYAAAAezyd8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX4UlEQVR4nO3dcbBW9X3n8fcX0MuqqQiyVMWIO3HaDUhrvWPSaWa3JgsEk4IzttmU7sZE91Ig3s2OOlWxM2lmtzTZVrPJ3codElN0t6lx0mZls+4Km5hmMsY01zQrElaDjEbQxCtwSYDF4vW7fzzn4gNy4cK9N+f8uO/XzDP3nN/5nXO+D8zlw+93znOeyEwkSSrFpLoLkCTpZBhckqSiGFySpKIYXJKkohhckqSiGFySpKIYXNI4iYiMiLf9HM4TEfEXEbEnIv5uvM8n1c3g0mkvIp6LiP8XEfuqf9z/R0RcXHddQyLiwxHxrVEc4l3AAmB2Zl41zPEHq/c/9PrPozifVCuDSxPFb2XmOcAFwE+AnprrGUuXAM9l5v7j9Pl2Zp7T9rrpZE4QEVNGV6I0dgwuTSiZeRD4MvD2obaIODci7o+I/oh4PiL+MCImRcT0iNgREb9V9TsnIrZFxIeq9fUR0RsRmyLiZxHxtxFxybHOe5xz/FOgF/j1aiQ0MMz+F0bEhojYXdXQVbXfCHy+bf9PjPTPIiI+EhFbq9q3R8Tvt237zeq93xYRPwb+oqr39oh4NiJ2RcSDETF9pOeTxor/i9KEEhFnAf8SeLytuQc4F/gnwAxgI/BSZt4bETcA90fEfOCPge9n5v1t+/4e8D7gO8B/BP6S1tTd0Y53jhXAv8nMY+035AHgKeBC4JeBTRHxbLX/4Aj2P5aXgfcD24F/BvzPiPhuZn6v2v6LwHRaI7pJQDdwLfDPgX7gs8CfA797kueVRiczffk6rV/Ac8A+YAA4BLwIXF5tmwz8A/D2tv6/D3yjbb0H2AzsBGa0ta8HHmhbPwcYBC6u1hN424nOAXwY+NZx6r+4Ou5b2tr+BFg/wv0/DLxWvf+h1zuP0e+/AR+rln+zqnlq2/atwHva1i+o/jyn1P137GtivZwq1ERxbWZOA6YCNwF/GxG/CJwPnAE839b3eeCitvV1wDxaQbHrqOO+MLSQmfuA3bRGRe1Gco7juRDYnZk/O8X9AR7PzGltr8cjYnFEPF5NPw4A11S1DunP1tTqkEuAr0TEQNV/K61AnXUSdUijZnBpQsnMwcz8G1r/4L4LeIXWqKH92tRbaY2uiIjJtILrfmDVMW5vP3x3YkScQ2tq7cWj+hz3HLRGZsfzIjA9It4yzP4nLSI6gL8G/gyYVYX6w0C0dTu6rheAxUcF4NTMPOU6pFNhcGlCqT7ztBQ4D9iamYPAg8AfR8Rbqpsrbgb+a7XLalr/gN8A/Cmt612T2w55TUS8KyLOBP49rZHNC23bGcE5fgLMro7xJtXxHgP+JCKmVtfbbmzb/1ScCXTQulb1WkQsBhaeYJ/e6j1cAhARM6s/S+nnyuDSRPHfI2If8FNaN1lcn5lbqm3dwH5aNyl8C/gi8IWIuJJWwHyoCp9P0Qqx29uO+0Xg47SmCK8E/tUw5z/mOaptXwe2AD+OiFeG2f93gTm0Rl9fAT6emf97pG/+aNW047+lFah7gGXAhhPs9pmqz8aI+BmtG1zecao1SKcqMv0iSelURMR6YEdm/mHdtUgTiSMuSVJRDC5JUlGcKpQkFcURlySpKAaXJKkojXhW4fnnn59z5sypuwxJUoM88cQTr2TmzKPbGxFcc+bMoa+vr+4yJEkNEhHPH6vdqUJJUlEMLklSUQwuSVJRDC5JUlEMLklSUQwuSVJRDC5JUlEMLqkBFi1axKRJk4gIJk2axKJFi+ouSWosg0uq2aJFi9i4cSMrVqxgYGCAFStWsHHjRsNLGkYjnpwhTWSbNm1i5cqV3HPPPQCHf/b29tZZltRYjfhak87OzvSRT5qoIoKBgQHOPffcw2179+5l2rRpNOH3U6pLRDyRmZ1HtztVKNUsIrjjjjuOaLvjjjuIiJoqkprN4JJqtmDBAtauXcuqVavYu3cvq1atYu3atSxYsKDu0qRGGtFUYUQ8B/wMGARey8zOiJgOfAmYAzwHfCAz90Trv4mfAa4BDgAfzszvHe/4ThVqolu0aBGbNm0iM4kIFixYwCOPPFJ3WVKthpsqPJmbM67OzFfa1m8HvpaZn4yI26v124DFwGXV6x3A2uqnpGEYUtLIjWaqcClwX7V8H3BtW/v92fI4MC0iLhjFeSRJOmykwZXAxoh4IiKWV22zMvOlavnHwKxq+SLghbZ9d1RtR4iI5RHRFxF9/f39p1C6JGkiGulU4bsyc2dE/GNgU0T83/aNmZkRcVL37WbmOmAdtK5xncy+kqSJa0QjrszcWf18GfgKcBXwk6EpwOrny1X3ncDFbbvPrtokSRq1EwZXRJwdEW8ZWgYWAk8BG4Drq27XAw9VyxuAD0XLO4G9bVOKkiSNykimCmcBX6k+DDkF+GJm/q+I+C7wYETcCDwPfKDq/zCtW+G30bod/iNjXrUkacI6YXBl5nbgV47Rvgt4zzHaE/jomFQnSdJRfHKGJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKkoBpckqSgGlySpKCMOroiYHBF/HxFfrdYvjYjvRMS2iPhSRJxZtXdU69uq7XPGqXZJ0gR0MiOujwFb29Y/BXw6M98G7AFurNpvBPZU7Z+u+kmSNCZGFFwRMRt4H/D5aj2AdwNfrrrcB1xbLS+t1qm2v6fqL0nSqI10xPWfgD8AXq/WZwADmflatb4DuKhavgh4AaDavrfqL0nSqJ0wuCLi/cDLmfnEWJ44IpZHRF9E9PX394/loSVJp7GRjLh+A1gSEc8BD9CaIvwMMC0iplR9ZgM7q+WdwMUA1fZzgV1HHzQz12VmZ2Z2zpw5c1RvQpI0cZwwuDLzjsycnZlzgA8CX8/M3wMeBX676nY98FC1vKFap9r+9czMMa1akjRhjeZzXLcBN0fENlrXsO6t2u8FZlTtNwO3j65ESZLeMOXEXd6Qmd8AvlEtbweuOkafg8DvjEFtkiS9iU/OkCQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFcXgkiQVxeCSJBXF4JIkFeWEwRURUyPi7yLi/0TEloj4RNV+aUR8JyK2RcSXIuLMqr2jWt9WbZ8zzu9BkjSBjGTE9Srw7sz8FeBXgfdGxDuBTwGfzsy3AXuAG6v+NwJ7qvZPV/0kSRoTJwyubNlXrZ5RvRJ4N/Dlqv0+4NpqeWm1TrX9PRERY1WwJGliG9E1roiYHBHfB14GNgHPAgOZ+VrVZQdwUbV8EfACQLV9LzBjDGuWJE1gIwquzBzMzF8FZgNXAb882hNHxPKI6IuIvv7+/tEeTpI0QZzUXYWZOQA8Cvw6MC0iplSbZgM7q+WdwMUA1fZzgV3HONa6zOzMzM6ZM2eeWvWSpAlnJHcVzoyIadXyPwIWAFtpBdhvV92uBx6qljdU61Tbv56ZOYY1S5ImsCkn7sIFwH0RMZlW0D2YmV+NiB8AD0TEfwD+Hri36n8v8F8iYhuwG/jgONQtSZqgThhcmfkkcMUx2rfTut51dPtB4HfGpDpJko7ikzMkSUUxuCRJRTG4JElFMbgkSUUxuCRJRTG4JElFMbgkSUUxuCRJRTG4JElFMbgkSUUxuKQGmDFjBhFx+DVjhl9hJw3H4JJqNmPGDHbv3s3cuXN5/vnnmTt3Lrt37za8pGGM5OnwksbRUGg99dRTADz11FPMmzePLVu21FyZ1EyOuKQGePjhh4+7LukNBpfUANdcc81x1yW9weCSajZ9+nS2bNnCvHnz+NGPfnR4mnD69Ol1lyY1kte4pJrt2rWLGTNmsGXLFi655BKgFWa7du2quTKpmRxxSQ2wbNkyOjo6AOjo6GDZsmU1VyQ1l8El1ay7u5ve3l7WrFnD/v37WbNmDb29vXR3d9ddmtRIkZl110BnZ2f29fXVXYZUi6lTp7JmzRpuvvnmw2133303q1ev5uDBgzVWJtUrIp7IzM43tRtcUr0igv3793PWWWcdbjtw4ABnn302Tfj9lOoyXHA5VSjVrKOjg97e3iPaent7D1/zknQk7yqUatbV1cVtt90GwIoVK+jt7eW2225jxYoVNVcmNZPBJdWsp6cHgNWrV3PLLbfQ0dHBihUrDrdLOpLXuCRJjeQ1LknSacHgkiQVxeCSGmD+/PlHfJHk/Pnz6y5JaiyDS6rZ/Pnz2bx5M0uWLKG/v58lS5awefNmw0sahsEl1Wzz5s1cccUVPPvss8yaNYtnn32WK664gs2bN9ddmtRIBpfUALt27aKnp4eDBw/S09Pjk+Gl4zC4pAaYPXs2V199NWeccQZXX301s2fPrrskqbEMLqkBHnvsMZYuXcorr7zC0qVLeeyxx+ouSWosn5wh1Wzu3LkcOHCADRs2MHPmTAAuvfTSIx66K+kNjrikmt15553s27ePOXPmEBHMmTOHffv2ceedd9ZdmtRIjrikBhgYGKC/vx+A5557jjPOOKPmiqTmcsQl1ayrq4tDhw6xcuVKBgYGWLlyJYcOHaKrq6vu0qRGcsQl1Wz//v0sX76ce+65B4B77rmHwcFB1q1bV3NlUjM54pIa4P3vf/9x1yW94YTBFREXR8SjEfGDiNgSER+r2qdHxKaI+GH187yqPSLisxGxLSKejIhfG+83IZVu2bJlPProoxw6dIhHH32UZcuW1V2S1FgjGXG9BtySmW8H3gl8NCLeDtwOfC0zLwO+Vq0DLAYuq17LgbVjXrV0Glm4cCH79u3juuuu48wzz+S6665j3759LFy4sO7SpEY6YXBl5kuZ+b1q+WfAVuAiYClwX9XtPuDaankpcH+2PA5Mi4gLxrpw6XTxyCOPsHDhQgYGBoDWHYYLFy7kkUceqbcwqaFO6uaMiJgDXAF8B5iVmS9Vm34MzKqWLwJeaNttR9X2EpKOyZCSRm7EN2dExDnAXwP/LjN/2r4tMxPIkzlxRCyPiL6I6Bv6/IokSScyouCKiDNohdZfZubfVM0/GZoCrH6+XLXvBC5u23121XaEzFyXmZ2Z2Tn0mBtJkk5kJHcVBnAvsDUz727btAG4vlq+Hniorf1D1d2F7wT2tk0pSpI0KiO5xvUbwL8GNkfE96u21cAngQcj4kbgeeAD1baHgWuAbcAB4CNjWbAkaWI7YXBl5reAGGbze47RP4GPjrIuSZKOySdnSJKKYnBJkopicEmSimJwSZKKYnBJkopicEmSimJwSZKKYnBJkopicEmSimJwSQ3Q3d3N1KlTiQimTp1Kd3d33SVJjWVwSTXr7u6mt7eXNWvWsH//ftasWUNvb6/hJQ0jWo8WrFdnZ2f29fXVXYZUi6lTp7JmzRpuvvnmw2133303q1ev5uDBgzVWJtUrIp7IzM43tRtcUr0igv3793PWWWcdbjtw4ABnn302Tfj9lOoyXHA5VSjVrKOjg97e3iPaent76ejoqKkiqdkMLqlmXV1d3HrrrUTE4dett95KV1dX3aVJjWRwSTV75pln3jQlmJk888wzNVUkNZvBJdVs48aNACxZsoT+/n6WLFlyRLukIxlcUgMsXryYhx56iPPPP5+HHnqIxYsX112S1FgGl9QA27dvP+IDyNu3b6+7JKmxDC6pAZ5++mmuvPJKXnzxRa688kqefvrpukuSGmtK3QVIannssce48MIL6y5DajxHXFIDzJ0797jrkt5gcEk16+jo4IYbbiAzD79uuOEGP4AsDcPgkmrW1dXFLbfccsQHkG+55RY/gCwNw+CSajbcB439ALJ0bAaXVDM/gCydHINLagA/gCyNnMElNcCsWbOOuy7pDQaX1ADr169n1apV7N27l1WrVrF+/fq6S5Iay+CSanb55ZcDsHbtWqZNm8batWuPaJd0JINLqtmTTz75ppC6/PLLefLJJ2uqSGo2g0uSVBSDS6rZ/Pnz2bx58xG3w2/evJn58+fXXZrUSAaXVLOh0Gq/HX4ovCS9mcElNcDAwACTJk0iIpg0aRIDAwN1lyQ1ll9rIjXAN7/5zcPLmXnEuqQjOeKSJBXF4JIkFcXgkhrirrvuYv/+/dx11111lyI12gmDKyK+EBEvR8RTbW3TI2JTRPyw+nle1R4R8dmI2BYRT0bEr41n8dLpZNu2bRw6dIht27bVXYrUaCMZca0H3ntU2+3A1zLzMuBr1TrAYuCy6rUcWDs2ZUqnv6Mf+STp2E4YXJn5TWD3Uc1Lgfuq5fuAa9va78+Wx4FpEXHBGNUqnZYmT558Uu3SRHeq17hmZeZL1fKPgaHvYLgIeKGt346qTdIwVq5cSUQcDqrJkycTEaxcubLmyqRmGvXNGZmZQJ7sfhGxPCL6IqKvv79/tGVIxerp6WHevHkMDg4CMDg4yLx58+jp6am5MqmZTjW4fjI0BVj9fLlq3wlc3NZvdtX2Jpm5LjM7M7Nz5syZp1iGVL7u7m62bt16xF2FW7dupbu7u+7SpEaK1oDpBJ0i5gBfzcx51fqfArsy85MRcTswPTP/ICLeB9wEXAO8A/hsZl51ouN3dnZmX1/fKN6GVK6pU6fy2muvHR5xQWu6cMqUKRw8eLDGyqR6RcQTmdl5dPtIbof/K+DbwC9FxI6IuBH4JLAgIn4I/ItqHeBhYDuwDfgcsGqM6pdOW6+++iqDg4PMmjWLrVu3MmvWLAYHB3n11VfrLk1qpBGNuMabIy5NZEMP1s1MMpOIICJ4/fXXacLvp1SX4UZcPmRXaoDXX3/98PJQgEk6Nh/5JEkqisElSSqKwSVJKorBJUkqisElSSqKwSVJKorBJUkqisElSSqKwSVJKorBJUkqisElSSqKzyqUxkFE1HIcn3GoicARlzQOhh6UO5LXTTfddMxj3HTTTSd1HENLE4UjLqlmPT09AHzuc5/j1VdfpaOjg66ursPtko7k93FJDRIRjpykyil/A7IkSU1icEmSimJwSZKKYnBJkopicEmSimJwSZKKYnBJkopicEmSimJwSZKKYnBJkopicEmSimJwSZKK4tPhpWFMnz6dPXv2/NzPO1bf5XUyzjvvPHbv3v1zP690KgwuaRh79uyZME9qryMspVPlVKEkqSgGlySpKAaXJKkoBpckqSgGlySpKAaXJKko3g4vDSM//gvwR+fWXcbPRX78F+ouQRoxg0saRnzipxPqc1z5R3VXIY2MU4WSpKIYXJKkoozLVGFEvBf4DDAZ+HxmfnI8ziONt4nyKKTzzjuv7hKkERvz4IqIycCfAwuAHcB3I2JDZv5grM8ljac6rm9FxIS5riadqvGYKrwK2JaZ2zPzH4AHgKXjcB5J0gQ0HlOFFwEvtK3vAN5xdKeIWA4sB3jrW986DmVI9RnNFONo9nW0pomgttvhM3MdsA6gs7PT3zadVgwQafyMx1ThTuDitvXZVZskSaM2HsH1XeCyiLg0Is4EPghsGIfzSJImoDGfKszM1yLiJuARWrfDfyEzt4z1eSRJE9O4XOPKzIeBh8fj2JKkic0nZ0iSimJwSZKKYnBJkopicEmSimJwSZKKYnBJkopicEmSihJNeKZaRPQDz9ddh9QA5wOv1F2E1BCXZObMoxsbEVySWiKiLzM7665DajKnCiVJRTG4JElFMbikZllXdwFS03mNS5JUFEdckqSiGFxSA0TEFyLi5Yh4qu5apKYzuKRmWA+8t+4ipBIYXFIDZOY3gd111yGVwOCSJBXF4JIkFcXgkiQVxeCSJBXF4JIaICL+Cvg28EsRsSMibqy7JqmpfHKGJKkojrgkSUUxuCRJRTG4JElFMbgkSUUxuCRJRTG4JElFMbgkSUUxuCRJRfn/HnNUb5rBkHMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(7, 5))\n",
    "plt.boxplot(train_data['Fare'])\n",
    "plt.title('Boxplot of Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are a few extreme data points. Let's explore this further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ward, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mr. Thomas Drake Martinez</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Lesurer, Mr. Gustave J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B101</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                Name  \\\n",
       "258          259         1       1                    Ward, Miss. Anna   \n",
       "679          680         1       1  Cardeza, Mr. Thomas Drake Martinez   \n",
       "737          738         1       1              Lesurer, Mr. Gustave J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch    Ticket      Fare        Cabin Embarked  \n",
       "258  female  35.0      0      0  PC 17755  512.3292          NaN        C  \n",
       "679    male  36.0      0      1  PC 17755  512.3292  B51 B53 B55        C  \n",
       "737    male  35.0      0      0  PC 17755  512.3292         B101        C  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve rows with Fare greater than 500\n",
    "train_data[train_data['Fare']>500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all of the passengers have the same ticket number, we can conclude that the fare was calculated for the entire group and not each individual. Hence, we will not discard these rows.\n",
    "\n",
    "To standardize the fare calculation across all passengers in the dataset, the obvious step would be to divide fare by the number of people on the same ticket and get the individual fare. But factors such as reduced fares for children, missing values, etc., will further complicate things. Therefore, we will leave it as it is. For an in-depth understanding of the titanic dataset (particularly fare calculation), you can explore [Encyclopedia Titanica](https://www.encyclopedia-titanica.org/).\n",
    "\n",
    "Before we proceed further, we also need to analyze passengers who had 0 fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Leonard, Mr. Lionel</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Harrison, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B94</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Parkes, Mr. Francis \"Frank\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. William Cahoone Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cunningham, Mr. Alfred Fleming</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Campbell, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>598</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Parr, Mr. William Henry Marsh</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>675</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Watson, Mr. Ennis Hastings</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>733</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Knight, Mr. Robert J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>807</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>816</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fry, Mr. Richard</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B102</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>823</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Reuchlin, Jonkheer. John George</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                              Name   Sex  \\\n",
       "179          180         0       3               Leonard, Mr. Lionel  male   \n",
       "263          264         0       1             Harrison, Mr. William  male   \n",
       "271          272         1       3      Tornquist, Mr. William Henry  male   \n",
       "277          278         0       2       Parkes, Mr. Francis \"Frank\"  male   \n",
       "302          303         0       3   Johnson, Mr. William Cahoone Jr  male   \n",
       "413          414         0       2    Cunningham, Mr. Alfred Fleming  male   \n",
       "466          467         0       2             Campbell, Mr. William  male   \n",
       "481          482         0       2  Frost, Mr. Anthony Wood \"Archie\"  male   \n",
       "597          598         0       3               Johnson, Mr. Alfred  male   \n",
       "633          634         0       1     Parr, Mr. William Henry Marsh  male   \n",
       "674          675         0       2        Watson, Mr. Ennis Hastings  male   \n",
       "732          733         0       2              Knight, Mr. Robert J  male   \n",
       "806          807         0       1            Andrews, Mr. Thomas Jr  male   \n",
       "815          816         0       1                  Fry, Mr. Richard  male   \n",
       "822          823         0       1   Reuchlin, Jonkheer. John George  male   \n",
       "\n",
       "      Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n",
       "179  36.0      0      0    LINE   0.0   NaN        S  \n",
       "263  40.0      0      0  112059   0.0   B94        S  \n",
       "271  25.0      0      0    LINE   0.0   NaN        S  \n",
       "277   NaN      0      0  239853   0.0   NaN        S  \n",
       "302  19.0      0      0    LINE   0.0   NaN        S  \n",
       "413   NaN      0      0  239853   0.0   NaN        S  \n",
       "466   NaN      0      0  239853   0.0   NaN        S  \n",
       "481   NaN      0      0  239854   0.0   NaN        S  \n",
       "597  49.0      0      0    LINE   0.0   NaN        S  \n",
       "633   NaN      0      0  112052   0.0   NaN        S  \n",
       "674   NaN      0      0  239856   0.0   NaN        S  \n",
       "732   NaN      0      0  239855   0.0   NaN        S  \n",
       "806  39.0      0      0  112050   0.0   A36        S  \n",
       "815   NaN      0      0  112058   0.0  B102        S  \n",
       "822  38.0      0      0   19972   0.0   NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve rows with Fare equal to 0\n",
    "train_data[train_data['Fare']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it looks like there are no data errors; just some passengers who got a free ride for whatever reason (visit Encyclopedia Titanica if you're interested to find out why).\n",
    "\n",
    "Next, we will check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of missing values in each column in train data\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of missing values in each column in test data\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's deal with the missing 'Age' values. For that purpose, we will first extract title of each passenger from their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract title from passenger's name\n",
    "def extract_title(df):\n",
    "    title = df['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip())\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            182\n",
       "Mrs             125\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Major             2\n",
       "Mlle              2\n",
       "Col               2\n",
       "Don               1\n",
       "the Countess      1\n",
       "Lady              1\n",
       "Jonkheer          1\n",
       "Sir               1\n",
       "Ms                1\n",
       "Mme               1\n",
       "Capt              1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of each title in train data\n",
    "train_data['Title'] = extract_title(train_data)\n",
    "train_data['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            182\n",
       "Mrs             125\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Major             2\n",
       "Mlle              2\n",
       "Col               2\n",
       "Don               1\n",
       "the Countess      1\n",
       "Lady              1\n",
       "Jonkheer          1\n",
       "Sir               1\n",
       "Ms                1\n",
       "Mme               1\n",
       "Capt              1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of each title in test data\n",
    "test_data['Title'] = extract_title(test_data)\n",
    "test_data['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are many titles with very few counts, we will map them to main categories (titles that are more frequently occurring)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map titles to main categories\n",
    "def map_title(df):\n",
    "    title_category = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\": \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\": \"Royalty\",\n",
    "    \"Dona\": \"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\": \"Mr\",\n",
    "    \"Mrs\": \"Mrs\",\n",
    "    \"Miss\": \"Miss\",\n",
    "    \"Master\": \"Master\",\n",
    "    \"Lady\": \"Royalty\"\n",
    "    }\n",
    "    new_title = df['Title'].map(title_category)\n",
    "    return new_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr         517\n",
       "Miss       184\n",
       "Mrs        127\n",
       "Master      40\n",
       "Officer     18\n",
       "Royalty      5\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of each title in train data after mapping\n",
    "train_data['Title'] = map_title(train_data)\n",
    "train_data['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr         517\n",
       "Miss       184\n",
       "Mrs        127\n",
       "Master      40\n",
       "Officer     18\n",
       "Royalty      5\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of each title in test data after mapping\n",
    "test_data['Title'] = map_title(test_data)\n",
    "test_data['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have extracted titles from names, we can group data by title and impute missing age values using the median age of each category. We will also group by 'Pclass' as it will help in accurately calculating the median age within each class.\n",
    "\n",
    "Note: We are using median value instead of mean because extreme values (or outliers) have a lot more impact on mean than median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Title  \n",
       "1       Master      4.0\n",
       "        Miss       30.0\n",
       "        Mr         40.0\n",
       "        Mrs        40.0\n",
       "        Officer    50.0\n",
       "        Royalty    40.0\n",
       "2       Master      1.0\n",
       "        Miss       24.0\n",
       "        Mr         31.0\n",
       "        Mrs        31.5\n",
       "        Officer    46.5\n",
       "3       Master      4.0\n",
       "        Miss       18.0\n",
       "        Mr         26.0\n",
       "        Mrs        31.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group train data by 'Pclass', 'Title' and calculate the median age\n",
    "train_data.groupby(['Pclass', 'Title']).median()['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note here is that unlike the 'Master' title, there is no separate category for young female passengers. If we go back and look at the original dataset, we will realize that the 'Miss' title includes both young and adult females. We can somewhat solve this by identifying passengers with 'Miss' title having 1 or 2 value in the 'Parch' column. This way we can retrieve passengers who are most likely, young females (there's also a small chance that the retrieved passenger is a female adult because the 'Parch' column not only reveals the number of parents but also the number of children)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify passengers who have the title 'Miss' and, 1 or 2 value in the 'Parch' column\n",
    "def is_young(df):\n",
    "    young = []\n",
    "    for index, value in df['Parch'].items():\n",
    "        if ((df.loc[index, 'Title'] == 'Miss') and (value == 1 or value == 2)):\n",
    "            young.append(1)\n",
    "        else:\n",
    "            young.append(0)\n",
    "    return young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Title    Is_Young(Miss)\n",
       "1       Master   0                  4.0\n",
       "        Miss     0                 31.0\n",
       "                 1                 20.0\n",
       "        Mr       0                 40.0\n",
       "        Mrs      0                 40.0\n",
       "        Officer  0                 50.0\n",
       "        Royalty  0                 40.0\n",
       "2       Master   0                  1.0\n",
       "        Miss     0                 30.0\n",
       "                 1                  7.0\n",
       "        Mr       0                 31.0\n",
       "        Mrs      0                 31.5\n",
       "        Officer  0                 46.5\n",
       "3       Master   0                  4.0\n",
       "        Miss     0                 21.0\n",
       "                 1                  5.0\n",
       "        Mr       0                 26.0\n",
       "        Mrs      0                 31.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group train data by 'Pclass', 'Title', 'Is_Young(Miss)' and calculate the median age\n",
    "train_data['Is_Young(Miss)'] = is_young(train_data)\n",
    "grouped_age = train_data.groupby(['Pclass', 'Title', 'Is_Young(Miss)']).median()['Age']\n",
    "grouped_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better as we can now guess the missing age values more accurately than before. We will apply this function to the test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Is_Young(Miss)'] = is_young(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will impute the missing age values according to the grouped data shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing age values in train and test data\n",
    "train_data.set_index(['Pclass', 'Title', 'Is_Young(Miss)'], drop=False, inplace=True)\n",
    "train_data['Age'].fillna(grouped_age, inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.set_index(['Pclass', 'Title', 'Is_Young(Miss)'], drop=False, inplace=True)\n",
    "test_data['Age'].fillna(grouped_age, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important thing that needs to be addressed is that I've only used the train data to calculate the median ages for replacing missing values in both train and test datasets. Many people, especially those participating in data science competitions, use test data as well for preprocessing purposes. This may help people improve their model's test accuracy and rank higher in competitions, but it is considered a major mistake in real world applications (known as **data leakage**). Models built using this approach do not generalize too well to the new/unseen data and give results that are a lot poorer than expected. Hence, test data should never be used for data preprocessing and should only be used for testing purposes.\n",
    "\n",
    "For replacing the missing 'Fare' value in test data, we will simply group the train data by 'Pclass' and repeat the same steps as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    60.2875\n",
       "2    14.2500\n",
       "3     8.0500\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group train data by 'Pclass' and calculate the median fare\n",
    "grouped_fare = train_data.groupby('Pclass').median()['Fare']\n",
    "grouped_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing fare value in test data\n",
    "test_data.set_index('Pclass', drop=False, inplace=True)\n",
    "test_data['Fare'].fillna(grouped_fare, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will drop all of the unnecessary rows and columns:\n",
    "* Name: We've extracted the information that we needed (i.e. Title) and don't need this column anymore\n",
    "* Cabin: Majority of the values are missing so we will drop the entire column\n",
    "* Embarked: Only 2 values are missing in train data so we can just remove those 2 entire rows\n",
    "* Ticket: Doesn't seem to provide any useful information so we will drop the entire column\n",
    "* Is_Young(Miss): Purpose of creating this column has been fulfilled and we don't need it anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary rows and columns\n",
    "train_data.drop(columns=['Name', 'Cabin', 'Ticket', 'Is_Young(Miss)'], inplace=True)\n",
    "test_data.drop(columns=['Name', 'Cabin', 'Ticket', 'Is_Young(Miss)'], inplace=True)\n",
    "train_data.dropna(subset=['Embarked'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always good to verify that there are no remaining missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "Title          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values in train data after data cleaning\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "Embarked       2\n",
       "Title          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values in test data after data cleaning\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploratory Data Analysis <a id=\"heading4\"></a>\n",
    "\n",
    "In this section, we will try to find some interesting insights using visual methods.\n",
    "\n",
    "First, we will look at the class distribtuion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(7, 5))\n",
    "sns.countplot(x='Survived', data=train_data)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the classes are slightly imbalanced since majority of the passengers did not survive. In scenarios like this, the same ratio is expected in test data so we don't need to worry about the imbalanced classes.\n",
    "\n",
    "Next, let's find out the ratio of survivors with respect to other variables (i.e. 'Sex', 'Pclass', 'Embarked', 'Title')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(7, 5))\n",
    "sns.barplot(x='Sex', y='Survived', data=train_data, ci=None)\n",
    "plt.title('Ratio of survivors based on sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(7, 5))\n",
    "sns.barplot(x='Pclass', y='Survived', data=train_data, ci=None)\n",
    "plt.title('Ratio of survivors based on ticket class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(7, 5))\n",
    "sns.barplot(x='Embarked', y='Survived', data=train_data, ci=None)\n",
    "plt.title('Ratio of survivors based on port of embarkation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAFNCAYAAACdVxEnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfvElEQVR4nO3de7gdZX238ftLEBVBUElbJYHwYhQpUqwRrVpFhRY8hPYtKIitWJWLvo22nrEqRazViodaxWpsLR4KCNraiKlIFbFFwARBIFAkHDTBUzgpKIrR3/vHTGSx2YcVWJO99+z7c13ryhyeNfObWTv7u+eZWTOpKiRJ6qOtprsASZK6YshJknrLkJMk9ZYhJ0nqLUNOktRbhpwkqbcMOc0oST6Y5E0dLPeRSS5OcmuSl496+ZtRRyfbt5k1nJTkb6a5huOSfGKa1v2fSV44yfxp3z8ana2nuwDNbkmuA34d+AVwG/B5YFlV3TbEe48EXlJVT940raqO7qZSXgucXVX7dLT8oXS4fRpHkuOAh1fVCzZNq6qDBuYfyZifQfWLR3IahedU1XbAPsBjgNdPbznj2hVY0+UK0tji/6eS+MeqNAFDTiNTVd8DzqQJOwCSHJPk6rab8PIkf9hOfxTwQeB3ktyW5JZ2+l26ipK8NMnaJDclWZHkYROtP8nSJGuS3JLky+06SPIl4GnA+9t1PWKc9x6Z5Jq2zmuTHNFOv0u3WpJFSWpTsLTreWuSc4GfAK9JsnrMsl+RZMXY7UtyRZJnD7TbOsmGJL892fa0865L8roklwA/bt/7uiTXt9twZZJnTPJx7ZTkrLbtOUl2HVj2e5OsS/KjJBcm+d2BefsmWd3O+36Sdw/Me0KSr7b1fiPJfgPzdmvXc2uSs4CdJqlt0s+93f9HJ7mqXdeJSTLOMg4E/gp4Xvu5f6Od/uUkL5noZ3Cc5Tw7TVf3Le327T1Z7ZphqsqXr3v8Aq4D9m+HFwCXAu8dmH8o8DCaP6ieB/wYeGg770jgf8Ys7yTgb9rhpwM3AL8N3Bd4H/CVCep4RLvsA4D70HRPrgW2aed/maZbarz3PgD4EfDIdvyhwG+2w8cBnxhouwgoYOuB5X4b+E2a7v8dgFuBxQPvWQUcNs72HQv860C7ZwFXDLk91wEXAwuB+wOPBNYBDxuoc/cJtvektsantPv1vYOfA/AC4CHt9rwK+B5wv3beecAft8PbAU9oh3cGbgSe2X7WB7Tj8wfe9+52fU9p1/+JCeqb9HNv9/8ZwI7ALsAG4MAJlnXc2PUM/iww9c/gY4AfAI8H5gEvbPf9faf7/56v4V4eyWkUPpPkVppfsj8A/nrTjKo6vaq+U1W/rKpPAlcB+w653COAj1TV16vqZzTdoL+TZNE4bZ8HfK6qzqqqnwPvpPnl/8Qh1/VLYK8k96+q71bV5nRtnlRVa6pqY1X9EPgP4HCAJIuBPYAV47zvZGBpkm3b8ecDp2zG9vxDVa2rqttpzoneF9gzyX2q6rqqunqSmj9XVV9p9+sbaPbrQoCq+kRV3dhuz7va5T6yfd/PgYcn2amqbquq89vpLwBWVtXK9rM+C1gNPDPJLsDjgDdV1c+q6ivAZyepbZjP/e1VdUtVfRs4m4HegxE7CvhQVV1QVb+oqo8CPwOe0NH6NGKGnEbhD6pqe2A/ml/ov+qKSvInA109twB7MUVX1YCHAd/aNFLNxSw30hw1TNX2lzShO17bu6iqH9OEytHAd5N8LskeQ9ZIu55BJ9OGHE1wfaaqfjLOetcCVwDPaYNuafveYbdn3cD8tcBf0hy5/CDJqZN17Y55723ATe06SfLqtiv1h+1ntgN3fmYvpjnK/N8kqwa6W3cFDt30ObfvezLNUfHDgJvb/bzJt5jYMJ/79waGf0JzVNmFXYFXjdmuhW2NmgUMOY1MVZ1D09XzToD2PM+HgWXAQ6pqR+AyYNP5k6kegfEdml8ytMt7AE032vVDtA3NL6Px2o5X+5lVdQDNL+X/beuGpstw24GmvzHe28eMnwXMT7IPTdidfLd33OmUts3BwOVtWA27PXdZb1WdXM1Vgru28/5ukvUuHFj2dsCDge+0599eCzwXeFD7mf2Q9jOrqquq6nDg19rlf6r9XNYBH6+qHQdeD6iqtwPfBR7Utttkl0lq25zPfSpT/YxNNX8d8NYx27VtVZ0yxfs0QxhyGrW/Bw5I8ls057qK5pwJSV5EcyS3yfeBBUm2mWBZpwAvSrJPkvsCfwtcUFXXjdP2NOBZSZ6R5D4055J+Bnx1qoKT/HqSg9tfpj+j+SrEL9vZFwNPSbJLkh0Y4srRtnvxdOAEmvA4a5LmpwK/B/wZdw3DzdqeNN8DfHq7n34K3D6wDeN5ZpInt/v+LcD5VbUO2B7YSPOZbZ3kWOCBA+t5QZL57ZHlLe3kXwKfoDki/f0k85LcL8l+SRZU1bdoui7fnGSbJE8GnjNJbZvzuU/l+8CiTHzV61Q/gx8Gjk7y+DQekORZSba/B7VoGhhyGqmq2gB8DDi2qi4H3kVz0cH3gUcD5w40/xLNZf3fS3LDOMv6L+BNwKdpjgZ2Bw6bYL1X0pwXeh/NRQvPoflqwx1DlL0V8EqaI4ibgKfShA7tuaVPApcAF9Jc8DCMk4H9gdOrauNEjarquzT754nteu7p9twXeHvb9ns0R1qTBfLJNOdObwIe264LmqtjPw98k6bL8KfctTv2QGBNkttoLlg5rKpubwPyYJqrGTe073kNd/6OeT7NxRs3tev92CT7ZOjPfQint//emOTr48yf6mdwNfBS4P3AzTQX/xx5D2vRNEiVD02VJPWTR3KSpN4y5CRJvWXISZJ6y5CTJPWWISdJ6q1Zd/fynXbaqRYtWjTdZUiSZpALL7zwhqqaP3b6rAu5RYsWsXr16qkbSpLmjCTj3irO7kpJUm8ZcpKk3jLkJEm9ZchJknrLkJMk9VanIZfkwCRXJlmb5Jhx5u+S5OwkFyW5JMkzu6xHkjS3dBZySeYBJwIHAXsChyfZc0yzNwKnVdVjaB6l8YGu6pEkzT1dHsntC6ytqmvaZ2CdSvO8qUHFnQ9k3IHmeV6SJI1El18G35m7PmxxPc1DEwcdB3whyctoniK9f4f1SJLmmOm+8ORw4KSqWgA8E/j4eI+pT3JUktVJVm/YsGGLFylJmp26DLnrgYUD4wvaaYNeDJwGUFXnAfcDdhq7oKpaXlVLqmrJ/Pl3uzWZJEnj6rK7chWwOMluNOF2GPD8MW2+DTwDOCnJo2hCzkO1e+Hbxz96uksYqV2OvXS6S5A0i3V2JFdVG4FlwJnAFTRXUa5JcnySpW2zVwEvTfIN4BTgyKqqrmqSJM0tnT6FoKpWAivHTDt2YPhy4Eld1iBJmrum+8ITSZI6Y8hJknrLkJMk9ZYhJ0nqLUNOktRbhpwkqbcMOUlSbxlykqTeMuQkSb1lyEmSesuQkyT1liEnSeotQ06S1FuGnCSptww5SVJvGXKSpN4y5CRJvWXISZJ6y5CTJPWWISdJ6i1DTpLUW4acJKm3DDlJUm8ZcpKk3uo05JIcmOTKJGuTHDPO/Pckubh9fTPJLV3WI0maW7buasFJ5gEnAgcA64FVSVZU1eWb2lTVKwbavwx4TFf1SJLmni6P5PYF1lbVNVV1B3AqcPAk7Q8HTumwHknSHNNlyO0MrBsYX99Ou5skuwK7AV+aYP5RSVYnWb1hw4aRFypJ6qfOuis302HAp6rqF+PNrKrlwHKAJUuW1JYsTLPPk973pOkuYaTOfdm5012CNGt1eSR3PbBwYHxBO208h2FXpSRpxLoMuVXA4iS7JdmGJshWjG2UZA/gQcB5HdYiSZqDOgu5qtoILAPOBK4ATquqNUmOT7J0oOlhwKlVZTekJGmkOj0nV1UrgZVjph07Zvy4LmuQJM1d3vFEktRbhpwkqbcMOUlSbxlykqTeMuQkSb1lyEmSesuQkyT1liEnSeotQ06S1FuGnCSptww5SVJvGXKSpN4y5CRJvWXISZJ6y5CTJPWWISdJ6i1DTpLUW4acJKm3DDlJUm8ZcpKk3jLkJEm9ZchJknrLkJMk9VanIZfkwCRXJlmb5JgJ2jw3yeVJ1iQ5uct6JElzy9ZdLTjJPOBE4ABgPbAqyYqqunygzWLg9cCTqurmJL/WVT2SpLmnyyO5fYG1VXVNVd0BnAocPKbNS4ETq+pmgKr6QYf1SJLmmC5Dbmdg3cD4+nbaoEcAj0hybpLzkxzYYT2SpDmms+7KzVj/YmA/YAHwlSSPrqpbBhslOQo4CmCXXXbZwiVKmo3e/6rPTncJI7XsXc+Z7hJmpS6P5K4HFg6ML2inDVoPrKiqn1fVtcA3aULvLqpqeVUtqaol8+fP76xgSVK/dBlyq4DFSXZLsg1wGLBiTJvP0BzFkWQnmu7LazqsSZI0h3QWclW1EVgGnAlcAZxWVWuSHJ9kadvsTODGJJcDZwOvqaobu6pJkjS3dHpOrqpWAivHTDt2YLiAV7YvSZJGyjueSJJ6y5CTJPWWISdJ6q3p/p6cpA6c85SnTncJI/XUr5wz3SVolvJITpLUW4acJKm3DDlJUm8ZcpKk3jLkJEm9ZchJknrLkJMk9ZYhJ0nqLUNOktRbhpwkqbcMOUlSbxlykqTeMuQkSb1lyEmSesuQkyT1liEnSeotQ06S1FuGnCSptww5SVJvGXKSpN7qNOSSHJjkyiRrkxwzzvwjk2xIcnH7ekmX9UiS5patu1pwknnAicABwHpgVZIVVXX5mKafrKplXdUhSZq7ujyS2xdYW1XXVNUdwKnAwR2uT5Kku+gy5HYG1g2Mr2+njfVHSS5J8qkkCzusR5I0x0z3hSefBRZV1d7AWcBHx2uU5Kgkq5Os3rBhwxYtUJI0e3UZctcDg0dmC9ppv1JVN1bVz9rRfwIeO96Cqmp5VS2pqiXz58/vpFhJUv90GXKrgMVJdkuyDXAYsGKwQZKHDowuBa7osB5J0hzT2dWVVbUxyTLgTGAe8JGqWpPkeGB1Va0AXp5kKbARuAk4sqt6JElzT2chB1BVK4GVY6YdOzD8euD1XdYgSZq7pvvCE0mSOmPISZJ6y5CTJPXWpOfkktwK1ETzq+qBI69IkqQRmTTkqmp7gCRvAb4LfBwIcATw0EneKknStBu2u3JpVX2gqm6tqh9V1T/ifSglSTPcsCH34yRHJJmXZKskRwA/7rIwSZLurWFD7vnAc4Hvt69D22mSJM1YQ30ZvKquw+5JSdIsM9SRXJJHJPliksva8b2TvLHb0iRJuneG7a78MM3tt34OUFWX0NxwWZKkGWvYkNu2qr42ZtrGURcjSdIoDRtyNyTZnfaL4UkOofnenCRJM9awTyH4c2A5sEeS64Frab4QLknSjDVsyH2rqvZP8gBgq6q6tcuiJEkahWG7K69Nshx4AnBbh/VIkjQyw4bcHsB/0XRbXpvk/Ume3F1ZkiTde0OFXFX9pKpOq6r/CzwGeCBwTqeVSZJ0Lw39PLkkT03yAeBC4H40t/mSJGnGGurCkyTXARcBpwGvqSpvzixJmvGGvbpy76r6UaeVSJI0YlM9Gfy1VfUO4K1J7vaE8Kp6eWeVSZJ0L011JHdF++/qrguRJGnUJg25qvpsO3hpVX19C9QjSdLIDHt15buSXJHkLUn2GnbhSQ5McmWStUmOmaTdHyWpJEuGXbYkSVMZ9ntyTwOeBmwAPpTk0qmeJ5dkHnAicBCwJ3B4kj3Habc98BfABZtZuyRJkxr6e3JV9b2q+gfgaOBi4Ngp3rIvsLaqrqmqO4BTGf/p4m8B/g746bC1SJI0jGGfDP6oJMcluRR4H/BVYMEUb9sZWDcwvr6dNrjc3wYWVtXnplj/UUlWJ1m9YcOGYUqWJGno78l9hOZI7Per6jujWHGSrYB3A0dO1baqltM86oclS5bc7asMkiSNZ8qQa8+tXVtV793MZV8PLBwYX9BO22R7YC/gy0kAfgNYkWRpVfmVBUnSvTZld2VV/QJYmGSbzVz2KmBxkt3a9x4GrBhY7g+raqeqWlRVi4DzAQNOkjQyw3ZXXgucm2QF8Kv7VlbVuyd6Q1VtTLIMOBOYB3ykqtYkOR5YXVUrJnqvJEmjMGzIXd2+tqLpZhxKVa0EVo6ZNu5VmVW137DLlSRpGEOFXFW9uetCJEkatWEftXM2MN4Nmp8+8ookSRqRYbsrXz0wfD/gj4CNoy9HkqTRGba78sIxk85N8rUO6pEkaWSG7a588MDoVsASYIdOKpIkaUSG7a68kDvPyW0ErgNe3EVBkiSNylRPBn8csK6qdmvHX0hzPu464PLOq5Mk6V6Y6o4nHwLuAEjyFOBtwEeBH9LeS1KSpJlqqu7KeVV1Uzv8PGB5VX0a+HSSizutTJKke2mqI7l5STYF4TOALw3MG/Z8niRJ02KqoDoFOCfJDcDtwH8DJHk4TZelJEkz1qQhV1VvTfJF4KHAF6pq0xWWWwEv67o4SZLujSm7HKvq/HGmfbObciRJGp0pnycnSdJsZchJknrLkJMk9ZYhJ0nqLUNOktRbhpwkqbcMOUlSbxlykqTeMuQkSb1lyEmSeqvTkEtyYJIrk6xNcsw4849OcmmSi5P8T5I9u6xHkjS3dBZySeYBJwIHAXsCh48TYidX1aOrah/gHcC7u6pHkjT3dHkkty+wtqquqao7gFOBgwcbVNWPBkYfABSSJI1Ilw8+3RlYNzC+Hnj82EZJ/hx4JbAN8PQO65EkzTHTfuFJVZ1YVbsDrwPeOF6bJEclWZ1k9YYNG7ZsgZKkWavLkLseWDgwvqCdNpFTgT8Yb0ZVLa+qJVW1ZP78+aOrUJLUa12G3CpgcZLdkmwDHAasGGyQZPHA6LOAqzqsR5I0x3R2Tq6qNiZZBpwJzAM+UlVrkhwPrK6qFcCyJPsDPwduBl7YVT2SpLmnywtPqKqVwMox044dGP6LLtcvSZrbpv3CE0mSumLISZJ6q9PuSknS9HnrCw6Z7hJG6g2f+NRmv8cjOUlSbxlykqTeMuQkSb1lyEmSesuQkyT1liEnSeotQ06S1FuGnCSptww5SVJvGXKSpN4y5CRJvWXISZJ6y5CTJPWWISdJ6i1DTpLUW4acJKm3DDlJUm8ZcpKk3jLkJEm9ZchJknrLkJMk9VanIZfkwCRXJlmb5Jhx5r8yyeVJLknyxSS7dlmPJGlu6SzkkswDTgQOAvYEDk+y55hmFwFLqmpv4FPAO7qqR5I093R5JLcvsLaqrqmqO4BTgYMHG1TV2VX1k3b0fGBBh/VIkuaYLkNuZ2DdwPj6dtpEXgz8Z4f1SJLmmK2nuwCAJC8AlgBPnWD+UcBRALvssssWrEySNJt1eSR3PbBwYHxBO+0ukuwPvAFYWlU/G29BVbW8qpZU1ZL58+d3UqwkqX+6DLlVwOIkuyXZBjgMWDHYIMljgA/RBNwPOqxFkjQHdRZyVbURWAacCVwBnFZVa5Icn2Rp2+wEYDvg9CQXJ1kxweIkSdpsnZ6Tq6qVwMox044dGN6/y/VLkuY273giSeotQ06S1FuGnCSptww5SVJvGXKSpN4y5CRJvWXISZJ6y5CTJPWWISdJ6q0Z8RSCUXnsaz423SWM1IUn/Ml0lyBJs5pHcpKk3jLkJEm9ZchJknrLkJMk9ZYhJ0nqLUNOktRbhpwkqbcMOUlSbxlykqTeMuQkSb1lyEmSesuQkyT1liEnSeqtTkMuyYFJrkyyNskx48x/SpKvJ9mY5JAua5EkzT2dhVySecCJwEHAnsDhSfYc0+zbwJHAyV3VIUmau7p8nty+wNqqugYgyanAwcDlmxpU1XXtvF92WIckaY7qsrtyZ2DdwPj6dpokSVvErLjwJMlRSVYnWb1hw4bpLkeSNEt0GXLXAwsHxhe00zZbVS2vqiVVtWT+/PkjKU6S1H9dhtwqYHGS3ZJsAxwGrOhwfZIk3UVnIVdVG4FlwJnAFcBpVbUmyfFJlgIkeVyS9cChwIeSrOmqHknS3NPl1ZVU1Upg5Zhpxw4Mr6LpxpQkaeRmxYUnkiTdE4acJKm3DDlJUm8ZcpKk3jLkJEm9ZchJknrLkJMk9ZYhJ0nqLUNOktRbhpwkqbcMOUlSbxlykqTeMuQkSb1lyEmSesuQkyT1liEnSeotQ06S1FuGnCSptww5SVJvGXKSpN4y5CRJvWXISZJ6y5CTJPWWISdJ6q1OQy7JgUmuTLI2yTHjzL9vkk+28y9IsqjLeiRJc0tnIZdkHnAicBCwJ3B4kj3HNHsxcHNVPRx4D/B3XdUjSZp7ujyS2xdYW1XXVNUdwKnAwWPaHAx8tB3+FPCMJOmwJknSHNJlyO0MrBsYX99OG7dNVW0Efgg8pMOaJElzSKqqmwUnhwAHVtVL2vE/Bh5fVcsG2lzWtlnfjl/dtrlhzLKOAo5qRx8JXNlJ0cPbCbhhylb95j5wH4D7ANwHMDP2wa5VNX/sxK07XOH1wMKB8QXttPHarE+yNbADcOPYBVXVcmB5R3VutiSrq2rJdNcxndwH7gNwH4D7AGb2Puiyu3IVsDjJbkm2AQ4DVoxpswJ4YTt8CPCl6urQUpI053R2JFdVG5MsA84E5gEfqao1SY4HVlfVCuCfgY8nWQvcRBOEkiSNRJfdlVTVSmDlmGnHDgz/FDi0yxo6MmO6TqeR+8B9AO4DcB/ADN4HnV14IknSdPO2XpKk3jLkJpGkknxiYHzrJBuSnDGddW0JbvvE255k6Xi3qZuNRvk5J9kxyf8bbYXdSvKLJBcnuSzJZ5PsOOLln9R+nYokf5lk21Euf5SSLEjyH0muSnJ1kve2Fw2S5JQklyR5RZI92n12UZLdk3x1umufjCE3uR8DeyW5fzt+AHf/GgTQ/HLYYlVtGW77BNteVSuq6u3TUtnoDf05D2FHYLNCLo3p/D10e1XtU1V70Vz89ucdrusvgRkZcu2dpv4N+ExVLQYeAWwHvDXJbwCPq6q9q+o9wB8An6qqx1TV1VX1xBGsv7PfIYbc1FYCz2qHDwdO2TQjyXFJPp7kXODj01Fcx4be9iS/meRr7V94lyRZPB0Fj9Bk235kkve3w4e2RwHfSPKVdtps2xeTbeu+Sc5r/2r/apJHttPH28a3A7u3005o270myaq2zZvbaYvS3Lj9Y8Bl3PX7tNPpPNq7MiXZJ8n5bd3/nuRB7VHL1zc1TrJ403iSY9vtvCzJ8jY0GGj7cuBhwNlJzk7yp0n+fmD+S5O8Z0ts5ASeDvy0qv4FoKp+AbwC+FPgK8DO7ef61zRh/WdJzgZIctumhSR5XZJL2/8Pb2+n7Z7k80kuTPLfSfZop5+U5INJLgDe0dmWVZWvCV7AbcDeNPfVvB9wMbAfcEY7/zjgQuD+013rdG878D7giHZ4m9m8T4bY9iOB97fDlwI7t8M7zrZ9McS2PhDYuh3eH/j0RNsILAIuG1j279FcdReaP6jPAJ7Stvsl8ISZsP3tv/OA02nuwARwCfDUdvh44O/b4bOBfdrhvwVe1g4/eGCZHwee0w6fBBzSDl8H7NQObwdcDdynHf8q8Ohp3A8vB94zzvSL2p+Pwc/1OODV4+zDg9rt2HZwnwBfBBa3w4+n+T70pn1zBjCvy23rWzfTyFXVJWkeAXQ4Y74O0VpRVbdv2aq2jM3c9vOANyRZAPxbVV21hcrsxBDbvsm5wElJTqPp7oFZti+m2NYdgI+2R2oF3KedfrdtzN3vrf577euidnw7YDHwbeBbVXX+qLflHrh/kotpjuCuAM5KsgPNHyzntG0+ShOAAP8EvCjJK4Hn0dyIHuBpSV5L0x35YGAN8NmJVlpVtyX5EvDsJFfQhN2lo920LW5/4F+q6icAVXVTku2AJwKnD/x83HfgPadXc9TYGbsrh7MCeCcD3TgDfryFa9nShtr2qjoZWArcDqxM8vQtU16nJtt2AKrqaOCNNF1uFyZ5yCzdFxNt61uAs6s5Z/UcmqO9YT/vAG+r5pzXPlX18Kr653beTPl/c3tV7QPsSlPvVOfkPk1zxPJs4MKqujHJ/YAP0ByxPRr4MO1+msI/0fQKvAj4l3tU/ehcDjx2cEKSBwK7ABvvxXK3Am4Z+BnYp6oeNTC/858DQ244HwHe3IO/tO6JobY9yf8BrqmqfwD+g6aLY7abctuT7F5VF1Rzk4MNwMJZui8m2tYduPNClCM3TZxgG28Fth9475nAn7Z/zZNk5yS/1k3590579PFy4FU0v3hvTvK77ew/Bs5p2/2UZrv+kTuDaVOg3dBu6yETrOYu+6eqLqD54+j5TPKH1BbyRWDbJH8Cv3oe6LtouhR/MuQyzqI5yt22XcaDq+pHwLVJDm2nJclvjbr4yRhyQ6iq9e1/5jlnM7b9ucBlbdfPXsDHOi1sCxhy209oT7RfRnM+4hvMwn0xyba+A3hbkou46x2S7raNVXUjcG578cUJVfUF4GTgvCSX0pz3254ZqqouojkXdzjNPXVPSHIJsA/NeblN/pXmnOIX2vfdQnP0dhlNAK6aYBXLgc9vumCjdRpwblXdPLINuQeqOUn2h8ChSa4Cvgn8FPirzVjG52l6BFa3PxevbmcdAbw4yTdounHHPle0U97xRJI2Q5JXAztU1ZtGsKwzaC74+OK9r0zj8cITSRpSkn8Hdqe55P7eLGdH4GvANwy4bnkkJ0nqLc/JSZJ6y5CTJPWWISdJ6i1DTpphkjykvU/gxUm+l+T6dvi2JB9o2+yX5IkD7zmuvepP0gCvrpRmmPb7ZvtAE1409wZ855hm+9Hcd3JGP+ZEmm4eyUmzRHv0dkZ7n8mjgVe0R3i/O6bduHd9l+Yij+SkWaaqrkvyQQaO8JI8Y6DJcuDo9qbJj6e5r+JsuH+mNHKGnNQjQ9z1XZpTDDmpX3511/fpLkSaCTwnJ81OY+/4D8BMuOu7NJMYctLs9FngD8e78IRpvuu7NJN470pJUm95JCdJ6i1DTpLUW4acJKm3DDlJUm8ZcpKk3jLkJEm9ZchJknrLkJMk9db/Bx3UKOoWea7jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(7, 5))\n",
    "sns.barplot(x='Title', y='Survived', data=train_data, ci=None)\n",
    "plt.title('Ratio of survivors based on title')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these visualizations, we can conclude the following:\n",
    "* Females had a way higher survival rate than males\n",
    "* Lower ticket class (with 3 being the lowest) means less chance of survival\n",
    "* Passengers who embarked from port 'C' had slightly more chances of survival\n",
    "* Passengers with the title 'Mr' and 'Officer' had really low chances of survival as compared to other passengers\n",
    "\n",
    "Note: The accuracy of these findings also depends on other factors such as the frequency distribution within each categorical variable. For example, if there is only 1 female in the entire dataset and she survived, then the survival rate of females will be 100% which cannot be considered a concrete finding. Hence, depending on the type of problem being solved, further data analysis should be done if required.\n",
    "\n",
    "Next, we will compute the pairwise correlation of different variables, focusing mainly on how different features correlate with the target variable 'Survived'. But first, we need to convert all of the categorical variables into numeric data type.\n",
    "\n",
    "To convert 'Sex' variable into numeric format, we will simply encode male with 1 and female with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 'Sex' variable values\n",
    "le = LabelEncoder()\n",
    "train_data['Sex'] = le.fit_transform(train_data['Sex'])\n",
    "test_data['Sex'] = le.transform(test_data['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'Embarked' and 'Title' variables, we will use dummy variables to represent different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Embarked' and 'Title' into dummy variables\n",
    "train_data = pd.get_dummies(train_data, columns=['Embarked', 'Title'])\n",
    "test_data = pd.get_dummies(test_data, columns=['Embarked', 'Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the dataset looks like after conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  \\\n",
       "0            1         0       3    1  22.0      1      0   7.2500   \n",
       "1            2         1       1    0  38.0      1      0  71.2833   \n",
       "2            3         1       3    0  26.0      0      0   7.9250   \n",
       "3            4         1       1    0  35.0      1      0  53.1000   \n",
       "4            5         0       3    1  35.0      0      0   8.0500   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  \\\n",
       "0           0           0           1             0           0         1   \n",
       "1           1           0           0             0           0         0   \n",
       "2           0           0           1             0           1         0   \n",
       "3           0           0           1             0           0         0   \n",
       "4           0           0           1             0           0         1   \n",
       "\n",
       "   Title_Mrs  Title_Officer  Title_Royalty  \n",
       "0          0              0              0  \n",
       "1          1              0              0  \n",
       "2          0              0              0  \n",
       "3          1              0              0  \n",
       "4          0              0              0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calculate the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005028</td>\n",
       "      <td>-0.035330</td>\n",
       "      <td>0.043136</td>\n",
       "      <td>0.035304</td>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>-0.033694</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>-0.026218</td>\n",
       "      <td>-0.064014</td>\n",
       "      <td>0.039008</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.055440</td>\n",
       "      <td>0.031681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335549</td>\n",
       "      <td>-0.541585</td>\n",
       "      <td>-0.055756</td>\n",
       "      <td>-0.034040</td>\n",
       "      <td>0.083151</td>\n",
       "      <td>0.255290</td>\n",
       "      <td>0.169966</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>-0.151777</td>\n",
       "      <td>0.085998</td>\n",
       "      <td>0.332094</td>\n",
       "      <td>-0.547689</td>\n",
       "      <td>0.343836</td>\n",
       "      <td>-0.030963</td>\n",
       "      <td>0.033666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035330</td>\n",
       "      <td>-0.335549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127741</td>\n",
       "      <td>-0.412684</td>\n",
       "      <td>0.081656</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>-0.548193</td>\n",
       "      <td>-0.245733</td>\n",
       "      <td>0.220558</td>\n",
       "      <td>0.076466</td>\n",
       "      <td>0.081547</td>\n",
       "      <td>-0.006737</td>\n",
       "      <td>0.139156</td>\n",
       "      <td>-0.151780</td>\n",
       "      <td>-0.149428</td>\n",
       "      <td>-0.118241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.043136</td>\n",
       "      <td>-0.541585</td>\n",
       "      <td>0.127741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111186</td>\n",
       "      <td>-0.116348</td>\n",
       "      <td>-0.247508</td>\n",
       "      <td>-0.179958</td>\n",
       "      <td>-0.084520</td>\n",
       "      <td>-0.075217</td>\n",
       "      <td>0.121405</td>\n",
       "      <td>0.159612</td>\n",
       "      <td>-0.692363</td>\n",
       "      <td>0.866888</td>\n",
       "      <td>-0.552629</td>\n",
       "      <td>0.088976</td>\n",
       "      <td>-0.007728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.035304</td>\n",
       "      <td>-0.055756</td>\n",
       "      <td>-0.412684</td>\n",
       "      <td>0.111186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.299570</td>\n",
       "      <td>-0.199577</td>\n",
       "      <td>0.113625</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>-0.086584</td>\n",
       "      <td>0.011295</td>\n",
       "      <td>-0.392649</td>\n",
       "      <td>-0.305175</td>\n",
       "      <td>0.215257</td>\n",
       "      <td>0.191443</td>\n",
       "      <td>0.189013</td>\n",
       "      <td>0.069560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.034040</td>\n",
       "      <td>0.081656</td>\n",
       "      <td>-0.116348</td>\n",
       "      <td>-0.299570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414542</td>\n",
       "      <td>0.160887</td>\n",
       "      <td>-0.060074</td>\n",
       "      <td>-0.026692</td>\n",
       "      <td>0.069438</td>\n",
       "      <td>0.349434</td>\n",
       "      <td>0.085939</td>\n",
       "      <td>-0.252201</td>\n",
       "      <td>0.061261</td>\n",
       "      <td>-0.024872</td>\n",
       "      <td>-0.008467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001657</td>\n",
       "      <td>0.083151</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>-0.247508</td>\n",
       "      <td>-0.199577</td>\n",
       "      <td>0.414542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217532</td>\n",
       "      <td>-0.011588</td>\n",
       "      <td>-0.081585</td>\n",
       "      <td>0.061512</td>\n",
       "      <td>0.267194</td>\n",
       "      <td>0.103551</td>\n",
       "      <td>-0.335765</td>\n",
       "      <td>0.223240</td>\n",
       "      <td>-0.048377</td>\n",
       "      <td>-0.035673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.255290</td>\n",
       "      <td>-0.548193</td>\n",
       "      <td>-0.179958</td>\n",
       "      <td>0.113625</td>\n",
       "      <td>0.160887</td>\n",
       "      <td>0.217532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.270731</td>\n",
       "      <td>-0.116684</td>\n",
       "      <td>-0.163758</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>0.119660</td>\n",
       "      <td>-0.181692</td>\n",
       "      <td>0.103920</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.015222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>-0.001208</td>\n",
       "      <td>0.169966</td>\n",
       "      <td>-0.245733</td>\n",
       "      <td>-0.084520</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>-0.060074</td>\n",
       "      <td>-0.011588</td>\n",
       "      <td>0.270731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148646</td>\n",
       "      <td>-0.782613</td>\n",
       "      <td>-0.035471</td>\n",
       "      <td>0.038498</td>\n",
       "      <td>-0.073976</td>\n",
       "      <td>0.067462</td>\n",
       "      <td>-0.008192</td>\n",
       "      <td>0.078960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>-0.033694</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>0.220558</td>\n",
       "      <td>-0.075217</td>\n",
       "      <td>-0.086584</td>\n",
       "      <td>-0.026692</td>\n",
       "      <td>-0.081585</td>\n",
       "      <td>-0.116684</td>\n",
       "      <td>-0.148646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.499261</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>0.169631</td>\n",
       "      <td>-0.079283</td>\n",
       "      <td>-0.090739</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>-0.023159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.022269</td>\n",
       "      <td>-0.151777</td>\n",
       "      <td>0.076466</td>\n",
       "      <td>0.121405</td>\n",
       "      <td>0.011295</td>\n",
       "      <td>0.069438</td>\n",
       "      <td>0.061512</td>\n",
       "      <td>-0.163758</td>\n",
       "      <td>-0.782613</td>\n",
       "      <td>-0.499261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024577</td>\n",
       "      <td>-0.140514</td>\n",
       "      <td>0.114726</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>-0.054604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Master</th>\n",
       "      <td>-0.026218</td>\n",
       "      <td>0.085998</td>\n",
       "      <td>0.081547</td>\n",
       "      <td>0.159612</td>\n",
       "      <td>-0.392649</td>\n",
       "      <td>0.349434</td>\n",
       "      <td>0.267194</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>-0.035471</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>0.024577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.110509</td>\n",
       "      <td>-0.255888</td>\n",
       "      <td>-0.088206</td>\n",
       "      <td>-0.031204</td>\n",
       "      <td>-0.016324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Miss</th>\n",
       "      <td>-0.064014</td>\n",
       "      <td>0.332094</td>\n",
       "      <td>-0.006737</td>\n",
       "      <td>-0.692363</td>\n",
       "      <td>-0.305175</td>\n",
       "      <td>0.085939</td>\n",
       "      <td>0.103551</td>\n",
       "      <td>0.119660</td>\n",
       "      <td>0.038498</td>\n",
       "      <td>0.169631</td>\n",
       "      <td>-0.140514</td>\n",
       "      <td>-0.110509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.600201</td>\n",
       "      <td>-0.206893</td>\n",
       "      <td>-0.073190</td>\n",
       "      <td>-0.038290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mr</th>\n",
       "      <td>0.039008</td>\n",
       "      <td>-0.547689</td>\n",
       "      <td>0.139156</td>\n",
       "      <td>0.866888</td>\n",
       "      <td>0.215257</td>\n",
       "      <td>-0.252201</td>\n",
       "      <td>-0.335765</td>\n",
       "      <td>-0.181692</td>\n",
       "      <td>-0.073976</td>\n",
       "      <td>-0.079283</td>\n",
       "      <td>0.114726</td>\n",
       "      <td>-0.255888</td>\n",
       "      <td>-0.600201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.479068</td>\n",
       "      <td>-0.169473</td>\n",
       "      <td>-0.088661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mrs</th>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.343836</td>\n",
       "      <td>-0.151780</td>\n",
       "      <td>-0.552629</td>\n",
       "      <td>0.191443</td>\n",
       "      <td>0.061261</td>\n",
       "      <td>0.223240</td>\n",
       "      <td>0.103920</td>\n",
       "      <td>0.067462</td>\n",
       "      <td>-0.090739</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>-0.088206</td>\n",
       "      <td>-0.206893</td>\n",
       "      <td>-0.479068</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058418</td>\n",
       "      <td>-0.030562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Officer</th>\n",
       "      <td>0.055440</td>\n",
       "      <td>-0.030963</td>\n",
       "      <td>-0.149428</td>\n",
       "      <td>0.088976</td>\n",
       "      <td>0.189013</td>\n",
       "      <td>-0.024872</td>\n",
       "      <td>-0.048377</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>-0.008192</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>-0.031204</td>\n",
       "      <td>-0.073190</td>\n",
       "      <td>-0.169473</td>\n",
       "      <td>-0.058418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Royalty</th>\n",
       "      <td>0.031681</td>\n",
       "      <td>0.033666</td>\n",
       "      <td>-0.118241</td>\n",
       "      <td>-0.007728</td>\n",
       "      <td>0.069560</td>\n",
       "      <td>-0.008467</td>\n",
       "      <td>-0.035673</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.078960</td>\n",
       "      <td>-0.023159</td>\n",
       "      <td>-0.054604</td>\n",
       "      <td>-0.016324</td>\n",
       "      <td>-0.038290</td>\n",
       "      <td>-0.088661</td>\n",
       "      <td>-0.030562</td>\n",
       "      <td>-0.010812</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PassengerId  Survived    Pclass       Sex       Age     SibSp  \\\n",
       "PassengerId       1.000000 -0.005028 -0.035330  0.043136  0.035304 -0.057686   \n",
       "Survived         -0.005028  1.000000 -0.335549 -0.541585 -0.055756 -0.034040   \n",
       "Pclass           -0.035330 -0.335549  1.000000  0.127741 -0.412684  0.081656   \n",
       "Sex               0.043136 -0.541585  0.127741  1.000000  0.111186 -0.116348   \n",
       "Age               0.035304 -0.055756 -0.412684  0.111186  1.000000 -0.299570   \n",
       "SibSp            -0.057686 -0.034040  0.081656 -0.116348 -0.299570  1.000000   \n",
       "Parch            -0.001657  0.083151  0.016824 -0.247508 -0.199577  0.414542   \n",
       "Fare              0.012703  0.255290 -0.548193 -0.179958  0.113625  0.160887   \n",
       "Embarked_C       -0.001208  0.169966 -0.245733 -0.084520  0.049316 -0.060074   \n",
       "Embarked_Q       -0.033694  0.004536  0.220558 -0.075217 -0.086584 -0.026692   \n",
       "Embarked_S        0.022269 -0.151777  0.076466  0.121405  0.011295  0.069438   \n",
       "Title_Master     -0.026218  0.085998  0.081547  0.159612 -0.392649  0.349434   \n",
       "Title_Miss       -0.064014  0.332094 -0.006737 -0.692363 -0.305175  0.085939   \n",
       "Title_Mr          0.039008 -0.547689  0.139156  0.866888  0.215257 -0.252201   \n",
       "Title_Mrs         0.005437  0.343836 -0.151780 -0.552629  0.191443  0.061261   \n",
       "Title_Officer     0.055440 -0.030963 -0.149428  0.088976  0.189013 -0.024872   \n",
       "Title_Royalty     0.031681  0.033666 -0.118241 -0.007728  0.069560 -0.008467   \n",
       "\n",
       "                  Parch      Fare  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "PassengerId   -0.001657  0.012703   -0.001208   -0.033694    0.022269   \n",
       "Survived       0.083151  0.255290    0.169966    0.004536   -0.151777   \n",
       "Pclass         0.016824 -0.548193   -0.245733    0.220558    0.076466   \n",
       "Sex           -0.247508 -0.179958   -0.084520   -0.075217    0.121405   \n",
       "Age           -0.199577  0.113625    0.049316   -0.086584    0.011295   \n",
       "SibSp          0.414542  0.160887   -0.060074   -0.026692    0.069438   \n",
       "Parch          1.000000  0.217532   -0.011588   -0.081585    0.061512   \n",
       "Fare           0.217532  1.000000    0.270731   -0.116684   -0.163758   \n",
       "Embarked_C    -0.011588  0.270731    1.000000   -0.148646   -0.782613   \n",
       "Embarked_Q    -0.081585 -0.116684   -0.148646    1.000000   -0.499261   \n",
       "Embarked_S     0.061512 -0.163758   -0.782613   -0.499261    1.000000   \n",
       "Title_Master   0.267194  0.011390   -0.035471    0.010330    0.024577   \n",
       "Title_Miss     0.103551  0.119660    0.038498    0.169631   -0.140514   \n",
       "Title_Mr      -0.335765 -0.181692   -0.073976   -0.079283    0.114726   \n",
       "Title_Mrs      0.223240  0.103920    0.067462   -0.090739   -0.001989   \n",
       "Title_Officer -0.048377  0.010679   -0.008192    0.012520   -0.000704   \n",
       "Title_Royalty -0.035673  0.015222    0.078960   -0.023159   -0.054604   \n",
       "\n",
       "               Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Officer  \\\n",
       "PassengerId       -0.026218   -0.064014  0.039008   0.005437       0.055440   \n",
       "Survived           0.085998    0.332094 -0.547689   0.343836      -0.030963   \n",
       "Pclass             0.081547   -0.006737  0.139156  -0.151780      -0.149428   \n",
       "Sex                0.159612   -0.692363  0.866888  -0.552629       0.088976   \n",
       "Age               -0.392649   -0.305175  0.215257   0.191443       0.189013   \n",
       "SibSp              0.349434    0.085939 -0.252201   0.061261      -0.024872   \n",
       "Parch              0.267194    0.103551 -0.335765   0.223240      -0.048377   \n",
       "Fare               0.011390    0.119660 -0.181692   0.103920       0.010679   \n",
       "Embarked_C        -0.035471    0.038498 -0.073976   0.067462      -0.008192   \n",
       "Embarked_Q         0.010330    0.169631 -0.079283  -0.090739       0.012520   \n",
       "Embarked_S         0.024577   -0.140514  0.114726  -0.001989      -0.000704   \n",
       "Title_Master       1.000000   -0.110509 -0.255888  -0.088206      -0.031204   \n",
       "Title_Miss        -0.110509    1.000000 -0.600201  -0.206893      -0.073190   \n",
       "Title_Mr          -0.255888   -0.600201  1.000000  -0.479068      -0.169473   \n",
       "Title_Mrs         -0.088206   -0.206893 -0.479068   1.000000      -0.058418   \n",
       "Title_Officer     -0.031204   -0.073190 -0.169473  -0.058418       1.000000   \n",
       "Title_Royalty     -0.016324   -0.038290 -0.088661  -0.030562      -0.010812   \n",
       "\n",
       "               Title_Royalty  \n",
       "PassengerId         0.031681  \n",
       "Survived            0.033666  \n",
       "Pclass             -0.118241  \n",
       "Sex                -0.007728  \n",
       "Age                 0.069560  \n",
       "SibSp              -0.008467  \n",
       "Parch              -0.035673  \n",
       "Fare                0.015222  \n",
       "Embarked_C          0.078960  \n",
       "Embarked_Q         -0.023159  \n",
       "Embarked_S         -0.054604  \n",
       "Title_Master       -0.016324  \n",
       "Title_Miss         -0.038290  \n",
       "Title_Mr           -0.088661  \n",
       "Title_Mrs          -0.030562  \n",
       "Title_Officer      -0.010812  \n",
       "Title_Royalty       1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pairwise correlation of columns\n",
    "corr = train_data.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert this into a visualization for better comprehension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap with the mask\n",
    "sns.heatmap(corr, mask=mask, cmap='RdBu_r', linewidths=.5, cbar_kws={'shrink': .7})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just focus on the 'Survived' variable, we will notice that:\n",
    "* It has a comparatively strong negative correlation with 'Pclass', 'Sex' and 'Title_Mr'\n",
    "* It has a comparatively strong positive correlation with 'Fare', 'Embarked_C', 'Title_Miss' and 'Title_Mrs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Building & Evaluation <a id=\"heading5\"></a>\n",
    "\n",
    "Before we can start building the machine learning models, we need to apply feature scaling to standardize the independent variables within a particular range. This is required because some machine learning algorithms (such as kNN) tend to give more weightage to features with high magnitudes than features with low magnitudes, regardless of the unit of the values. To bring all features to the same level of magnitudes, we need to apply feature scaling.\n",
    "\n",
    "In this case, we will use the MinMaxScaler to scale each feature to a (0, 1) range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (891,16) (15,) (891,16) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-774c3e13d49c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    408\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (891,16) (15,) (891,16) "
     ]
    }
   ],
   "source": [
    "# Apply feature scaling using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_data.iloc[:, 2:] = scaler.fit_transform(train_data.iloc[:, 2:])\n",
    "test_data.iloc[:, 1:] = scaler.transform(test_data.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the dataset looks like after feature scaling (remember, we only need to scale predictor variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex       Age  SibSp  Parch      Fare  \\\n",
       "0            1         0     1.0  1.0  0.271174  0.125    0.0  0.014151   \n",
       "1            2         1     0.0  0.0  0.472229  0.125    0.0  0.139136   \n",
       "2            3         1     1.0  0.0  0.321438  0.000    0.0  0.015469   \n",
       "3            4         1     0.0  0.0  0.434531  0.125    0.0  0.103644   \n",
       "4            5         0     1.0  1.0  0.434531  0.000    0.0  0.015713   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  \\\n",
       "0         0.0         0.0         1.0           0.0         0.0       1.0   \n",
       "1         1.0         0.0         0.0           0.0         0.0       0.0   \n",
       "2         0.0         0.0         1.0           0.0         1.0       0.0   \n",
       "3         0.0         0.0         1.0           0.0         0.0       0.0   \n",
       "4         0.0         0.0         1.0           0.0         0.0       1.0   \n",
       "\n",
       "   Title_Mrs  Title_Officer  Title_Royalty  \n",
       "0        0.0            0.0            0.0  \n",
       "1        1.0            0.0            0.0  \n",
       "2        0.0            0.0            0.0  \n",
       "3        1.0            0.0            0.0  \n",
       "4        0.0            0.0            0.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split our train and test datasets with respect to predictor (X) and response (y) variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train = train_data.iloc[:, 2:], test_data.iloc[:, 1:], train_data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'y_test' is not provided in this dataset. For getting the test scores, we will have to submit our predictions online. To make the entire process a bit smoother, we will write a function that takes in model predictions and generates a file in the required format to submit online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate submission file to get test score\n",
    "def submission(preds):\n",
    "    test_data['Survived'] = preds\n",
    "    predictions = test_data[['PassengerId', 'Survived']]\n",
    "    predictions.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can finally start building machine learning models to predict which of the passengers survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Logistic Regression <a id=\"subheading1\"></a>\n",
    "\n",
    "Important parameters that we will tune:\n",
    "* penalty: Used to specify the norm used in the penalization\n",
    "* C: Inverse of regularization strength\n",
    "\n",
    "For hyperparameter tuning, we will use grid search cross validation over the specified parameter values. We will repeat 5-fold cross validation 10 times so that we can further improve the model performance and reduce overfitting. This will lead to better results for test/unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=10, n_splits=5, random_state=101),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'penalty': ['l1', 'l2', 'elasticnet', 'none']}])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Parameters to tune\n",
    "params = [{'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "           'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}]\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=seed)\n",
    "lr_clf = GridSearchCV(logreg, params, cv=cv, n_jobs=-1)\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "lr_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8273236843775789"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "lr_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train accuracy is 82.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 16 features per sample; expecting 15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-83b0a997f0ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \"\"\"\n\u001b[0;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 16 features per sample; expecting 15"
     ]
    }
   ],
   "source": [
    "# Test score\n",
    "y_preds = lr_clf.predict(X_test)\n",
    "submission(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, the test accuracy is found to be 76.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Gaussian Naive Bayes <a id=\"subheading2\"></a>\n",
    "\n",
    "Using default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (891,16) (15,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-62fe179b9206>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[0mjointi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_prior_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[0mn_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigma_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m             n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) /\n\u001b[0m\u001b[0;32m    457\u001b[0m                                  (self.sigma_[i, :]), 1)\n\u001b[0;32m    458\u001b[0m             \u001b[0mjoint_log_likelihood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjointi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn_ij\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (891,16) (15,) "
     ]
    }
   ],
   "source": [
    "# Test score\n",
    "y_preds = gnb.predict(X_test)\n",
    "submission(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, the test accuracy is found to be 75.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Linear Discriminant Analysis (LDA) <a id=\"subheading3\"></a>\n",
    "\n",
    "Using default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 16 features per sample; expecting 15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-40dd966ffe4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \"\"\"\n\u001b[0;32m    562\u001b[0m         \u001b[1;31m# Only override for the doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 16 features per sample; expecting 15"
     ]
    }
   ],
   "source": [
    "# Test score\n",
    "y_preds = lda.predict(X_test)\n",
    "submission(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, the test accuracy is found to be 77.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 k Nearest Neighbors (kNN) <a id=\"subheading4\"></a>\n",
    "\n",
    "Important parameters that we will tune:\n",
    "* n_neighbors: Number of neighbors to use\n",
    "* p: For choosing between manhattan distance and euclidean distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=10, n_splits=5, random_state=101),\n",
       "             estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid=[{'n_neighbors': range(1, 21), 'p': [1, 2]}])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Parameters to tune\n",
    "params = [{'n_neighbors': range(1, 21),\n",
    "           'p': [1, 2]}]\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=seed)\n",
    "knn_clf = GridSearchCV(knn, params, cv=cv, n_jobs=-1)\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 12, 'p': 1}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "knn_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214771789500412"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "knn_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train accuracy is 82.1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "query data dimension must match training data dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-d6485722a813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \"\"\"\n\u001b[0;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    660\u001b[0m                 \u001b[0mdelayed_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_tree_query_parallel_helper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m                 \u001b[0mparallel_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"prefer\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"threads\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             chunked_results = Parallel(n_jobs, **parallel_kwargs)(\n\u001b[0m\u001b[0;32m    663\u001b[0m                 delayed_query(\n\u001b[0;32m    664\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\neighbors\\_binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree.query\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: query data dimension must match training data dimension"
     ]
    }
   ],
   "source": [
    "# Test score\n",
    "y_preds = knn_clf.predict(X_test)\n",
    "submission(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, the test accuracy is found to be 77.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Support Vector Machine (SVM) <a id=\"subheading5\"></a>\n",
    "\n",
    "Important parameters that we will tune:\n",
    "* C: Penalty parameter for determining the trade-off between setting a larger margin and lowering misclassification\n",
    "* kernel: Specifies the kernel type to be used in the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=10, n_splits=5, random_state=101),\n",
       "             estimator=SVC(max_iter=10000), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification model\n",
    "svm = SVC(max_iter=10000)\n",
    "\n",
    "# Parameters to tune\n",
    "params = [{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "           'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}]\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=seed)\n",
    "svm_clf = GridSearchCV(svm, params, cv=cv, n_jobs=-1)\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "svm_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8284548974798451"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "svm_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train accuracy is 82.8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 16 should be equal to 15, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-5c02b1918ffe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \"\"\"\n\u001b[0;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    482\u001b[0m                                  (X.shape[1], self.shape_fit_[0]))\n\u001b[0;32m    483\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_fit_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0m\u001b[0;32m    485\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m                              (X.shape[1], self.shape_fit_[1]))\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 16 should be equal to 15, the number of features at training time"
     ]
    }
   ],
   "source": [
    "# Test score\n",
    "y_preds = svm_clf.predict(X_test)\n",
    "submission(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, the test accuracy is found to be 77.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Decision Tree <a id=\"subheading6\"></a>\n",
    "\n",
    "Important parameters that we will tune:\n",
    "* max_depth: Maximum depth of the tree\n",
    "* min_samples_split: Minimum number of samples required to split an internal node\n",
    "* max_features: Number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=10, n_splits=5, random_state=101),\n",
       "             estimator=DecisionTreeClassifier(random_state=101), n_jobs=-1,\n",
       "             param_grid=[{'max_depth': [5, 7, 10, None],\n",
       "                          'max_features': ['sqrt', 5, 7, 10],\n",
       "                          'min_samples_split': [2, 5, 10]}])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification model\n",
    "dt = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# Parameters to tune\n",
    "params = [{'max_depth': [5, 7, 10, None],\n",
    "           'min_samples_split': [2, 5, 10],\n",
    "           'max_features': ['sqrt', 5, 7, 10]}]\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=seed)\n",
    "dt_clf = GridSearchCV(dt, params, cv=cv, n_jobs=-1)\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'max_features': 5, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "dt_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161994540722403"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "dt_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train accuracy is 81.6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "y_preds = dt_clf.predict(X_test)\n",
    "submission(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, the test accuracy is found to be 78%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Random Forest <a id=\"subheading7\"></a>\n",
    "\n",
    "Important parameters that we will tune:\n",
    "* n_estimators: Number of trees in the forest\n",
    "* max_depth: Maximum depth of the tree\n",
    "* min_samples_split: Minimum number of samples required to split an internal node\n",
    "* max_features: Number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell will take a while to run depending on the available processing power\n",
    "\n",
    "# Classification model\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# Parameters to tune\n",
    "params = [{'n_estimators': range(50, 550, 50),\n",
    "           'max_depth': [5, 7, 10, None],\n",
    "           'min_samples_split': [2, 5, 10],\n",
    "           'max_features': ['sqrt', 5, 7, 10]}]\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=seed)\n",
    "rf_clf = GridSearchCV(rf, params, cv=cv, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "rf_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "rf_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train accuracy is 83.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "y_preds = rf_clf.predict(X_test)\n",
    "submission(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, the test accuracy is found to be 77%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 XGBoost <a id=\"subheading8\"></a>\n",
    "\n",
    "Important parameters that we will tune:\n",
    "* max_depth: Maximum depth of the tree\n",
    "* learning_rate: Controls the contribution of each tree\n",
    "* n_estimators: Number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell will take a while to run depending on the available processing power\n",
    "\n",
    "# Classification model\n",
    "xgboost = xgb.XGBClassifier(random_state=seed)\n",
    "\n",
    "# Parameters to tune\n",
    "params = [{'max_depth': [3, 5, 10],\n",
    "           'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.07, 0.1],\n",
    "           'n_estimators': range(100, 1100, 100)}]\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=seed)\n",
    "xgb_clf = GridSearchCV(xgboost, params, cv=cv, n_jobs=-1)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "xgb_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "xgb_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train accuracy is 82.9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "y_preds = xgb_clf.predict(X_test)\n",
    "submission(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, the test accuracy is found to be 76.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Model Stacking <a id=\"subheading9\"></a>\n",
    "\n",
    "In this part, we will stack all of our best performing models using the stacking classifier. Predictions generated by various models will be optimally combined to form a new set of predictions. (Note: The new predictions may not always give better result than the individual models).\n",
    "\n",
    "Using default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('lda', LinearDiscriminantAnalysis()),\n",
       "                               ('knn',\n",
       "                                KNeighborsClassifier(n_neighbors=12, p=1)),\n",
       "                               ('svm', SVC(C=1, kernel='poly', max_iter=10000)),\n",
       "                               ('dt',\n",
       "                                DecisionTreeClassifier(max_depth=5,\n",
       "                                                       max_features=5,\n",
       "                                                       random_state=101)),\n",
       "                               ('rf',\n",
       "                                RandomForestClassifier(max_depth=10,\n",
       "                                                       max_features=10,\n",
       "                                                       min_samples_split=10,\n",
       "                                                       n_estimators=300,\n",
       "                                                       random_state=101))],\n",
       "                   final_estimator=LogisticRegression(), n_jobs=-1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models that we will input to stacking classifier\n",
    "base_estimators = list()\n",
    "base_estimators.append(('lda', lda))\n",
    "base_estimators.append(('knn', knn_clf.best_estimator_))\n",
    "base_estimators.append(('svm', svm_clf.best_estimator_))\n",
    "base_estimators.append(('dt', dt_clf.best_estimator_))\n",
    "base_estimators.append(('rf', rf_clf.best_estimator_))\n",
    "\n",
    "# Stacking classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression(), cv=5, n_jobs=-1)\n",
    "stacking_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "y_preds = stacking_clf.predict(X_test)\n",
    "submission(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, the test accuracy is found to be 78%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10 Result Comparison <a id=\"subheading10\"></a>\n",
    "\n",
    "\n",
    "| Model | Train Accuracy (%) | Test Accuracy (%) |\n",
    "| ----- | ------------------ | ----------------- |\n",
    "| Logistic Regression | 82.7 | 76.8 |\n",
    "| Gaussian Naive Bayes | N/A | 75.1 |\n",
    "| Linear Discriminant Analysis | N/A | 77.5 |\n",
    "| k Nearest Neighbors | 82.1 | 77.3 |\n",
    "| Support Vector Machine | 82.8| 77.8 |\n",
    "| Decision Tree | 81.6 | 78 |\n",
    "| Random Forest | 83.7 | 77 |\n",
    "| XGBoost | 82.9 | 76.8 |\n",
    "| Model Stacking | N/A | 78 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above table, we can observe the following:\n",
    "* Random Forest gave the highest train accuracy of 83.7%\n",
    "* Decision Tree and Stacking Classifier performed best for test/unseen data with an accuracy of 78%\n",
    "* Most of the models performed really similar in terms of test accuracy\n",
    "* Due to the small dataset size, all models have (slightly) overfitted the train data, giving lower test scores than expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion <a id=\"heading6\"></a>\n",
    "\n",
    "This notebook gave a brief overview of how different steps are performed in a data science project life cycle. We started by reading in the dataset, preprocessing it, exploring it to find useful insights, and finally built various machine learning models and evaluated them. The main objective of this project was to analyze the titanic dataset and predict whether a passenger will survive or not, based on various input features. To further build and improve upon this project, a lot of techniques could be tried.\n",
    "\n",
    "Innovative ways of feature engineering like combining the 'SibSp' and 'Parch' features, or applying different data preprocessing methods such as binning the 'Age' column could be tried to help improve the overall performance. One technique that will surely improve the scores is to further hypertune the models. Due to limited time and processing power available, we only performed grid search over a few combinations of paramters' values (we also skipped many parameters and used their default value). The extra time spent on tuning the parameters usually leads to better results.\n",
    "\n",
    "Additionally, there are other options for trying and improving the prediction accuracy such as applying feature selection techniques or building deep learning models (e.g. neural networks). Part of a job of data scientists is to be creative, keep experimenting and try figuring out new ways of improving upon their work. The 'titanic survival prediction' task is no exception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This DataFrame is created to stock differents models and fair metrics that we produce in this notebook\n",
    "algo_metrics = pd.DataFrame(columns=['model', 'fair_metrics', 'prediction', 'probs'])\n",
    "\n",
    "def add_to_df_algo_metrics(algo_metrics, model, fair_metrics, preds, probs, name):\n",
    "    return algo_metrics.append(pd.DataFrame(data=[[model, fair_metrics, preds, probs]], columns=['model', 'fair_metrics', 'prediction', 'probs'], index=[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_metrics(dataset, pred, pred_is_dataset=False):\n",
    "    if pred_is_dataset:\n",
    "        dataset_pred = pred\n",
    "    else:\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = pred\n",
    "    \n",
    "    cols = ['statistical_parity_difference', 'equal_opportunity_difference', 'average_abs_odds_difference',  'disparate_impact', 'theil_index']\n",
    "    obj_fairness = [[0,0,0,1,0]]\n",
    "    \n",
    "    fair_metrics = pd.DataFrame(data=obj_fairness, index=['objective'], columns=cols)\n",
    "    \n",
    "    for attr in dataset_pred.protected_attribute_names:\n",
    "        idx = dataset_pred.protected_attribute_names.index(attr)\n",
    "        privileged_groups =  [{attr:dataset_pred.privileged_protected_attributes[idx][0]}] \n",
    "        unprivileged_groups = [{attr:dataset_pred.unprivileged_protected_attributes[idx][0]}] \n",
    "        \n",
    "        classified_metric = ClassificationMetric(dataset, \n",
    "                                                     dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        metric_pred = BinaryLabelDatasetMetric(dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        acc = classified_metric.accuracy()\n",
    "\n",
    "        row = pd.DataFrame([[metric_pred.mean_difference(),\n",
    "                                classified_metric.equal_opportunity_difference(),\n",
    "                                classified_metric.average_abs_odds_difference(),\n",
    "                                metric_pred.disparate_impact(),\n",
    "                                classified_metric.theil_index()]],\n",
    "                           columns  = cols,\n",
    "                           index = [attr]\n",
    "                          )\n",
    "        fair_metrics = fair_metrics.append(row)    \n",
    "    \n",
    "    fair_metrics = fair_metrics.replace([-np.inf, np.inf], 2)\n",
    "        \n",
    "    return fair_metrics\n",
    "\n",
    "def plot_fair_metrics(fair_metrics):\n",
    "    fig, ax = plt.subplots(figsize=(20,4), ncols=5, nrows=1)\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        left    =  0.125, \n",
    "        bottom  =  0.1, \n",
    "        right   =  0.9, \n",
    "        top     =  0.9, \n",
    "        wspace  =  .5, \n",
    "        hspace  =  1.1\n",
    "    )\n",
    "\n",
    "    y_title_margin = 1.2\n",
    "\n",
    "    plt.suptitle(\"Fairness metrics\", y = 1.09, fontsize=20)\n",
    "    sns.set(style=\"dark\")\n",
    "\n",
    "    cols = fair_metrics.columns.values\n",
    "    obj = fair_metrics.loc['objective']\n",
    "    size_rect = [0.2,0.2,0.2,0.4,0.25]\n",
    "    rect = [-0.1,-0.1,-0.1,0.8,0]\n",
    "    bottom = [-1,-1,-1,0,0]\n",
    "    top = [1,1,1,2,1]\n",
    "    bound = [[-0.1,0.1],[-0.1,0.1],[-0.1,0.1],[0.8,1.2],[0,0.25]]\n",
    "\n",
    "    display(Markdown(\"### Check bias metrics :\"))\n",
    "    display(Markdown(\"A model can be considered bias if just one of these five metrics show that this model is biased.\"))\n",
    "    for attr in fair_metrics.index[1:len(fair_metrics)].values:\n",
    "        display(Markdown(\"#### For the %s attribute :\"%attr))\n",
    "        check = [bound[i][0] < fair_metrics.loc[attr][i] < bound[i][1] for i in range(0,5)]\n",
    "        display(Markdown(\"With default thresholds, bias against unprivileged group detected in **%d** out of 5 metrics\"%(5 - sum(check))))\n",
    "\n",
    "    for i in range(0,5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        ax = sns.barplot(x=fair_metrics.index[1:len(fair_metrics)], y=fair_metrics.iloc[1:len(fair_metrics)][cols[i]])\n",
    "        \n",
    "        for j in range(0,len(fair_metrics)-1):\n",
    "            a, val = ax.patches[j], fair_metrics.iloc[j+1][cols[i]]\n",
    "            marg = -0.2 if val < 0 else 0.1\n",
    "            ax.text(a.get_x()+a.get_width()/5, a.get_y()+a.get_height()+marg, round(val, 3), fontsize=15,color='black')\n",
    "\n",
    "        plt.ylim(bottom[i], top[i])\n",
    "        plt.setp(ax.patches, linewidth=0)\n",
    "        ax.add_patch(patches.Rectangle((-5,rect[i]), 10, size_rect[i], alpha=0.3, facecolor=\"green\", linewidth=1, linestyle='solid'))\n",
    "        plt.axhline(obj[i], color='black', alpha=0.3)\n",
    "        plt.title(cols[i])\n",
    "        ax.set_ylabel('')    \n",
    "        ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fair_metrics_and_plot(data, model, plot=False, model_aif=False):\n",
    "    pred = model.predict(data).labels if model_aif else model.predict(data.features)\n",
    "    # fair_metrics function available in the metrics.py file\n",
    "    fair = fair_metrics(data, pred)\n",
    "\n",
    "    if plot:\n",
    "        # plot_fair_metrics function available in the visualisations.py file\n",
    "        # The visualisation of this function is inspired by the dashboard on the demo of IBM aif360 \n",
    "        plot_fair_metrics(fair)\n",
    "        display(fair)\n",
    "    \n",
    "    return fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex       Age  SibSp  Parch      Fare  \\\n",
       "0            1         0     1.0  1.0  0.271174  0.125    0.0  0.014151   \n",
       "1            2         1     0.0  0.0  0.472229  0.125    0.0  0.139136   \n",
       "2            3         1     1.0  0.0  0.321438  0.000    0.0  0.015469   \n",
       "3            4         1     0.0  0.0  0.434531  0.125    0.0  0.103644   \n",
       "4            5         0     1.0  1.0  0.434531  0.000    0.0  0.015713   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  \\\n",
       "0         0.0         0.0         1.0           0.0         0.0       1.0   \n",
       "1         1.0         0.0         0.0           0.0         0.0       0.0   \n",
       "2         0.0         0.0         1.0           0.0         1.0       0.0   \n",
       "3         0.0         0.0         1.0           0.0         0.0       0.0   \n",
       "4         0.0         0.0         1.0           0.0         0.0       1.0   \n",
       "\n",
       "   Title_Mrs  Title_Officer  Title_Royalty  \n",
       "0        0.0            0.0            0.0  \n",
       "1        1.0            0.0            0.0  \n",
       "2        0.0            0.0            0.0  \n",
       "3        1.0            0.0            0.0  \n",
       "4        0.0            0.0            0.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X)\n",
    "\n",
    "\n",
    "#combine_final = [train_df, test_df]\n",
    "#result = pd.concat(combine_final)\n",
    "#print(result.ifany())\n",
    "#print(result)\n",
    "privileged_groups = [{'Sex': 0}]\n",
    "unprivileged_groups = [{'Sex': 1}]\n",
    "dataset_orig = StandardDataset(train_data,\n",
    "                                  label_name='Survived',\n",
    "                                  protected_attribute_names=['Sex'],\n",
    "                                  favorable_classes=[1],\n",
    "                                  privileged_classes=[[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.551476\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "nb_fname = ipynbname.name()\n",
    "nb_path = ipynbname.path()\n",
    "\n",
    "import pickle\n",
    "\n",
    "data_orig_train, data_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "X_train = data_orig_train.features\n",
    "y_train = data_orig_train.labels.ravel()\n",
    "\n",
    "X_test = data_orig_test.features\n",
    "y_test = data_orig_test.labels.ravel()\n",
    "\n",
    "# Models that we will input to stacking classifier\n",
    "base_estimators = list()\n",
    "base_estimators.append(('lda', lda))\n",
    "base_estimators.append(('knn', knn_clf.best_estimator_))\n",
    "base_estimators.append(('svm', svm_clf.best_estimator_))\n",
    "base_estimators.append(('dt', dt_clf.best_estimator_))\n",
    "base_estimators.append(('rf', rf_clf.best_estimator_))\n",
    "\n",
    "# Stacking classifier\n",
    "model = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression(), cv=5, n_jobs=-1)\n",
    "\n",
    "mdl = model.fit(X_train, y_train)\n",
    "with open('../../Results/Stacking/' + nb_fname + '.pkl', 'wb') as f:\n",
    "        pickle.dump(mdl, f)\n",
    "\n",
    "with open('../../Results/Stacking/' + nb_fname + '_Train' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_train, f) \n",
    "    \n",
    "with open('../../Results/Stacking/' + nb_fname + '_Test' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_test, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "final_metrics = []\n",
    "accuracy = []\n",
    "list_estimators = []\n",
    "f1= []\n",
    "\n",
    "for name, ml_model in base_estimators:\n",
    "    \n",
    "    list_estimators.append((name,ml_model))\n",
    "    #print(list_estimators)\n",
    "    model = StackingClassifier(estimators = base_estimators, verbose =1)\n",
    "    \n",
    "    mdl = model.fit(X_train, y_train)\n",
    "    yy = mdl.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, yy))\n",
    "    f1.append(f1_score(y_test, yy))\n",
    "    fair = get_fair_metrics_and_plot(data_orig_test, mdl)                           \n",
    "    fair_list = fair.iloc[1].tolist()\n",
    "    final_metrics.append(fair_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "final_result = pd.DataFrame(final_metrics)\n",
    "final_result[4] = np.log(final_result[4])\n",
    "final_result = final_result.transpose()\n",
    "final_result.loc[0] = f1  # add f1 and acc to df\n",
    "acc = pd.DataFrame(accuracy).transpose()\n",
    "acc = acc.rename(index={0: 'accuracy'})\n",
    "final_result = pd.concat([acc,final_result])\n",
    "final_result = final_result.rename(index={0: 'f1', 1: 'statistical_parity_difference', 2: 'equal_opportunity_difference', 3: 'average_abs_odds_difference', 4: 'disparate_impact', 5: 'theil_index'})\n",
    "final_result.columns = ['T' + str(col) for col in final_result.columns]\n",
    "final_result.insert(0, \"classifier\", final_result['T' + str(len(list_estimators) - 1)])   ##Add final metrics add the beginning of the df\n",
    "final_result.to_csv('../../Results/Stacking/' + nb_fname + '.csv')\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
