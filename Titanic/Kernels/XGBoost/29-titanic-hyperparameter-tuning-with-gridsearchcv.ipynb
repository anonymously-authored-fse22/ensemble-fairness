{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic - Hyperparameter tuning with GridSearchCV\n\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/header.png)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#7ca4cd; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation</center></h3>\n\n* [1. Data loading and feature engineering](#1)\n* [2. Decision Tree](#2)\n* [3. Random Forest](#3)\n* [4. AdaBoost](#4)\n* [5. XGBoost](#5)\n* [6. LightGBM](#6)\n* [7. CatBoost](#7)\n* [8. Logistic Regression](#8)\n* [9. SVC](#9)\n* [10. K-Nearest Neighbors](#10)\n* [Submission](#100)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost as cb\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seed(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n    \n\nSEED = 42\nset_seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>Data loading and feature engineering<center><h2>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check train samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train shape: {train_df.shape}\")\ntrain_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check test samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Test shape: {test_df.shape}\")\ntest_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatenate train and test data together to exploratory analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = pd.concat(\n    [\n        train_df.drop([\"PassengerId\", \"Survived\"], axis=1), \n        test_df.drop([\"PassengerId\"], axis=1),\n    ]\n)\ny_train = train_df[\"Survived\"].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check missed values"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age and Cabin have a lot of NULL values - we can ignore them.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = full_df.drop([\"Age\", \"Cabin\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the distribution of features below to try to fill not so big NULL valued columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.hist(full_df[\"Fare\"], bins=20)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.title(\"Fare distribution\", fontsize=16)\n\nplt.subplot(1, 2, 2)\nembarked_info = full_df[\"Embarked\"].value_counts()\nplt.bar(embarked_info.index, embarked_info.values)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.title(\"Embarked distribution\", fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's fill the Embarked column with more frequently value \"S\".   \nThe column Fare fill with a mean value"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df[\"Embarked\"].fillna(\"S\", inplace=True)\nfull_df[\"Fare\"].fillna(full_df[\"Fare\"].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extract titles of people from their names"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df[\"Title\"] = full_df[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\")\nfull_df[\"Title\"] = full_df[\"Title\"].replace([\"Ms\", \"Mlle\"], \"Miss\")\nfull_df[\"Title\"] = full_df[\"Title\"].replace([\"Mme\", \"Countess\", \"Lady\", \"Dona\"], \"Mrs\")\nfull_df[\"Title\"] = full_df[\"Title\"].replace([\"Dr\", \"Major\", \"Col\", \"Sir\", \"Rev\", \"Jonkheer\", \"Capt\", \"Don\"], \"Mr\")\nfull_df = full_df.drop([\"Name\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encode categories as numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df[\"Sex\"] = full_df[\"Sex\"].map({\"male\": 1, \"female\": 0}).astype(int)    \nfull_df[\"Embarked\"] = full_df[\"Embarked\"].map({\"S\": 1, \"C\": 2, \"Q\": 3}).astype(int)    \nfull_df['Title'] = full_df['Title'].map({\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3}).astype(int)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extract ticket numbers from ticket column (some tickets have the same number - it can be useful)"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df[\"TicketNumber\"] = full_df[\"Ticket\"].str.split()\nfull_df[\"TicketNumber\"] = full_df[\"TicketNumber\"].str[-1]\nfull_df[\"TicketNumber\"] = LabelEncoder().fit_transform(full_df[\"TicketNumber\"])\nfull_df = full_df.drop([\"Ticket\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create new features:\n- FamilySize - total number of family members in the ship\n- IsAlone - the person has some family or traveled alone?"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df[\"FamilySize\"] = full_df[\"SibSp\"] + full_df[\"Parch\"] + 1\nfull_df[\"IsAlone\"] = full_df[\"FamilySize\"].apply(lambda x: 1 if x == 1 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's split the data back into training and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = full_df[:y_train.shape[0]]\nX_test = full_df[y_train.shape[0]:]\n\nprint(f\"Train X shape: {X_train.shape}\")\nprint(f\"Train y shape: {y_train.shape}\")\nprint(f\"Test X shape: {X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create one-hot categorical representations and normalize numerical columns for the gradient-based models"},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_cols = [\"Embarked\", \"Title\"]\nfor col in one_hot_cols:\n    full_df = pd.concat(\n        [full_df, pd.get_dummies(full_df[col], prefix=col)], \n        axis=1, \n        join=\"inner\",\n    )\nfull_df = full_df.drop(one_hot_cols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nfull_df.loc[:] = scaler.fit_transform(full_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_norm = full_df[:y_train.shape[0]]\nX_test_norm = full_df[y_train.shape[0]:]\n\nprint(f\"Train norm X shape: {X_train_norm.shape}\")\nprint(f\"Train y shape: {y_train.shape}\")\nprint(f\"Test norm X shape: {X_test_norm.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's highlight categorical features in one list, since they may be needed for some models"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = ['Sex', 'Embarked', 'Title', 'TicketNumber', 'IsAlone']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save mean cross-validated accuracy scores of best models"},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_valid_scores = {}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>Decision Tree<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_desicion_tree = DecisionTreeClassifier(\n    random_state=SEED,\n    class_weight='balanced',\n)\n\nmodel_desicion_tree = GridSearchCV(\n    model_desicion_tree, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_desicion_tree.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_desicion_tree.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \\\n    f'{model_desicion_tree.best_score_:.3f}'\n)\ncross_valid_scores['desicion_tree'] = model_desicion_tree.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>Random Forest<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"n_estimators\": [5, 10, 15, 20, 25], \n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_random_forest = RandomForestClassifier(\n    random_state=SEED,\n    class_weight='balanced',\n)\n\nmodel_random_forest = GridSearchCV(\n    model_random_forest, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_random_forest.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_random_forest.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{model_random_forest.best_score_:.3f}'\n)\ncross_valid_scores['random_forest'] = model_random_forest.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>AdaBoost<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"n_estimators\": [5, 10, 15, 20, 25, 50, 75, 100], \n    \"learning_rate\": [0.001, 0.01, 0.1, 1.],\n}\n\nmodel_adaboost = AdaBoostClassifier(\n    random_state=SEED,\n)\n\nmodel_adaboost = GridSearchCV(\n    model_adaboost, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_adaboost.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_adaboost.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{model_adaboost.best_score_:.3f}'\n)\ncross_valid_scores['ada_boost'] = model_adaboost.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>XGBoost<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    'max_depth': [3, 5, 7, 9], \n    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1]\n}\n\nmodel_xgb = xgb.XGBClassifier(\n    random_state=SEED,\n)\n\nmodel_xgb = GridSearchCV(\n    model_xgb, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_xgb.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_xgb.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_xgb.best_score_:.3f}'\n)\ncross_valid_scores['xgboost'] = model_xgb.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>LightGBM<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'num_leaves': [7, 15, 31],\n}\n\nmodel_lgbm = lgbm.LGBMClassifier(\n    random_state=SEED,\n    class_weight='balanced',\n)\n\nmodel_lgbm = GridSearchCV(\n    model_lgbm, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_lgbm.fit(\n    X_train, \n    y_train, \n    categorical_feature=categorical_columns\n)\n\nprint('-----')\nprint(f'Best parameters {model_lgbm.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_lgbm.best_score_:.3f}'\n)\ncross_valid_scores['lightgbm'] = model_lgbm.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>CatBoost<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    'iterations': [5, 10, 15, 20, 25, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'depth': [3, 5, 7, 9, 11, 13],\n}\n\nmodel_catboost = cb.CatBoostClassifier(\n    verbose=False,\n)\n\nmodel_catboost = GridSearchCV(\n    model_catboost, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_catboost.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_catboost.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_catboost.best_score_:.3f}'\n)\ncross_valid_scores['catboost'] = model_catboost.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>Logistic Regression<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"C\": [0.001, 0.01, 0.1, 1.],\n    \"penalty\": [\"l1\", \"l2\"]\n}\n\nmodel_logistic_regression = LogisticRegression(\n    random_state=SEED,\n    class_weight=\"balanced\",\n    solver=\"liblinear\",\n)\n\nmodel_logistic_regression = GridSearchCV(\n    model_logistic_regression, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_logistic_regression.fit(X_train_norm, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_logistic_regression.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_logistic_regression.best_score_:.3f}'\n)\ncross_valid_scores['logistic_regression'] = model_logistic_regression.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>SVC<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"C\": [0.001, 0.01, 0.1, 1.],\n    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n    \"gamma\": [\"scale\", \"auto\"],\n}\n\nmodel_svc = SVC(\n    random_state=SEED,\n    class_weight=\"balanced\",\n    probability=True,\n)\n\nmodel_svc = GridSearchCV(\n    model_svc, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_svc.fit(X_train_norm, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_svc.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_svc.best_score_:.3f}'\n)\ncross_valid_scores['svc'] = model_svc.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"10\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>K-Nearest Neighbors<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"weights\": [\"uniform\", \"distance\"],\n}\n\nmodel_k_neighbors = KNeighborsClassifier(\n)\n\nmodel_k_neighbors = GridSearchCV(\n    model_k_neighbors, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_k_neighbors.fit(X_train_norm, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_k_neighbors.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_k_neighbors.best_score_:.3f}'\n)\ncross_valid_scores['k_neighbors'] = model_k_neighbors.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"100\"></a>\n<h2 style='background:#7ca4cd; border:0; color:white'><center>Submission<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(cross_valid_scores, index=['cross_valid_score']).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_submission(model, X_test, test_passenger_id, model_name):\n    y_pred_test = model.predict_proba(X_test)[:, 1]\n    submission = pd.DataFrame(\n        {\n            'PassengerId': test_passenger_id, \n            'Survived': (y_pred_test >= 0.5).astype(int),\n        }\n    )\n    submission.to_csv(f\"submission_{model_name}.csv\", index=False)\n    \n    return y_pred_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_decision_tree = create_submission(\n    model_desicion_tree, X_test, test_df[\"PassengerId\"], \"decision_tree\"\n)\ntest_pred_random_forest = create_submission(\n    model_random_forest, X_test, test_df[\"PassengerId\"], \"random_forest\"\n)\ntest_pred_adaboost = create_submission(\n    model_adaboost, X_test, test_df[\"PassengerId\"], \"adaboost\"\n)\ntest_pred_xgboost = create_submission(\n    model_xgb, X_test, test_df[\"PassengerId\"], \"xgboost\"\n)\ntest_pred_lightgbm = create_submission(\n    model_lgbm, X_test, test_df[\"PassengerId\"], \"lightgbm\"\n)\ntest_pred_catboost = create_submission(\n    model_catboost, X_test, test_df[\"PassengerId\"], \"catboost\"\n)\ntest_pred_logistic_regression = create_submission(\n    model_logistic_regression, X_test_norm, test_df[\"PassengerId\"], \"logistic_regression\"\n)\ntest_pred_svc = create_submission(\n    model_svc, X_test_norm, test_df[\"PassengerId\"], \"svc\"\n)\ntest_pred_k_neighbors = create_submission(\n    model_k_neighbors, X_test_norm, test_df[\"PassengerId\"], \"k_neighbors\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_merged = (\n    test_pred_decision_tree + \n    test_pred_random_forest + \n    test_pred_adaboost +\n    test_pred_xgboost + \n    test_pred_lightgbm + \n    test_pred_catboost +\n    test_pred_logistic_regression + \n    test_pred_svc +\n    test_pred_k_neighbors\n)\ntest_pred_merged = np.round(test_pred_merged / 9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(\n    {\n        'PassengerId': test_df[\"PassengerId\"], \n        'Survived': test_pred_merged.astype(int),\n    }\n)\nsubmission.to_csv(f\"submission_merged.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}