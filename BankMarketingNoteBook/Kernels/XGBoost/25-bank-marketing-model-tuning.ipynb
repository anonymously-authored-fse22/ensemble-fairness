{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Contents:**\n<ol>\n    <li><a href='#intro'> Introduction </a></li> \n    <li><a href='#exp_data'> Exploring Data </a></li>\n    <li><a href='#train_model'> Train the model </a></li>\n    <li><a href='#predict'> Predicts </a> </li>\n    <li><a href='#parameter_tuning'> Parameter tuning </a></li>\n    <ul>\n        <li><a href=\"#rf\">RandomForestClassifier</a></li>\n        <li><a href=\"#kn\"> KNeigbhors Classifier </a></li>\n    </ul>\n    <li><a href='#conclusion'> Conclusion </a></li>\n    <li><a href=\"#ref\">References</a></li>\n</ol>"},{"metadata":{},"cell_type":"markdown","source":"<h3 id='intro'>Introduction</h3>\n<h4>Problem statement : has the client subscribed a term deposit? Yes or No </h4>\n<br/>\nIt one binary classification problem, So what I will do first? I will explore data and visualization data then train model using **sklearn, catboost,** after that I will try to optimize this model. I will also delete unnecessary columns.<br/><br/>\n**Note:** <ol><li>My english is not very good.</li>\n    <li>If you like this kernel please upvote.</li>\n    </ol>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import rcParams\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')\n\ncolor = sns.color_palette()\nrcParams['figure.figsize'] = 10, 6\nlbl = LabelEncoder()\n\n\n%matplotlib inline\npd.set_option('display.max_columns', 50)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#s1 = pd.Series([4,5,6,20,42])\n#s2 = pd.Series([1,2,3,5,42])\n\n#s1[s1.isin(s2)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f=open(os.path.join('/kaggle/input', 'bank-marketing/bank-additional-names.txt'), \"r\")\nif f.mode == 'r':\n    contents =f.read()\n    print(contents)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/bank-marketing/bank-additional-full.csv', sep = ';')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 id='exp_data'>Exploring Data </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['y'] == 'yes'].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['y'] == 'no'].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(df['marital'],df['y'], normalize='index'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x='marital', hue='y', data=df)\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_target_yes = df[(df['age'] > 0) & (df['y'] == 'yes')]\nage_target_no = df[(df['age'] > 0) & (df['y'] == 'no')]\n\nplt.figure(figsize=(10, 6))\nsns.distplot(age_target_yes['age'], bins=25, color='g')\nsns.distplot(age_target_no['age'], bins=25, color='r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = pd.DataFrame()\ngroup['job_count'] = df.groupby(['job'])['job'].count()\ngroup['job_index'] = group.index\n\ngroup_top = group.sort_values(by='job_count', ascending=False).head(15)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x='job_index', y ='job_count', data =group_top)\nplt.xticks(rotation=45)\nplt.title('Count job types')\nplt.xlabel('Job types')\nplt.ylabel('Number of job each type')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# other attributes:<br/>\n  12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)<br/>\n  13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)<br/>\n  14 - previous: number of contacts performed before this campaign and for this client (numeric)<br/>\n  15 - poutcome: outcome of the previous marketing campaign (categorical: \"failure\",\"nonexistent\",\"success\")"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['poutcome'])['poutcome'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(df['poutcome'], df['y']))\nsns.countplot(x='poutcome', hue='y', data=df)\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I expect this result. If client previous marketing campaign successful then they will subscribed  term deposit."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(df['contact'], df['y']))\nsns.countplot(x='contact', hue='y', data=df)\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.boxenplot(x='education', y='cons.price.idx', hue='y', data=df )\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\ng = sns.distplot(df[df['y'] == 'yes']['nr.employed'], label='Yes')\ng= sns.distplot(df[df['y'] == 'no']['nr.employed'], label='No')\ng.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\ng = sns.distplot(df[df['y'] == 'yes']['euribor3m'], label='Yes')\ng= sns.distplot(df[df['y'] == 'no']['euribor3m'], label='No')\ng.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\ng = sns.distplot(df[df['y'] == 'yes']['cons.conf.idx'], label='Yes')\ng= sns.distplot(df[df['y'] == 'no']['cons.conf.idx'], label='No')\ng.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\ng = sns.distplot(df[df['y'] == 'yes']['emp.var.rate'], label='Yes')\ng= sns.distplot(df[df['y'] == 'no']['emp.var.rate'], label='No')\ng.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\ng = sns.distplot(df[df['y'] == 'yes']['cons.conf.idx'], label='Yes')\ng= sns.distplot(df[df['y'] == 'no']['cons.conf.idx'], label='No')\ng.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\ng = sns.distplot(df[df['y'] == 'yes']['cons.price.idx'], label='Yes')\ng= sns.distplot(df[df['y'] == 'no']['cons.price.idx'], label='No')\ng.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\ntmp = pd.crosstab(df['marital'], df['y'], normalize='index') * 100\ntmp = tmp.reset_index()\nplt.subplot(221)\ng = sns.countplot(x='marital', data=df, order=list(tmp.marital.values))\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3, '{:1.2f}%'.format(height/df.shape[0]*100),\n            ha=\"center\",fontsize=14) \n    \nplt.xticks(rotation=45)\nplt.subplot(222)\ng1 = sns.countplot(x='marital', hue='y', data=df,order=list(tmp.marital.values))\nplt.subplots_adjust(hspace = 0.6, top = 1.4)\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\ntmp = pd.crosstab(df['education'], df['y'], normalize='index') * 100\ntmp = tmp.reset_index()\nplt.subplot(221)\ng = sns.countplot(x='education', data=df, order=list(tmp.education.values))\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3, '{:1.2f}%'.format(height/df.shape[0]*100),\n            ha=\"center\",fontsize=14) \n    \nplt.xticks(rotation=45)\nplt.subplot(222)\ng1 = sns.countplot(x='education', hue='y', data=df,order=list(tmp.education.values))\nplt.subplots_adjust(hspace = 0.6, top = 1.4)\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\ntmp = pd.crosstab(df['month'], df['y'], normalize='index') * 100\ntmp = tmp.reset_index()\nplt.subplot(221)\ng = sns.countplot(x='month', data=df, order=list(tmp.month.values))\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3, '{:1.2f}%'.format(height/df.shape[0]*100),\n            ha=\"center\",fontsize=14) \n    \nplt.xticks(rotation=45)\nplt.subplot(222)\ng1 = sns.countplot(x='month', hue='y', data=df,order=list(tmp.month.values))\nplt.subplots_adjust(hspace = 0.6, top = 1.4)\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\ntmp = pd.crosstab(df['job'], df['y'], normalize='index') * 100\ntmp = tmp.reset_index()\nplt.subplot(221)\ng = sns.countplot(x='job', data=df, order=list(tmp.job.values))\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3, '{:1.2f}%'.format(height/df.shape[0]*100),\n            ha=\"center\",fontsize=14) \n    \nplt.xticks(rotation=45)\nplt.subplot(222)\ng1 = sns.countplot(x='job', hue='y', data=df,order=list(tmp.job.values))\nplt.subplots_adjust(hspace = 0.6, top = 1.4)\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false,"collapsed":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.plot(df['cons.price.idx'])\n#plt.plot(df['euribor3m'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target(y) columns have to change yes to 1 and no to 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['y'] = df['y'].map({'yes':1, 'no':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['marital'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['marital'] = df['marital'].map({'married':1, 'single':2, 'divorced':3, 'unknown':4})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['education'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['education'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['education'] = df['education'].map({'basic.4y':1, 'high.school':2, 'basic.6y':3, 'basic.9y':4,\n       'professional.course':5, 'unknown':6, 'university.degree':6, 'illiterate':7})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nimport xgboost as xgb\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#g = sns.FacetGrid(df, hue=\"y\", col=\"housing\", margin_titles=True)\n#g=g.map(plt.scatter, \"age\", \"marital\",edgecolor=\"w\").add_legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''age_target_yes = df[(df['age'] > 0) & (df['y'] == 1)]\nage_target_no = df[(df['age'] > 0) & (df['y'] == 0)]\n\nplt.scatterplot(age_target_yes['age'], age_target_yes.index, color='red')\nplt.scatter(age_target_no['age'], age_target_no.index, color='green')\nplt.show()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''sns.scatterplot(x='age', y= df.index, hue='y',  data=df)\nplt.show()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['poutcome']=  df['poutcome'].map({'nonexistent':1, 'failure':2, 'success':3})\ndf['contact'] = df['contact'].map({'telephone':1, 'cellular':2})\ndf['housing'] = df['housing'].map({'no':1, 'yes':2, 'unknown':3})\ndf['loan'] = df['loan'].map({'no':1, 'yes':2, 'unknown':3})\ndf['default'] = df['default'].map({'no':1, 'yes':2, 'unknown':3})\ndf['job'] = df['job'].map({'housemaid':1, 'services':2, 'admin.':3, 'blue-collar':4, 'technician':5,\n       'retired':6, 'management':7, 'unemployed':8, 'self-employed':9, 'unknown':10,\n       'entrepreneur':11, 'student':12})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"month and day_of_week this both columns have to delete because It seems this is not useful."},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['day_of_week']\ndel df['month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 id='train_model'>Train the model</h3>"},{"metadata":{},"cell_type":"markdown","source":"Finally not an object data types in this dataset. It is ready to apply in ML model."},{"metadata":{},"cell_type":"markdown","source":"I am to select feature columns and label column for model training."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_col = ['age', 'job','marital', 'education', 'default','housing','loan', 'contact','duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx','euribor3m','nr.employed']\nlabel_col = ['y']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(df[feature_col],df[label_col], test_size=0.2, random_state=52)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 id='parameter_tuning'> Parameter tuning</h3>"},{"metadata":{},"cell_type":"markdown","source":"<h4 id=\"rf\"> RandomForestClassifier </h4>\nRandomForestClassifier run without any parameter then try to give parameter."},{"metadata":{"trusted":true},"cell_type":"code","source":"randomforest = RandomForestClassifier()\nrandomforest.fit(X_train,Y_train)\nrandomforest_score = round(randomforest.score(X_train,Y_train)*100, 2)\n#model_name.append('RandomForestClassifier')\n#model_score.append(randomforest_score)\nrandomforest_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_y = randomforest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''predict_y.shape\npredict_y\nY_test.shape\nY_test['y'].shape[0]\nnp.array(Y_test['y'])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prob = predict_y[predict_y == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_result = roc_auc_score(Y_test['y'], predict_y)\nprint('AUC: %.2f' % auc_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(Y_test['y'], predict_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#roc_auc = auc(fpr, tpr)\n#roc_auc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**N_estimators** "},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train, X_test, Y_train, Y_test \n\nn_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n\ntrain_results =[]\ntest_results =[]\n\nfor estimator in n_estimators:\n    rf = RandomForestClassifier(n_estimators=estimator, n_jobs= -1)\n    rf.fit(X_train,Y_train)\n    \n    train_pred = rf.predict(X_train)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n\n    roc_auc = auc(false_positive_rate,true_positive_rate)\n    train_results.append(roc_auc)\n    \n    y_pred = rf.predict(X_test)\n   \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \n    \nfrom matplotlib.legend_handler import HandlerLine2D\n\nline1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\" )\nline2, = plt.plot(n_estimators, test_results, 'r', label =\"Test AUC\")\n\nplt.legend(handler_map = {line1: HandlerLine2D(numpoints = 2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#n_estimators=64 is best "},{"metadata":{"trusted":true},"cell_type":"code","source":"#np.arange(1, 33, 1)\n#max_depths = np.linspace(1, 32, 32, endpoint=True)\n#max_depths\n#np.linspace(1, 32, 32, endpoint=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmax_depths = np.arange(1, 33, 1)\ntrain_results = []\ntest_results = []\nfor max_depth in max_depths:\n    rf = RandomForestClassifier(max_depth=max_depth, n_jobs=-1)\n    rf.fit(X_train, Y_train)\n    train_pred = rf.predict(X_train)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n\n    train_results.append(roc_auc)\n    y_pred = rf.predict(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\nfrom matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('AUC score')\nplt.xlabel('Tree depth')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train, X_test, Y_train, Y_test\nmin_samples_splits = np.linspace(0.1, 1.0, 10,  endpoint=True)\n\ntrain_results = []\ntest_results = []\n\nfor min_samples_split in min_samples_splits:\n    rf = RandomForestClassifier(min_samples_split= min_samples_split )\n    rf.fit(X_train, Y_train)\n    \n    train_pred = rf.predict(X_train)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    \n    y_pred = rf.predict(X_test)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \nfrom matplotlib.legend_handler import HandlerLine2D\n\nline1, = plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')\nline2, = plt.plot(min_samples_splits, test_results, 'r', label=\"Test AUC\")\nplt.legend(handler_map={line1:HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC Score')\nplt.xlabel('Min Samples split')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Intersting:** This is underfitting case. <br/>\nNow we will check min_samples_leaf parameter values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\n\ntrain_results = []\ntest_results =[]\n\nfor min_samples_leaf in min_samples_leafs:\n    rf = RandomForestClassifier(min_samples_leaf=min_samples_leaf)\n    rf.fit(X_train, Y_train)\n    \n    train_pred = rf.predict(X_train)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n    \n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    \n    y_pred = rf.predict(X_test)\n    \n    false_positive_rate, true_positive_rate,thresholds = roc_curve(Y_test, y_pred)\n    \n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nfrom matplotlib.legend_handler import HandlerLine2D    \nline1, = plt.plot(min_samples_leafs,train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(min_samples_leafs, test_results, 'r', label='Test AUC')\nplt.legend(handler_map={line1:HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC Score')\nplt.xlabel('Min Samples leaf')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will try to max_features "},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = list(range(1, df.shape[1]))\n#print(max_features)\n\ntrain_results =[]\ntest_results =[]\n\nfor max_feature in max_features:\n    rf = RandomForestClassifier(max_features = max_feature)\n    rf.fit(X_train, Y_train)\n    \n    train_pred = rf.predict(X_train)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    \n    y_pred = rf.predict(X_test)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    \n    test_results.append(roc_auc)\n\nfrom matplotlib.legend_handler import HandlerLine2D       \nline1, =plt.plot(max_features, train_results, 'b', label=\"Train AUC\")\nline2, =plt.plot(max_features, test_results, 'r', label=\"Test AUC\")\n\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC Score')\nplt.xlabel('Max features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4 id=\"kn\">KNeigbhors Classifier and tuning KNeighbors</h4>"},{"metadata":{},"cell_type":"markdown","source":"Without any parmater predict **Target values** after that tuning model."},{"metadata":{"trusted":true},"cell_type":"code","source":"kn = KNeighborsClassifier()\nkn.fit(X_train, Y_train)\n\ny_pred = kn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC AUC\",round(roc_auc,2))\nprint(\"Score\", round(kn.score(X_train,Y_train)*100, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(false_positive_rate, true_positive_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**n_neighbors**"},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbors = list(range(1, 30))\n\ntrain_results = []\ntest_results =[]\n\nfor n in neighbors:\n    kn = KNeighborsClassifier(n_neighbors=n)\n    kn.fit(X_train, Y_train)\n    \n    train_pred = kn.predict(X_train)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    \n    y_pred = kn.predict(X_test)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \nline1, = plt.plot(neighbors, train_results, 'b', label='Train AUC')\nline2, = plt.plot(neighbors, test_results, 'r', label='Test AUC')\n\nplt.legend(handler_map ={line1:HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC Score')\nplt.xlabel('n_neigbors')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When neighbors number increasing result is imporve."},{"metadata":{"trusted":true},"cell_type":"code","source":"distances = [1, 2, 3, 4, 5]\n\ntrain_results = []\ntest_results = []\n\nfor p in distances:\n    kn = KNeighborsClassifier(p=p)\n    kn.fit(X_train, Y_train)\n    \n    train_pred = kn.predict(X_train)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    \n    y_pred = kn.predict(X_test)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n    \n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \nline1, = plt.plot(distances, train_results, 'b', label='Train AUC')\nline2, = plt.plot(distances, test_results, 'r', label='Test AUC')\n\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC Score')\nplt.xlabel('P')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>GradientBoostingClassifier</h4>"},{"metadata":{"trusted":true},"cell_type":"code","source":"gbclassifier = GradientBoostingClassifier()\ngbclassifier.fit(X_train, Y_train)\ny_pred = gbclassifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test AUC value before add any parameter."},{"metadata":{"trusted":true},"cell_type":"code","source":"false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"AUC \",round(roc_auc, 2))\nprint(\"Score\", round(gbclassifier.score(X_train,Y_train)*100, 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Learning_rate**"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n\ntrain_results = []\ntest_results = []\n\nfor eta in learning_rates:\n    gbclassifier = GradientBoostingClassifier(learning_rate=eta)\n    gbclassifier.fit(X_train, Y_train)\n    \n    train_pred = gbclassifier.predict(X_train)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    \n    y_pred = gbclassifier.predict(X_test)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \nline1, = plt.plot(learning_rates, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(learning_rates, test_results, 'r', label=\"Test AUC\")\n\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('AUC Score')\nplt.xlabel('Learn')\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**N_estimators**"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n\ntrain_results = []\ntest_results = []\n\nfor estimator in n_estimators:\n    gbclassifier = GradientBoostingClassifier(n_estimators=estimator)\n    gbclassifier.fit(X_train, Y_train)\n    \n    train_pred = gbclassifier.predict(X_train)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n    roc_auc =auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    \n    y_pred = gbclassifier.predict(X_test)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \nline1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(n_estimators, test_results, 'r', label=\"Test AUC\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If number of estimator increasing result in overfitting. "},{"metadata":{},"cell_type":"markdown","source":"**Max depth**"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''max_depths = np.linspace(1, 32, 32, endpoint=True)\n\ntrain_results =[]\ntest_results = []\n\nfor max_depth in max_depths:\n    gbclassifier = GradientBoostingClassifier(max_depth=max_depth)\n    gbclassifier.fit(X_train, Y_train)\n    \n    train_pred = gbclassifier.predict(X_train)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    \n    y_pred = gbclassifier.predict(X_test)\n    \n    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n    \n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \nline1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 id='conclusion'>Conclusion</h3>\nI am working on this kernel. "},{"metadata":{},"cell_type":"markdown","source":"<h3 id=\"ref\">References</h3>\nhttps://medium.com/@mohtedibf/in-depth-parameter-tuning-for-knn-4c0de485baf6 <br/>\nhttps://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae <br/>\nhttps://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d <br/>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}