{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank_Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification problem - will client subscribe a deposit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_palette('husl')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier  # for K nearest neighbours\n",
    "from sklearn import svm  #for Support Vector Machine (SVM) Algorithm\n",
    "from sklearn import metrics #for checking the model accuracy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from scipy.stats import skew \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../input/bank-marketing/bank-additional-full.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imbalanced data\n",
    "print('Imbalanced data','\\n',data['y'].value_counts())\n",
    "print('Null',data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label=LabelEncoder()\n",
    "data['y']=label.fit_transform(data['y'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, hue=\"y\", height=5) \\\n",
    "   .map(sns.distplot, \"age\") \\\n",
    "   .add_legend();\n",
    "bins=[0,29,32,37,43,52,58,62,100]\n",
    "for i in bins:\n",
    "    plt.axvline(i,c='green',linewidth=1,linestyle=\"--\")  #vertical line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = [1,2,3,4,5,6,7,8]\n",
    "data['age_range'] = (pd.cut(data.age, bins, labels = labels)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, hue=\"y\", height=5) \\\n",
    "   .map(sns.distplot, \"duration\") \\\n",
    "   .add_legend();\n",
    "bins=[-1,30,100,180,319,650,1000,1800,5500]\n",
    "for i in bins:\n",
    "    plt.axvline(i,c='green',linewidth=1,linestyle=\"--\")  #vertical line\n",
    "labels = [1,2,3,4,5,6,7,8]\n",
    "data['dur_range'] = (pd.cut(data.duration, bins, labels = labels)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dur_range.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pdays - days after 1st Call (999 if 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['1st_call'] = data['pdays'].map(lambda x: 1 if x == 999 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['1st_call'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pdays'] = data['pdays'].map(lambda x: 0 if x == 999 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Num and Cat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['y'].copy()\n",
    "data=data.drop(['y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['campaign'] = data['campaign'].astype('object')\n",
    "feat=data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_cat = np.where(data[feat].dtypes == np.object)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dum object column\n",
    "data= pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mass_calc(X,y):\n",
    "\n",
    "    #Some parameters\n",
    "\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n",
    "\n",
    "    #Split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "    #Standartize\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    a=[]\n",
    "   \n",
    "    #Search knn_param\n",
    "    a_index=list(range(1,11))\n",
    "    knn=[1,2,3,4,5,6,7,8,9,10]\n",
    "    a=[]\n",
    "    for i in knn:\n",
    "        model=KNeighborsClassifier(n_neighbors=i) \n",
    "        model.fit(X_train_std, y_train)\n",
    "        prediction=model.predict(X_test_std)\n",
    "        a.append(pd.Series(metrics.accuracy_score(prediction,y_test)))\n",
    "\n",
    "\n",
    "    #Max_Score_KNN\n",
    "    knn=pd.DataFrame(knn)\n",
    "    a=pd.DataFrame(a)\n",
    "    knn_data=pd.concat([knn,a],axis=1)\n",
    "    knn_data.columns=['Neig','Score']\n",
    "    knn_take=int(knn_data[knn_data['Score']==knn_data['Score'].max()][:1]['Neig'])\n",
    "\n",
    "    #model\n",
    "    #SolveLater How to write names automat\n",
    "    x=['CatB','XGB','RandomF','NB','svm.SVC','Log','DTr',str('KN='+str(knn_take))]\n",
    "    #Form for cycle\n",
    "\n",
    "    models=[CatBoostClassifier(),XGBClassifier(),RandomForestClassifier(),GaussianNB(),svm,LogisticRegression(),DecisionTreeClassifier(),KNeighborsClassifier(n_neighbors=knn_take)]\n",
    "    a_index=list(range(1,len(models)+1))\n",
    "    a=[]\n",
    "    for model in models:\n",
    "\n",
    "        model.fit(X_train_std, y_train)\n",
    "        prediction=model.predict(X_test_std)\n",
    "        a.append(pd.Series(metrics.accuracy_score(prediction,y_test)))\n",
    "    plt.plot(x, a)\n",
    "    #plt.xticks(x)\n",
    "    #MAX_Score+Model\n",
    "    x=pd.DataFrame(x)\n",
    "    a=pd.DataFrame(a)\n",
    "    all_scores=pd.concat([x,a],axis=1)\n",
    "    all_scores.columns=['model','Score']\n",
    "    print('Max_score:',all_scores[all_scores['Score']==all_scores['Score'].max()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mass_calc(data,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best XGB  0.92 by accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mass_calc(X,y,Score):\n",
    "\n",
    "    #Some parameters\n",
    "\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n",
    "\n",
    "    #Split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "    #Standartize\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    a=[]\n",
    "   \n",
    "    #Search knn_param\n",
    "    a_index=list(range(1,11))\n",
    "    knn=[1,2,3,4,5,6,7,8,9,10]\n",
    "    a=[]\n",
    "    for i in knn:\n",
    "        model=KNeighborsClassifier(n_neighbors=i) \n",
    "        model.fit(X_train_std, y_train)\n",
    "        prediction=model.predict(X_test_std)\n",
    "        a.append(pd.Series(Score(prediction,y_test)))\n",
    "\n",
    "\n",
    "    #Max_Score_KNN\n",
    "    knn=pd.DataFrame(knn)\n",
    "    a=pd.DataFrame(a)\n",
    "    knn_data=pd.concat([knn,a],axis=1)\n",
    "    knn_data.columns=['Neig','Score']\n",
    "    knn_take=int(knn_data[knn_data['Score']==knn_data['Score'].max()][:1]['Neig'])\n",
    "\n",
    "    #model\n",
    "    #SolveLater How to write names automat\n",
    "    x=['CatB','XGB','RandomF','NB','svm.SVC','Log','DTr',str('KN='+str(knn_take))]\n",
    "    #Form for cycle\n",
    "\n",
    "    models=[CatBoostClassifier(),XGBClassifier(),RandomForestClassifier(),GaussianNB(),svm,LogisticRegression(),DecisionTreeClassifier(),KNeighborsClassifier(n_neighbors=knn_take)]\n",
    "    a_index=list(range(1,len(models)+1))\n",
    "    a=[]\n",
    "    for model in models:\n",
    "\n",
    "        model.fit(X_train_std, y_train)\n",
    "        prediction=model.predict(X_test_std)\n",
    "        a.append(pd.Series(Score(prediction,y_test)))\n",
    "    plt.plot(x, a)\n",
    "    #plt.xticks(x)\n",
    "    #MAX_Score+Model\n",
    "    x=pd.DataFrame(x)\n",
    "    a=pd.DataFrame(a)\n",
    "    all_scores=pd.concat([x,a],axis=1)\n",
    "    all_scores.columns=['model','Score']\n",
    "    print('Max_score:',all_scores[all_scores['Score']==all_scores['Score'].max()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mass_calc(data,y,metrics.roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best XGB  0.81 by auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check XGB stability using Cross_Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
