{"cells":[{"metadata":{},"cell_type":"markdown","source":"Thanks for clicking!!\n\nI will try to show my logic of each steps of the whole process."},{"metadata":{},"cell_type":"markdown","source":"#**Dataset Introduction**\n\nThe data is related with direct marketing campaigns(phone calls) of a Portuguese banking institution. Our classification goal is to predict if the client will subscribe a product.\n\nTherefore, first we can identity the Dependent variable(Y) is a dummy variable which is if the client will subscire(Yes/No) of a term deposit. That actually will affect our chose of models. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import libraries\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import data\nd1 = pd.read_csv('../input/bank-additional-full.csv',sep = ';', header = 0)\n\n#we can first find out the types of each variables that decide \n#what preprocessing skills that we will need for each variables\nd1.info()\n\n#There are 21 variables in total and no missing values,but later \n#we can know that theres unknown category in several variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nAfter have a basic understanding of the dataset's structure, next I will start data preprocessing part.\n\nFirst, we can see from the dataframe, a lot variales are categorical variables. The following data description is from UCI\nsource: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"},{"metadata":{},"cell_type":"markdown","source":"Bank client data:\n\n1 - age (numeric)\n\n2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n\n3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n\n4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n\n5 - default: has credit in default? (categorical: 'no','yes','unknown')\n\n6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n\n7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"d1.job.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1.marital.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1.education.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nd2 = d1\nunknown = {\"job\": {\"unknown\": \"admin.\"},\n          \"marital\": {\"unknown\": \"married\"},\n          \"education\": {\"unknown\": \"university.degree\"},\n          \"default\": {\"unknown\": \"no\"},\n          \"housing\": {\"unknown\": \"yes\"},\n          \"loan\": {\"unknown\": \"no\"}}\nd2.replace(unknown,inplace = True)\n#replace unknown in each column to the most frequent in that column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d2.age.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I divide age starting rom 25% quantile and then add 20 to each categories using the \n\ndef age(dataframe):\n    dataframe.loc[dataframe['age'] <= 32, 'age'] = 1\n    dataframe.loc[(dataframe['age'] > 32) & (dataframe['age'] <= 52), 'age'] = 2\n    dataframe.loc[(dataframe['age'] > 52) & (dataframe['age'] <= 72), 'age'] = 3\n    dataframe.loc[(dataframe['age'] > 72) & (dataframe['age'] <= 98), 'age'] = 4\n           \n    return dataframe\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age(d2).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode varables that already become dummy \nlabelencoder_X = LabelEncoder()\nd2.job = labelencoder_X.fit_transform(d2.job)\nd2.marital = labelencoder_X.fit_transform(d2.marital)\nd2.default = labelencoder_X.fit_transform(d2.default)\nd2.housing = labelencoder_X.fit_transform(d2.housing)\nd2.loan = labelencoder_X.fit_transform(d2.loan)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"edu = {\"illiterate\" : 0,\n       \"basic.4y\" : 1,\n       \"basic.6y\" : 2,\n       \"basic.9y\" : 3,\n       \"high.school\" : 4,\n       \"professional.course\" : 5,\n       \"university.degree\" : 6}\nd2['education'].replace(edu,inplace = True)\n\n#Because I think education level has kind of ordinal, so i assign numbers to different level\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Related with the last contact of the current campaign:\n\n8 - contact: contact communication type (categorical: 'cellular','telephone') \n\n9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n\n10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n\n11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model."},{"metadata":{"trusted":true},"cell_type":"code","source":"d1.contact.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1.month.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1.day_of_week.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d2.contact = labelencoder_X.fit_transform(d2.contact)\nd2.month = labelencoder_X.fit_transform(d2.month)\nd2.day_of_week = labelencoder_X.fit_transform(d2.day_of_week)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Other attributes:\n\n12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n\n13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n\n14 - previous: number of contacts performed before this campaign and for this client (numeric)\n\n15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\nsocial and economic context attributes\n\n16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n\n17 - cons.price.idx: consumer price index - monthly indicator (numeric) \n\n18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric) \n\n19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n\n20 - nr.employed: number of employees - quarterly indicator (numeric)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d1.poutcome.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d2['poutcome'].replace(['nonexistent', 'failure', 'success'], [1,2,3], inplace  = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transform Y variable to dummy\nd2.y.value_counts()\nd2.y= labelencoder_X.fit_transform(d2.y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nd2.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = d2.corr()\ncorr.style.background_gradient(cmap = 'coolwarm')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = 'duration', data = d2, orient = 'v')\n#Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and \n#should be discarded if the intention is to have a realistic predictive model.\n#Therefore, we drop this variable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#**Model**\n\n* Logistic Regression\n* Random Forest Classifier\n* XGB Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = d2.y\nX = d2.drop('y',axis = 1)\nX = X.drop('duration',axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train for 75%, test dataset is 25%\nX_train, X_test,Y_train, Y_test = train_test_split(X,Y,test_size = 0.25,random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#############\n#Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,Y_train)\nlogpred = logmodel.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\nconlg = print(metrics.confusion_matrix(Y_test, logpred))\nacclg = print(round(metrics.accuracy_score(Y_test, logpred), 4)*100)\n##89.7\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#since the dataset is relatviely imbalaced, we should look at ROC_AUC\nproblg = logmodel.predict_proba(X_test)\npredslg = problg[:,1]\nfprlg, tprlg, threshold = metrics.roc_curve(Y_test, predslg)\nroc_auclg = metrics.auc(fprlg, tprlg)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Receiver Operating Characteristic for Logistic Regression')\nplt.plot(fprlg, tprlg, 'b', label = 'AUClg = %0.2f' % roc_auclg)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate lg')\nplt.xlabel('False Positive Rate lg')\nplt.show()\n##0.79\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#####\n#Random Forest \nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 100)\nrf.fit(X_train, Y_train)\nrfpred = rf.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conrf = print(metrics.confusion_matrix(Y_test, rfpred))\naccrf = print(round(metrics.accuracy_score(Y_test, rfpred), 4)*100)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probrf = rf.predict_proba(X_test)\npredsrf = probrf[:,1]\nfprrf, tprrf, thresholdrf = metrics.roc_curve(Y_test, predsrf)\nroc_aucrf = metrics.auc(fprrf, tprrf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Receiver Operating Characteristic for Random Forest')\nplt.plot(fprrf, tprrf, 'b', label = 'AUCrf = %0.2f' % roc_aucrf)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate rf')\nplt.xlabel('False Positive Rate rf')\nplt.show()\n##0.77\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#########\n##XGBoost\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train, Y_train)\nxgbpred = xgb.predict(X_test)\n\nconxgb = print(metrics.confusion_matrix(Y_test, xgbpred))\naccxgb = print(round(metrics.accuracy_score(Y_test, xgbpred), 4)*100)\n##89.97\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probxgb = xgb.predict_proba(X_test)\npredsxgb = probxgb[:,1]\nfprxgb, tprxgb, thresholdxgb = metrics.roc_curve(Y_test, predsxgb)\nroc_aucxgb = metrics.auc(fprxgb, tprxgb)\n\n\nplt.title('Receiver Operating Characteristic for XGBoost')\nplt.plot(fprxgb, tprxgb, 'b', label = 'AUCxgb = %0.2f' % roc_aucxgb)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate xgb')\nplt.xlabel('False Positive Rate xgb')\nplt.show()\n##0.8\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}