{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-28T12:00:16.009092Z","iopub.execute_input":"2021-05-28T12:00:16.009527Z","iopub.status.idle":"2021-05-28T12:00:16.022199Z","shell.execute_reply.started":"2021-05-28T12:00:16.009488Z","shell.execute_reply":"2021-05-28T12:00:16.020857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:00:19.08432Z","iopub.execute_input":"2021-05-28T12:00:19.084725Z","iopub.status.idle":"2021-05-28T12:00:19.089454Z","shell.execute_reply.started":"2021-05-28T12:00:19.084688Z","shell.execute_reply":"2021-05-28T12:00:19.088205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Portugese Bank term Deposit marketing campaign DataSet description:**\n\n*The data is related with direct marketing campaigns of a Portuguese banking institution.\nThe different marketing campaigns were based on phone calls.\nOften, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed.*","metadata":{}},{"cell_type":"markdown","source":"**Features Description:**\n\n- Features 1 to 4 is information on customer's age, job, marital status and educational qualification.\n- Features 5 to 8 is information on customer's credit information - Loan default status - housing, personal loan and A/c Bal value\n- Features 9 to 12 is information on customer contact in current campaign - contact mode, day of week, last contact month, duration in sec. , campaign - num of contacts during campaign.\n- Duration variable to be removed(or weightage to be reduced) as the output of the call determines the outcome for that specific customer and our model should be good in predicting with customer profile rather than duration of call with specific customer.\n- Features 13 to 15 is information on previous campaign: pdays- num of days of contact from previous campaign;\n  previous - num of contacts performed before this campaign; poutcome- outcome of previous marketing campaign\n- Target variable 'y' conatins the values of the current campaign outcome.","metadata":{}},{"cell_type":"code","source":"X = pd.read_csv('./X_Bank_portugese_dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:01:56.237008Z","iopub.execute_input":"2021-05-28T12:01:56.237496Z","iopub.status.idle":"2021-05-28T12:01:56.297646Z","shell.execute_reply.started":"2021-05-28T12:01:56.237451Z","shell.execute_reply":"2021-05-28T12:01:56.296518Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:04:23.639329Z","iopub.execute_input":"2021-05-28T12:04:23.639801Z","iopub.status.idle":"2021-05-28T12:04:23.646136Z","shell.execute_reply.started":"2021-05-28T12:04:23.639758Z","shell.execute_reply":"2021-05-28T12:04:23.645344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:14:16.735874Z","iopub.execute_input":"2021-05-28T12:14:16.736622Z","iopub.status.idle":"2021-05-28T12:14:16.743362Z","shell.execute_reply.started":"2021-05-28T12:14:16.736556Z","shell.execute_reply":"2021-05-28T12:14:16.742179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = pd.read_csv('./y_Bank_portugese_dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:04:44.118995Z","iopub.execute_input":"2021-05-28T12:04:44.119632Z","iopub.status.idle":"2021-05-28T12:04:44.138631Z","shell.execute_reply.started":"2021-05-28T12:04:44.119578Z","shell.execute_reply":"2021-05-28T12:04:44.137817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:05:59.431295Z","iopub.execute_input":"2021-05-28T12:05:59.431722Z","iopub.status.idle":"2021-05-28T12:05:59.441348Z","shell.execute_reply.started":"2021-05-28T12:05:59.431689Z","shell.execute_reply":"2021-05-28T12:05:59.440565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:11:14.427969Z","iopub.execute_input":"2021-05-28T12:11:14.428629Z","iopub.status.idle":"2021-05-28T12:11:14.433185Z","shell.execute_reply.started":"2021-05-28T12:11:14.42857Z","shell.execute_reply":"2021-05-28T12:11:14.432101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = y.ravel()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:12:01.225214Z","iopub.execute_input":"2021-05-28T12:12:01.225625Z","iopub.status.idle":"2021-05-28T12:12:01.231981Z","shell.execute_reply.started":"2021-05-28T12:12:01.225588Z","shell.execute_reply":"2021-05-28T12:12:01.231079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:13:24.480783Z","iopub.execute_input":"2021-05-28T12:13:24.481209Z","iopub.status.idle":"2021-05-28T12:13:24.487228Z","shell.execute_reply.started":"2021-05-28T12:13:24.48116Z","shell.execute_reply":"2021-05-28T12:13:24.486225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:12:21.561589Z","iopub.execute_input":"2021-05-28T12:12:21.562164Z","iopub.status.idle":"2021-05-28T12:12:21.603551Z","shell.execute_reply.started":"2021-05-28T12:12:21.562115Z","shell.execute_reply":"2021-05-28T12:12:21.602728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print( X_train.shape, y_train.shape, X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:12:24.379748Z","iopub.execute_input":"2021-05-28T12:12:24.38033Z","iopub.status.idle":"2021-05-28T12:12:24.386013Z","shell.execute_reply.started":"2021-05-28T12:12:24.380276Z","shell.execute_reply":"2021-05-28T12:12:24.385157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Applying Random Forest Classifier for this dataset and study the model explainability with SHAP values and dependance plots.***","metadata":{}},{"cell_type":"code","source":"rf_clf = RandomForestClassifier(n_estimators = 150).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:14:37.476774Z","iopub.execute_input":"2021-05-28T12:14:37.477176Z","iopub.status.idle":"2021-05-28T12:14:39.112236Z","shell.execute_reply.started":"2021-05-28T12:14:37.477136Z","shell.execute_reply":"2021-05-28T12:14:39.110911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Applying *permutation importance method* to compute the feature importances**\n* *This method works as follows:*\n*    * Alogrithm selects a feature from a single row\n*    * Permutates over the range of values available from the dataset for that feature and calculates the impact on the * target variable.\n*    * And same is repeated row-wise and for all features.","metadata":{}},{"cell_type":"code","source":"from eli5.sklearn import PermutationImportance\nimport eli5","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:14:44.233309Z","iopub.execute_input":"2021-05-28T12:14:44.233898Z","iopub.status.idle":"2021-05-28T12:14:44.238255Z","shell.execute_reply.started":"2021-05-28T12:14:44.233839Z","shell.execute_reply":"2021-05-28T12:14:44.237324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perm = PermutationImportance(rf_clf, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:15:50.793475Z","iopub.execute_input":"2021-05-28T12:15:50.794231Z","iopub.status.idle":"2021-05-28T12:16:09.977611Z","shell.execute_reply.started":"2021-05-28T12:15:50.794186Z","shell.execute_reply":"2021-05-28T12:16:09.976426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Applying SHAP summary report to calculate Feature values and depndancy (interaction) plots**","metadata":{}},{"cell_type":"code","source":"import shap","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:22:35.275962Z","iopub.execute_input":"2021-05-28T12:22:35.276568Z","iopub.status.idle":"2021-05-28T12:22:37.63175Z","shell.execute_reply.started":"2021-05-28T12:22:35.276516Z","shell.execute_reply":"2021-05-28T12:22:37.630578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer = shap.TreeExplainer(rf_clf)\n\nshap_values = explainer.shap_values(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:22:52.719434Z","iopub.execute_input":"2021-05-28T12:22:52.719906Z","iopub.status.idle":"2021-05-28T12:44:49.47135Z","shell.execute_reply.started":"2021-05-28T12:22:52.719866Z","shell.execute_reply":"2021-05-28T12:44:49.470046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_values","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:45:07.236048Z","iopub.execute_input":"2021-05-28T12:45:07.236664Z","iopub.status.idle":"2021-05-28T12:45:07.247568Z","shell.execute_reply.started":"2021-05-28T12:45:07.236606Z","shell.execute_reply":"2021-05-28T12:45:07.246267Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_values[1], X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:45:17.411869Z","iopub.execute_input":"2021-05-28T12:45:17.412335Z","iopub.status.idle":"2021-05-28T12:45:19.599751Z","shell.execute_reply.started":"2021-05-28T12:45:17.412294Z","shell.execute_reply":"2021-05-28T12:45:19.598686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* From above shap value summary plot, below are some of the inferences about dataset on *target variable (make new deposit in current campaign y/n)*:\n* *Ranked Feature Permutation-importance wise:*\n*    \n*    **Feature**:\n*     **1.** **poutcome_enc**: *Previous campaign outcome for deposit conversion - unknown/failure/other/success*\n*             * range of the **purple-pink(feat value higher side) dots** in shap value is from **-0.1 to 0.6**\n*             * distribution of those dots are dense near -0.2 to 0 and sparse in  0.3- 0.5 range of shap value\n*             * poutcome feature on most of the data have little -ve impact and more +ve on target variable\n*             * previous campaign outcome has **more influence in current campaign deposit converion** from customers than other features in the dataset.\n*             * permutation importance value: *0.0228 +/- 0.0007*\n*\n*    **2.** **job_enc**: *Job profile - managment/entrpreuner/technician/blue-collar/other*\n*           * range of **feat values in higher side: -0.2 to 0.1** (with some outliers)\n*           * distribution : dense in -0.1 to 0.1 range & sparse towards -0.2\n*           * job profile of the customers have **lesser impact on outome**(closer to 0 SHAP val) compared mode of poutcome feature.\n*           * permutation importance value: *0.0029 +/- 0.0018*\n*\n*   **3.** **contact_enc**: *Contact - mode of contact during the campaign - cell/ telephone / other*\n*           * range of **feat values in higher side: -0.2 to 0.25**\n*           * distribution : dense in -0.05 to 0.1 range & sparse towards 0.2\n*           * mode of contact has **less impact value on the outcome** as poutcome and is biased towards +ve impact on outcome.\n*           * permutation importance value: *0.0023 +/- 0.0014*\n*\n*   **4.** **housing_enc**: *Housing loan - Yes / No*\n*           * range of feat values in higher side:**0 to -0.2**\n*           * distribution: dense in -0.1 to 0 range & sparse towards -0.15\n*           * Housing loan status has **equal impact value on the outcome** as contact_enc. but on the -ve side.\n*           * permutation importance value: *0.0023 +/- 0.0010*\n*\n*   **5.** **educ_ord**: *Education qualification - tertiary, secondary, primary, other*\n*           * range of feat values in higher side: **-0.15 to 0.2**\n*           * distribution: dense near 0 (shap value) and sparse when away from centre\n*           * education qualification has **almost equal impact on the outcome** as job profile\n*           * permutation importance value: *0.0016 +/- 0.0011*\n*\n*   **6.** **marital_enc**:  *Marital status - Single/Married/Divorced*\n*           - range of feat values in higher side: **-0.2 to 0.1**\n*           - distribution: dense in -0.1 to 0 range & sparse towards -0.15\n*           - marital_enc has **similar impact value on the outcome** compared to Educ_ord.\n*           * permutation importance value: *0.0013 +/- 0.0010*\n*\n*    **7.** **loan_enc**: *personal loan - Yes/No*\n*           - range of feat values in higher side: **-0.2 to 0.1**\n*           - distribution: sparse throughout the range\n*           - loan_enc has **lesser impact on outcome** compared to marital_enc\n*           * permutation importance value: *0.0006 +/- 0.0006*\n*\n*    **8.** **default_enc**: *Loan default - Yes/No*\n*           - range of feat values in higher side: **-0.1 to 0.1**\n*           - distribution: sparse throughout the range\n*           - deafult_enc has **less impact on outcome** compared to other features\n*           * permutation importance value: *0.0003 +/- 0.0003*","metadata":{}},{"cell_type":"markdown","source":"* **Further we will explore the interactions between the top features identified**","metadata":{}},{"cell_type":"markdown","source":"**(Poutcome vs Job category on Target variable)**","metadata":{}},{"cell_type":"code","source":"shap.dependence_plot('job_enc', shap_values[1], X_test, interaction_index=\"poutcome_enc\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:45:41.621969Z","iopub.execute_input":"2021-05-28T12:45:41.622553Z","iopub.status.idle":"2021-05-28T12:45:42.000129Z","shell.execute_reply.started":"2021-05-28T12:45:41.622508Z","shell.execute_reply":"2021-05-28T12:45:41.999286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Below summary is inferred from interaction plot of top 2 important features *(Poutcome vs Job category on Target variable)* :\n*    * Interdependancy of the top 2 features is found to be **less across all categories of Job  type** (range 0.15 to -0.1)\n*    * Unemployed and Low income categories(1 - 3)* have **more positive impact on target variable** compared to *Higher income categories(4-6)* supported by *    * previous outcome feature values*. (more pink/purple dots in lower side for categ 4-6).","metadata":{}},{"cell_type":"markdown","source":"**(Poutcome vs (*Higher interaction feat calculated by algorithm*) on Target variable)**","metadata":{}},{"cell_type":"code","source":"shap.dependence_plot('poutcome_enc', shap_values[1], X_test, interaction_index='auto')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:45:53.958831Z","iopub.execute_input":"2021-05-28T12:45:53.959234Z","iopub.status.idle":"2021-05-28T12:45:54.544509Z","shell.execute_reply.started":"2021-05-28T12:45:53.9592Z","shell.execute_reply":"2021-05-28T12:45:54.543328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Below summary is inferred from *interaction plot of **important feature and higher interaction feature** chosen by algorithm (Poutcome vs housing_enc on Target variable)* :\n*  *  Previous outcome ***success rate has high influence on target variable***","metadata":{}},{"cell_type":"markdown","source":"*From **interaction feature *housing_enc*** - we can infer that the ***customers with housing loan(value 2) are less likely to make new deposits in the bank compared to without housing loan (value 1).***","metadata":{}},{"cell_type":"markdown","source":"**This notebook demonstrates the application of *Permutation importance method from Eli5 library* for calculating feature importances based on model fit.**\n **Also, the various features of *SHAP library - Summary plot, dependency plot* have been applied to explore and understand the dataset's feature impact and feature interdependencies in contributing to the prediction of the outcome (target variable).**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}